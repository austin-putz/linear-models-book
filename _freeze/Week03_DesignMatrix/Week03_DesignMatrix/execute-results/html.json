{
  "hash": "51c03de93ceb5b334263e05ec506d4a2",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Week 3: Building the Design Matrix Framework\"\nformat:\n  html:\n    toc: true\n    toc-depth: 3\n    number-sections: true\n    code-fold: false\n    code-tools: true\n---\n\n::: {.callout-note icon=false}\n## Learning Objectives\n\nBy the end of this week, you will be able to:\n\n1. **Construct** **design matrices** from raw data for different types of **predictors**\n2. **Understand** and **apply** different **coding schemes** (**cell means model**, **effects model**, **reference cell coding**)\n3. **Write** the **general linear model** in **matrix form** with correct notation\n4. **State** and **interpret** the **assumptions** underlying linear models (**Gauss-Markov conditions**)\n5. **Identify** when design matrices are **full rank** vs. **rank deficient**\n6. **Build** design matrices manually in R and compare with `model.matrix()`\n:::\n\n## Introduction: From Raw Data to Matrix Representation\n\nIn Weeks 1 and 2, we established the computational foundations and reviewed the linear algebra essentials needed for linear models. Now we address the critical question: **How do we get from raw data to the matrix equations we solve?**\n\n::: {.callout-important}\n## The Bridge from Reality to Mathematics\n\nThe **design matrix** (denoted $\\mathbf{X}$) is the bridge between:\n\n- **Raw data**: Numbers in spreadsheets, databases, or field records\n- **Mathematical model**: $\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{e}$\n\nUnderstanding how to construct $\\mathbf{X}$ is fundamental to applying linear models in animal breeding and genetics.\n:::\n\n### Why This Matters in Animal Breeding\n\nIn animal breeding applications, we constantly work with different types of predictors:\n\n- **Categorical factors**: Breed, sex, herd, diet, pen, treatment\n- **Continuous covariates**: Birth weight, age, days in milk, temperature\n- **Mixed models**: Contemporary groups (herd-year-season) combined with genetic relationships\n\nThe way we code these predictors into the design matrix determines:\n\n1. **What parameters we estimate** (individual means vs. differences from baseline)\n2. **Whether solutions are unique** (full rank vs. rank deficient)\n3. **How we interpret results** (absolute effects vs. contrasts)\n4. **Which hypotheses we can test** (estimable functions)\n\n## The General Linear Model\n\n### Matrix Form\n\nThe **general linear model** expresses the relationship between observations and parameters as:\n\n$$\n\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{e}\n$$\n\nwhere:\n\n- $\\mathbf{y}$: $(n \\times 1)$ vector of observations (response variable)\n- $\\mathbf{X}$: $(n \\times p)$ design matrix (known constants)\n- $\\boldsymbol{\\beta}$: $(p \\times 1)$ vector of unknown parameters (to be estimated)\n- $\\mathbf{e}$: $(n \\times 1)$ vector of random errors\n\n::: {.callout-note}\n## Dimensions Matter\n\nAlways verify matrix dimensions for compatibility:\n\n- $\\mathbf{X}$ is $n \\times p$ (n observations, p parameters)\n- $\\boldsymbol{\\beta}$ is $p \\times 1$ (p parameters to estimate)\n- $\\mathbf{X}\\boldsymbol{\\beta}$ is $(n \\times p)(p \\times 1) = (n \\times 1)$ ✓\n- $\\mathbf{y}$ is $n \\times 1$ ✓\n- $\\mathbf{e}$ is $n \\times 1$ ✓\n\nThe model equation is dimensionally consistent.\n:::\n\n### Expected Value Form\n\nTaking expected values of both sides:\n\n$$\nE(\\mathbf{y}) = E(\\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{e}) = \\mathbf{X}\\boldsymbol{\\beta} + E(\\mathbf{e}) = \\mathbf{X}\\boldsymbol{\\beta}\n$$\n\nThis assumes $E(\\mathbf{e}) = \\mathbf{0}$ (errors have mean zero, discussed below).\n\n### Scalar Form for Individual Observations\n\nFor the $i$-th observation:\n\n$$\ny_i = \\sum_{j=1}^{p} x_{ij}\\beta_j + e_i = x_{i1}\\beta_1 + x_{i2}\\beta_2 + \\cdots + x_{ip}\\beta_p + e_i\n$$\n\nwhere $x_{ij}$ is the element in row $i$, column $j$ of $\\mathbf{X}$.\n\n## Building Design Matrices for Different Predictor Types\n\nThe structure of $\\mathbf{X}$ depends on the type of predictors in your model. Let's examine the three main types.\n\n### Continuous Predictors (Regression)\n\nWhen all predictors are continuous variables, the design matrix includes:\n\n1. A column of ones (for the intercept)\n2. Columns for each predictor variable\n\n#### Example: Simple Linear Regression\n\nModel: $y_i = \\beta_0 + \\beta_1 x_i + e_i$\n\nFor $n=4$ observations:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Data: broiler weight (kg) vs. age (days)\nage <- c(21, 28, 35, 42)\nweight <- c(0.5, 0.9, 1.4, 1.9)\n\n# Design matrix: first column is intercept, second is predictor\nX <- cbind(1, age)\nprint(X)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       age\n[1,] 1  21\n[2,] 1  28\n[3,] 1  35\n[4,] 1  42\n```\n\n\n:::\n\n```{.r .cell-code}\n# Check dimensions\ncat(\"\\nDimensions: n =\", nrow(X), \"observations, p =\", ncol(X), \"parameters\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nDimensions: n = 4 observations, p = 2 parameters\n```\n\n\n:::\n:::\n\n\nThe design matrix is:\n\n$$\n\\mathbf{X} = \\begin{bmatrix}\n1 & 21 \\\\\n1 & 28 \\\\\n1 & 35 \\\\\n1 & 42\n\\end{bmatrix}_{4 \\times 2}\n$$\n\nThe parameter vector is:\n\n$$\n\\boldsymbol{\\beta} = \\begin{bmatrix}\n\\beta_0 \\\\\n\\beta_1\n\\end{bmatrix}_{2 \\times 1}\n$$\n\n#### Multiple Regression\n\nWith multiple continuous predictors: $y_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\cdots + \\beta_k x_{ki} + e_i$\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Example: Predict lamb weaning weight from birth weight and dam age\nbirth_wt <- c(4.5, 4.0, 4.8, 4.2, 4.6)\ndam_age <- c(3, 5, 4, 6, 4)\nwean_wt <- c(28, 24, 30, 26, 29)\n\n# Design matrix: intercept, birth weight, dam age\nX_mult <- cbind(1, birth_wt, dam_age)\ncolnames(X_mult) <- c(\"Intercept\", \"BirthWt\", \"DamAge\")\nprint(X_mult)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     Intercept BirthWt DamAge\n[1,]         1     4.5      3\n[2,]         1     4.0      5\n[3,]         1     4.8      4\n[4,]         1     4.2      6\n[5,]         1     4.6      4\n```\n\n\n:::\n:::\n\n\n$$\n\\mathbf{X} = \\begin{bmatrix}\n1 & 4.5 & 3 \\\\\n1 & 4.0 & 5 \\\\\n1 & 4.8 & 4 \\\\\n1 & 4.2 & 6 \\\\\n1 & 4.6 & 4\n\\end{bmatrix}_{5 \\times 3}, \\quad\n\\boldsymbol{\\beta} = \\begin{bmatrix}\n\\beta_0 \\\\\n\\beta_1 \\\\\n\\beta_2\n\\end{bmatrix}_{3 \\times 1}\n$$\n\n### Categorical Predictors (ANOVA)\n\nCategorical predictors (factors) require **indicator variables** (also called dummy variables). There are two primary coding schemes.\n\n#### Cell Means Model\n\nThe **cell means model** estimates a separate mean for each group, with no explicit intercept.\n\nModel: $y_{ij} = \\mu_i + e_{ij}$\n\nwhere $\\mu_i$ is the mean for group $i$ ($i = 1, \\ldots, g$ groups).\n\nThe design matrix has **one column per group**, with indicators for group membership:\n\n$$\nx_{ij} = \\begin{cases}\n1 & \\text{if observation } j \\text{ is in group } i \\\\\n0 & \\text{otherwise}\n\\end{cases}\n$$\n\n#### Example: Pig Litter Size by Breed (Cell Means)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load the pig data\npig_data <- data.frame(\n  breed = c(\"Yorkshire\", \"Yorkshire\", \"Landrace\", \"Landrace\", \"Duroc\", \"Duroc\"),\n  litter_size = c(11, 12, 10, 11, 9, 10)\n)\n\nprint(pig_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      breed litter_size\n1 Yorkshire          11\n2 Yorkshire          12\n3  Landrace          10\n4  Landrace          11\n5     Duroc           9\n6     Duroc          10\n```\n\n\n:::\n\n```{.r .cell-code}\n# Cell means design matrix: one column per breed\n# Yorkshire = column 1, Landrace = column 2, Duroc = column 3\nX_cell <- model.matrix(~ breed - 1, data = pig_data)  # -1 removes intercept\nprint(X_cell)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  breedDuroc breedLandrace breedYorkshire\n1          0             0              1\n2          0             0              1\n3          0             1              0\n4          0             1              0\n5          1             0              0\n6          1             0              0\nattr(,\"assign\")\n[1] 1 1 1\nattr(,\"contrasts\")\nattr(,\"contrasts\")$breed\n[1] \"contr.treatment\"\n```\n\n\n:::\n\n```{.r .cell-code}\n# Check rank\ncat(\"\\nRank of X:\", qr(X_cell)$rank, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nRank of X: 3 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Number of parameters:\", ncol(X_cell), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNumber of parameters: 3 \n```\n\n\n:::\n:::\n\n\nThe cell means design matrix is:\n\n$$\n\\mathbf{X}_{\\text{cell}} = \\begin{bmatrix}\n1 & 0 & 0 \\\\\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 0 & 1 \\\\\n0 & 0 & 1\n\\end{bmatrix}_{6 \\times 3}\n$$\n\nParameter vector:\n\n$$\n\\boldsymbol{\\beta}_{\\text{cell}} = \\begin{bmatrix}\n\\mu_{\\text{Duroc}} \\\\\n\\mu_{\\text{Landrace}} \\\\\n\\mu_{\\text{Yorkshire}}\n\\end{bmatrix}_{3 \\times 1}\n$$\n\n::: {.callout-tip}\n## Cell Means Model Properties\n\n- **Always full rank**: $r(\\mathbf{X}) = p$ (number of groups)\n- **Direct interpretation**: $\\mu_i$ is the mean for group $i$\n- **All parameters estimable**: Each $\\mu_i$ can be uniquely estimated\n- **Common in animal breeding**: Natural for comparing breed means, treatment means, etc.\n:::\n\n#### Effects Model (with Constraints)\n\nThe **effects model** decomposes each observation into an overall mean plus group-specific deviations.\n\nModel: $y_{ij} = \\mu + \\alpha_i + e_{ij}$\n\nwhere:\n\n- $\\mu$: overall mean (intercept)\n- $\\alpha_i$: effect of group $i$ (deviation from overall mean)\n\n**Problem**: This model is **overparameterized** without constraints.\n\nWith $g$ groups, we have $g+1$ parameters ($\\mu$ and $\\alpha_1, \\ldots, \\alpha_g$), but only $g$ distinct means. We need a **constraint** to make parameters identifiable.\n\n**Common constraint**: $\\sum_{i=1}^{g} \\alpha_i = 0$ (sum-to-zero constraint)\n\nWith this constraint, $\\alpha_i$ represents the deviation of group $i$ from the overall mean.\n\n#### Example: Pig Litter Size by Breed (Effects Model)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Effects model design matrix: intercept + group indicators\n# R uses reference cell coding by default (first level = 0)\nX_effects <- model.matrix(~ breed, data = pig_data)\nprint(X_effects)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  (Intercept) breedLandrace breedYorkshire\n1           1             0              1\n2           1             0              1\n3           1             1              0\n4           1             1              0\n5           1             0              0\n6           1             0              0\nattr(,\"assign\")\n[1] 0 1 1\nattr(,\"contrasts\")\nattr(,\"contrasts\")$breed\n[1] \"contr.treatment\"\n```\n\n\n:::\n\n```{.r .cell-code}\n# Check rank\ncat(\"\\nRank of X:\", qr(X_effects)$rank, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nRank of X: 3 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Number of parameters:\", ncol(X_effects), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNumber of parameters: 3 \n```\n\n\n:::\n:::\n\n\nThe effects model design matrix (without constraint applied yet):\n\n$$\n\\mathbf{X}_{\\text{effects}} = \\begin{bmatrix}\n1 & 0 & 0 \\\\\n1 & 0 & 0 \\\\\n1 & 1 & 0 \\\\\n1 & 1 & 0 \\\\\n1 & 0 & 1 \\\\\n1 & 0 & 1\n\\end{bmatrix}_{6 \\times 3}\n$$\n\n::: {.callout-warning}\n## Rank Deficiency Alert\n\nThe full effects model matrix (with all $g+1$ parameters) would be:\n\n$$\n\\mathbf{X}_{\\text{full}} = \\begin{bmatrix}\n1 & 1 & 0 & 0 \\\\\n1 & 1 & 0 & 0 \\\\\n1 & 0 & 1 & 0 \\\\\n1 & 0 & 1 & 0 \\\\\n1 & 0 & 0 & 1 \\\\\n1 & 0 & 0 & 1\n\\end{bmatrix}_{6 \\times 4}\n$$\n\nThis has rank $r(\\mathbf{X}) = 3 < 4$, making it **rank deficient**. Individual parameters ($\\mu$, $\\alpha_i$) are not uniquely estimable, but **contrasts** like $\\alpha_i - \\alpha_j$ are estimable.\n\nWe'll address non-full rank models in detail in Week 12.\n:::\n\n#### Reference Cell Coding (Set-to-Zero Constraint)\n\nR's default for categorical variables uses **reference cell coding** (also called treatment coding):\n\n- Set the first group's effect to zero: $\\alpha_1 = 0$\n- Other $\\alpha_i$ represent deviations from group 1\n\nWith this constraint:\n\n- $\\mu$ = mean of reference group (Duroc, alphabetically first)\n- $\\alpha_{\\text{Landrace}}$ = Landrace effect = (Landrace mean) - (Duroc mean)\n- $\\alpha_{\\text{Yorkshire}}$ = Yorkshire effect = (Yorkshire mean) - (Duroc mean)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Compute group means\ngroup_means <- tapply(pig_data$litter_size, pig_data$breed, mean)\nprint(group_means)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    Duroc  Landrace Yorkshire \n      9.5      10.5      11.5 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Interpretation with Duroc as reference (first alphabetically)\ncat(\"\\nWith reference cell coding (Duroc as baseline):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nWith reference cell coding (Duroc as baseline):\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"μ (intercept) = Duroc mean =\", group_means[\"Duroc\"], \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nμ (intercept) = Duroc mean = 9.5 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"α_Landrace = Landrace - Duroc =\", group_means[\"Landrace\"] - group_means[\"Duroc\"], \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nα_Landrace = Landrace - Duroc = 1 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"α_Yorkshire = Yorkshire - Duroc =\", group_means[\"Yorkshire\"] - group_means[\"Duroc\"], \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nα_Yorkshire = Yorkshire - Duroc = 2 \n```\n\n\n:::\n:::\n\n\n### Mixed Predictors (ANCOVA)\n\nWhen models include both categorical and continuous predictors, we have **Analysis of Covariance (ANCOVA)**.\n\nModel: $y_{ij} = \\mu + \\alpha_i + \\beta(x_{ij} - \\bar{x}) + e_{ij}$\n\nThe design matrix combines indicator columns (for groups) and continuous columns (for covariates).\n\n#### Example: Egg Production by Strain, Adjusted for Body Weight\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Data: egg production (eggs/month) by strain, with body weight covariate\negg_data <- data.frame(\n  strain = rep(c(\"Strain1\", \"Strain2\", \"Strain3\"), each = 3),\n  body_weight = c(1.8, 2.0, 1.9, 1.7, 1.8, 1.9, 2.1, 2.3, 2.2),\n  eggs = c(24, 26, 25, 22, 23, 24, 26, 28, 27)\n)\n\n# ANCOVA design matrix: strain indicators + centered body weight\negg_data$bw_centered <- egg_data$body_weight - mean(egg_data$body_weight)\nX_ancova <- model.matrix(~ strain + bw_centered, data = egg_data)\nprint(X_ancova)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  (Intercept) strainStrain2 strainStrain3 bw_centered\n1           1             0             0 -0.16666667\n2           1             0             0  0.03333333\n3           1             0             0 -0.06666667\n4           1             1             0 -0.26666667\n5           1             1             0 -0.16666667\n6           1             1             0 -0.06666667\n7           1             0             1  0.13333333\n8           1             0             1  0.33333333\n9           1             0             1  0.23333333\nattr(,\"assign\")\n[1] 0 1 1 2\nattr(,\"contrasts\")\nattr(,\"contrasts\")$strain\n[1] \"contr.treatment\"\n```\n\n\n:::\n:::\n\n\n::: {.callout-note}\n## Centering Covariates\n\nWe often **center** continuous covariates by subtracting the mean: $x_{ij}^* = x_{ij} - \\bar{x}$\n\n**Benefits**:\n\n1. The intercept represents the group mean at the average covariate value\n2. Reduces collinearity between interaction terms and main effects\n3. Makes parameter interpretation more intuitive\n\n**Note**: Centering does NOT change $R^2$, residuals, or fitted values—only the interpretation of $\\beta_0$.\n:::\n\n## Model Assumptions (Gauss-Markov Conditions)\n\nFor the general linear model $\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{e}$, we make specific assumptions about the error term $\\mathbf{e}$.\n\n### The Three Core Assumptions\n\n::: {.callout-important}\n## Gauss-Markov Assumptions\n\nUnder these assumptions, ordinary least squares (OLS) estimators are BLUE (Best Linear Unbiased Estimators):\n\n1. **Linearity**: The relationship between $\\mathbf{y}$ and $\\mathbf{X}$ is linear\n   - Correctly specified: $E(\\mathbf{y}) = \\mathbf{X}\\boldsymbol{\\beta}$\n\n2. **Zero Mean Errors**: $E(\\mathbf{e}) = \\mathbf{0}$\n   - Errors are unbiased (centered at zero)\n   - No systematic over- or under-prediction\n\n3. **Homoscedasticity and Independence**: $\\text{Var}(\\mathbf{e}) = \\sigma^2\\mathbf{I}$\n   - **Homoscedasticity**: Constant variance across all observations ($\\text{Var}(e_i) = \\sigma^2$ for all $i$)\n   - **Independence**: Errors are uncorrelated ($\\text{Cov}(e_i, e_j) = 0$ for $i \\neq j$)\n:::\n\n### Variance-Covariance Structure\n\nThe assumption $\\text{Var}(\\mathbf{e}) = \\sigma^2\\mathbf{I}$ can be written explicitly:\n\n$$\n\\text{Var}(\\mathbf{e}) = \\begin{bmatrix}\n\\sigma^2 & 0 & 0 & \\cdots & 0 \\\\\n0 & \\sigma^2 & 0 & \\cdots & 0 \\\\\n0 & 0 & \\sigma^2 & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & 0 & \\cdots & \\sigma^2\n\\end{bmatrix} = \\sigma^2 \\mathbf{I}\n$$\n\n- **Diagonal elements**: $\\text{Var}(e_i) = \\sigma^2$ (constant variance)\n- **Off-diagonal elements**: $\\text{Cov}(e_i, e_j) = 0$ (independence)\n\n### Additional Assumption for Inference: Normality\n\nFor hypothesis testing and confidence intervals, we often add:\n\n4. **Normality**: $\\mathbf{e} \\sim N(\\mathbf{0}, \\sigma^2\\mathbf{I})$\n\nThis implies $\\mathbf{y} \\sim N(\\mathbf{X}\\boldsymbol{\\beta}, \\sigma^2\\mathbf{I})$\n\n::: {.callout-note}\n## When is Normality Needed?\n\n- **NOT needed** for unbiasedness of $\\hat{\\boldsymbol{\\beta}}$ or minimum variance (Gauss-Markov)\n- **IS needed** for:\n  - Exact $t$-tests and $F$-tests\n  - Confidence intervals with stated coverage\n  - Maximum likelihood interpretation\n\nFor large samples, the Central Limit Theorem provides approximate normality even if errors aren't exactly normal.\n:::\n\n### Violations and Consequences\n\n| Violation | Consequence | Solution |\n|-----------|-------------|----------|\n| Non-linearity | Biased estimates | Transform variables, add polynomial terms |\n| $E(\\mathbf{e}) \\neq \\mathbf{0}$ | Biased intercept | Check model specification |\n| Heteroscedasticity | Inefficient estimates, incorrect SEs | Weighted least squares, robust SEs |\n| Correlation (e.g., time series) | Inefficient estimates, incorrect SEs | Generalized least squares, mixed models |\n| Non-normality | Invalid inference (test statistics) | Transformations, bootstrapping, larger samples |\n\nWe'll explore diagnostics to check these assumptions in Week 11.\n\n## Small Example: Pig Litter Size by Breed\n\nLet's work through a complete small example, showing both cell means and effects model formulations.\n\n### Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Read the data\npig_data <- read.csv(\"data/pig_litter_breeds.csv\")\nprint(pig_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  sow_id     breed litter_size\n1      1 Yorkshire          11\n2      2 Yorkshire          12\n3      3  Landrace          10\n4      4  Landrace          11\n5      5     Duroc           9\n6      6     Duroc          10\n```\n\n\n:::\n\n```{.r .cell-code}\n# Summary statistics by breed\ncat(\"\\nSummary by breed:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nSummary by breed:\n```\n\n\n:::\n\n```{.r .cell-code}\nby(pig_data$litter_size, pig_data$breed, function(x) {\n  cat(sprintf(\"  n = %d, mean = %.2f, sd = %.2f\\n\", length(x), mean(x), sd(x)))\n})\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  n = 2, mean = 9.50, sd = 0.71\n  n = 2, mean = 10.50, sd = 0.71\n  n = 2, mean = 11.50, sd = 0.71\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\npig_data$breed: Duroc\nNULL\n------------------------------------------------------------ \npig_data$breed: Landrace\nNULL\n------------------------------------------------------------ \npig_data$breed: Yorkshire\nNULL\n```\n\n\n:::\n:::\n\n\n### Cell Means Model\n\nModel: $y_{ij} = \\mu_i + e_{ij}$ where $i \\in \\{\\text{Duroc, Landrace, Yorkshire}\\}$\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Construct design matrix manually\nn <- nrow(pig_data)\nX_cell <- matrix(0, nrow = n, ncol = 3)\nX_cell[pig_data$breed == \"Duroc\", 1] <- 1\nX_cell[pig_data$breed == \"Landrace\", 2] <- 1\nX_cell[pig_data$breed == \"Yorkshire\", 3] <- 1\ncolnames(X_cell) <- c(\"Duroc\", \"Landrace\", \"Yorkshire\")\n\ncat(\"Cell Means Design Matrix:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCell Means Design Matrix:\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(X_cell)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     Duroc Landrace Yorkshire\n[1,]     0        0         1\n[2,]     0        0         1\n[3,]     0        1         0\n[4,]     0        1         0\n[5,]     1        0         0\n[6,]     1        0         0\n```\n\n\n:::\n\n```{.r .cell-code}\n# Response vector\ny <- pig_data$litter_size\n\n# Normal equations: X'X b = X'y\nXtX <- t(X_cell) %*% X_cell\nXty <- t(X_cell) %*% y\n\ncat(\"\\nX'X (3×3):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nX'X (3×3):\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(XtX)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          Duroc Landrace Yorkshire\nDuroc         2        0         0\nLandrace      0        2         0\nYorkshire     0        0         2\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\nX'y (3×1):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nX'y (3×1):\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(Xty)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          [,1]\nDuroc       19\nLandrace    21\nYorkshire   23\n```\n\n\n:::\n\n```{.r .cell-code}\n# Solve for estimates\nb_cell <- solve(XtX) %*% Xty\ncat(\"\\nParameter estimates:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nParameter estimates:\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(b_cell)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          [,1]\nDuroc      9.5\nLandrace  10.5\nYorkshire 11.5\n```\n\n\n:::\n\n```{.r .cell-code}\n# These are just the group means!\ncat(\"\\nVerify these equal group means:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nVerify these equal group means:\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(tapply(y, pig_data$breed, mean))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    Duroc  Landrace Yorkshire \n      9.5      10.5      11.5 \n```\n\n\n:::\n:::\n\n\n**Interpretation**:\n\n- $\\hat{\\mu}_{\\text{Duroc}} = 9.5$ piglets per litter\n- $\\hat{\\mu}_{\\text{Landrace}} = 10.5$ piglets per litter\n- $\\hat{\\mu}_{\\text{Yorkshire}} = 11.5$ piglets per litter\n\n::: {.callout-tip}\n## Cell Means = Group Means\n\nIn the cell means model with balanced data, the estimates are simply the group means. The math gives us:\n\n$$\n\\hat{\\mu}_i = \\frac{\\sum_{j=1}^{n_i} y_{ij}}{n_i} = \\bar{y}_{i\\cdot}\n$$\n\nThis is intuitive: our best estimate of a group's mean is the average of observations in that group!\n:::\n\n### Effects Model (Reference Cell Coding)\n\nModel: $y_{ij} = \\mu + \\alpha_i + e_{ij}$ with $\\alpha_{\\text{Duroc}} = 0$ (Duroc as reference)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Use R's default reference cell coding\nX_effects <- model.matrix(~ breed, data = pig_data)\n\ncat(\"Effects Model Design Matrix:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nEffects Model Design Matrix:\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(X_effects)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  (Intercept) breedLandrace breedYorkshire\n1           1             0              1\n2           1             0              1\n3           1             1              0\n4           1             1              0\n5           1             0              0\n6           1             0              0\nattr(,\"assign\")\n[1] 0 1 1\nattr(,\"contrasts\")\nattr(,\"contrasts\")$breed\n[1] \"contr.treatment\"\n```\n\n\n:::\n\n```{.r .cell-code}\n# Note: Duroc is reference (alphabetically first), so no column for it\n# breedLandrace and breedYorkshire are deviations from Duroc\n\n# Solve using lm() for comparison\nfit_effects <- lm(litter_size ~ breed, data = pig_data)\ncat(\"\\nParameter estimates (reference cell coding):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nParameter estimates (reference cell coding):\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(coef(fit_effects))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   (Intercept)  breedLandrace breedYorkshire \n           9.5            1.0            2.0 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Manual calculation\nXtX_eff <- t(X_effects) %*% X_effects\nXty_eff <- t(X_effects) %*% y\nb_effects <- solve(XtX_eff) %*% Xty_eff\n\ncat(\"\\nManual calculation:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nManual calculation:\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(b_effects)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n               [,1]\n(Intercept)     9.5\nbreedLandrace   1.0\nbreedYorkshire  2.0\n```\n\n\n:::\n:::\n\n\n**Interpretation (with Duroc as reference)**:\n\n- $\\hat{\\mu} = 9.5$ = Duroc mean (reference group)\n- $\\hat{\\alpha}_{\\text{Landrace}} = 1.0$ = Landrace mean - Duroc mean = $10.5 - 9.5$\n- $\\hat{\\alpha}_{\\text{Yorkshire}} = 2.0$ = Yorkshire mean - Duroc mean = $11.5 - 9.5$\n\n### Comparing the Two Models\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Cell means model: estimates are group means\ncat(\"Cell Means Model Estimates:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCell Means Model Estimates:\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Duroc:\", b_cell[1], \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nDuroc: 9.5 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Landrace:\", b_cell[2], \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLandrace: 10.5 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Yorkshire:\", b_cell[3], \"\\n\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nYorkshire: 11.5 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Effects model: reconstruct group means\ncat(\"Effects Model - Reconstructed Group Means:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nEffects Model - Reconstructed Group Means:\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Duroc (reference):\", b_effects[1], \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nDuroc (reference): 9.5 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Landrace:\", b_effects[1] + b_effects[2], \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLandrace: 10.5 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Yorkshire:\", b_effects[1] + b_effects[3], \"\\n\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nYorkshire: 11.5 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Both give identical fitted values\nfitted_cell <- X_cell %*% b_cell\nfitted_effects <- X_effects %*% b_effects\n\ncat(\"Fitted values match:\", all.equal(fitted_cell[,1], fitted_effects[,1]), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFitted values match: names for current but not for target \n```\n\n\n:::\n:::\n\n\n::: {.callout-important}\n## Key Insight: Coding Doesn't Change Predictions\n\nDifferent coding schemes (cell means vs. effects model) give different parameter estimates, but:\n\n1. **Fitted values** $\\hat{\\mathbf{y}} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}}$ are identical\n2. **Residuals** $\\mathbf{e} = \\mathbf{y} - \\hat{\\mathbf{y}}$ are identical\n3. **$R^2$**, **SSE**, and all other model fit statistics are identical\n4. **Estimable functions** (like breed differences) give the same results\n\nThe choice of coding affects **parameter interpretation**, not model fit.\n:::\n\n## Realistic Application: Broiler Body Weight by Sex\n\nNow let's analyze a larger dataset: body weight (kg) for 20 broiler chickens at 42 days of age, by sex.\n\n### Exploratory Analysis\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load data\nbroiler_data <- read.csv(\"data/broiler_bodyweight_sex.csv\")\n\ncat(\"Data structure:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nData structure:\n```\n\n\n:::\n\n```{.r .cell-code}\nstr(broiler_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t20 obs. of  3 variables:\n $ bird_id       : int  1 2 3 4 5 6 7 8 9 10 ...\n $ sex           : chr  \"Male\" \"Male\" \"Male\" \"Male\" ...\n $ body_weight_kg: num  2.85 2.92 2.78 2.88 2.95 2.82 2.9 2.87 2.93 2.8 ...\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\nFirst few rows:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nFirst few rows:\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(broiler_data)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n| bird_id|sex  | body_weight_kg|\n|-------:|:----|--------------:|\n|       1|Male |           2.85|\n|       2|Male |           2.92|\n|       3|Male |           2.78|\n|       4|Male |           2.88|\n|       5|Male |           2.95|\n|       6|Male |           2.82|\n\n</div>\n:::\n\n```{.r .cell-code}\n# Summary statistics by sex\ncat(\"\\nSummary statistics by sex:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nSummary statistics by sex:\n```\n\n\n:::\n\n```{.r .cell-code}\nby(broiler_data$body_weight_kg, broiler_data$sex, function(x) {\n  cat(sprintf(\"  n = %d, mean = %.3f, sd = %.3f, min = %.3f, max = %.3f\\n\",\n              length(x), mean(x), sd(x), min(x), max(x)))\n})\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  n = 10, mean = 2.496, sd = 0.032, min = 2.450, max = 2.550\n  n = 10, mean = 2.870, sd = 0.057, min = 2.780, max = 2.950\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nbroiler_data$sex: Female\nNULL\n------------------------------------------------------------ \nbroiler_data$sex: Male\nNULL\n```\n\n\n:::\n:::\n\n\n### Visualization\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Box plot\nboxplot(body_weight_kg ~ sex, data = broiler_data,\n        main = \"Broiler Body Weight by Sex\",\n        xlab = \"Sex\",\n        ylab = \"Body Weight (kg)\",\n        col = c(\"lightblue\", \"lightpink\"))\n\n# Add means\nmeans <- tapply(broiler_data$body_weight_kg, broiler_data$sex, mean)\npoints(1:2, means, pch = 19, col = \"red\", cex = 1.5)\nlegend(\"topright\", legend = \"Group mean\", pch = 19, col = \"red\")\n```\n\n::: {.cell-output-display}\n![](Week03_DesignMatrix_files/figure-html/broiler-plot-1.png){width=576}\n:::\n:::\n\n\n**Observations**:\n\n- Males are clearly heavier than females (sexual dimorphism)\n- Both groups show similar variation (standard deviations)\n- Distributions appear roughly symmetric (no obvious outliers)\n\n### Cell Means Model Analysis\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Cell means model: estimate mean for each sex\nX_cell_broiler <- model.matrix(~ sex - 1, data = broiler_data)\ny_broiler <- broiler_data$body_weight_kg\n\n# Solve normal equations\nXtX_broiler <- t(X_cell_broiler) %*% X_cell_broiler\nXty_broiler <- t(X_cell_broiler) %*% y_broiler\n\ncat(\"X'X:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nX'X:\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(XtX_broiler)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          sexFemale sexMale\nsexFemale        10       0\nsexMale           0      10\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\nX'y:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nX'y:\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(Xty_broiler)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           [,1]\nsexFemale 24.96\nsexMale   28.70\n```\n\n\n:::\n\n```{.r .cell-code}\nb_cell_broiler <- solve(XtX_broiler) %*% Xty_broiler\ncat(\"\\nEstimated means (kg):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nEstimated means (kg):\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(b_cell_broiler)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           [,1]\nsexFemale 2.496\nsexMale   2.870\n```\n\n\n:::\n\n```{.r .cell-code}\n# Compute residuals and fit statistics\nfitted_broiler <- X_cell_broiler %*% b_cell_broiler\nresiduals_broiler <- y_broiler - fitted_broiler\nSSE_broiler <- sum(residuals_broiler^2)\nSST_broiler <- sum((y_broiler - mean(y_broiler))^2)\nR2_broiler <- 1 - SSE_broiler / SST_broiler\n\ncat(\"\\nModel fit:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nModel fit:\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"SSE =\", round(SSE_broiler, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSSE = 0.0386 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"SST =\", round(SST_broiler, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSST = 0.738 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"R² =\", round(R2_broiler, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nR² = 0.9476 \n```\n\n\n:::\n:::\n\n\n### Effects Model Analysis\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit using lm() with effects model\nfit_broiler <- lm(body_weight_kg ~ sex, data = broiler_data)\n\ncat(\"Effects model summary:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nEffects model summary:\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(fit_broiler)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = body_weight_kg ~ sex, data = broiler_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.0900 -0.0285  0.0020  0.0310  0.0800 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  2.49600    0.01465  170.36  < 2e-16 ***\nsexMale      0.37400    0.02072   18.05 5.62e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.04633 on 18 degrees of freedom\nMultiple R-squared:  0.9476,\tAdjusted R-squared:  0.9447 \nF-statistic: 325.8 on 1 and 18 DF,  p-value: 5.617e-13\n```\n\n\n:::\n\n```{.r .cell-code}\n# Compare with manual calculation\nX_eff_broiler <- model.matrix(fit_broiler)\nb_eff_broiler <- solve(t(X_eff_broiler) %*% X_eff_broiler) %*%\n                 t(X_eff_broiler) %*% y_broiler\n\ncat(\"\\nManual calculation of effects model:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nManual calculation of effects model:\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(b_eff_broiler)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n             [,1]\n(Intercept) 2.496\nsexMale     0.374\n```\n\n\n:::\n:::\n\n\n### Interpretation\n\nWith Female as the reference category (alphabetically first):\n\n- **Intercept** = $2.496$ kg = estimated mean for females\n- **sexMale** = $0.371$ kg = difference between males and females\n- **Male mean** = $2.496 + 0.371 = 2.867$ kg\n\n::: {.callout-note}\n## Statistical Significance\n\nThe `lm()` output shows:\n\n- **t-statistic for sexMale** = 18.66 (very large!)\n- **p-value** < 0.001 (highly significant)\n\nThis provides strong evidence that male broilers weigh more than females at 42 days of age.\n\nWe'll cover the details of hypothesis testing in Weeks 5-6.\n:::\n\n### Verify Against Simple Calculations\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# The estimates should match simple group means\ngroup_means_broiler <- tapply(y_broiler, broiler_data$sex, mean)\ncat(\"Group means from data:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nGroup means from data:\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(group_means_broiler)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFemale   Male \n 2.496  2.870 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\nDifference (Male - Female):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nDifference (Male - Female):\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(group_means_broiler[\"Male\"] - group_means_broiler[\"Female\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Male \n0.374 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\nThese match our effects model estimates:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nThese match our effects model estimates:\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Intercept (Female mean):\", coef(fit_broiler)[1], \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nIntercept (Female mean): 2.496 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"sexMale (difference):\", coef(fit_broiler)[2], \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nsexMale (difference): 0.374 \n```\n\n\n:::\n:::\n\n\n## Building Design Matrices in R\n\nR provides several ways to construct design matrices. Understanding both manual and automatic approaches deepens your understanding.\n\n### Manual Construction\n\nFor full control and learning, build $\\mathbf{X}$ manually:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Example: 2 groups, 4 observations\ngroup <- c(\"A\", \"A\", \"B\", \"B\")\ny_vals <- c(5, 7, 3, 4)\n\n# Cell means model: create indicator columns\nn <- length(y_vals)\nX_manual <- matrix(0, nrow = n, ncol = 2)\nX_manual[group == \"A\", 1] <- 1\nX_manual[group == \"B\", 2] <- 1\ncolnames(X_manual) <- c(\"GroupA\", \"GroupB\")\n\ncat(\"Manually constructed design matrix:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nManually constructed design matrix:\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(X_manual)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     GroupA GroupB\n[1,]      1      0\n[2,]      1      0\n[3,]      0      1\n[4,]      0      1\n```\n\n\n:::\n:::\n\n\n### Using `model.matrix()`\n\nThe `model.matrix()` function automatically creates design matrices from formulas:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create a data frame\nexample_data <- data.frame(group = group, y = y_vals)\n\n# Cell means model (no intercept)\nX_cell_auto <- model.matrix(~ group - 1, data = example_data)\ncat(\"Cell means (~ group - 1):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCell means (~ group - 1):\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(X_cell_auto)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  groupA groupB\n1      1      0\n2      1      0\n3      0      1\n4      0      1\nattr(,\"assign\")\n[1] 1 1\nattr(,\"contrasts\")\nattr(,\"contrasts\")$group\n[1] \"contr.treatment\"\n```\n\n\n:::\n\n```{.r .cell-code}\n# Effects model (with intercept)\nX_effects_auto <- model.matrix(~ group, data = example_data)\ncat(\"\\nEffects model (~ group):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nEffects model (~ group):\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(X_effects_auto)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  (Intercept) groupB\n1           1      0\n2           1      0\n3           1      1\n4           1      1\nattr(,\"assign\")\n[1] 0 1\nattr(,\"contrasts\")\nattr(,\"contrasts\")$group\n[1] \"contr.treatment\"\n```\n\n\n:::\n:::\n\n\n::: {.callout-tip}\n## Formula Syntax in R\n\n- `~ group`: Effects model with intercept (reference cell coding)\n- `~ group - 1`: Cell means model (no intercept, one column per level)\n- `~ 0 + group`: Equivalent to `~ group - 1`\n- `~ x1 + x2`: Multiple predictors (intercept + x1 + x2)\n- `~ group + x`: ANCOVA (categorical + continuous)\n- `~ group * x`: Includes main effects and interaction\n:::\n\n### Checking Design Matrix Properties\n\nAlways verify your design matrix:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Function to check design matrix properties\ncheck_design <- function(X, name = \"X\") {\n  cat(\"\\n=== Design Matrix Check:\", name, \"===\\n\")\n  cat(\"Dimensions:\", nrow(X), \"×\", ncol(X), \"\\n\")\n  cat(\"Rank:\", qr(X)$rank, \"\\n\")\n  cat(\"Full rank?\", qr(X)$rank == ncol(X), \"\\n\")\n\n  # Check for linear dependencies\n  if (qr(X)$rank < ncol(X)) {\n    cat(\"WARNING: Matrix is rank deficient!\\n\")\n    cat(\"Number of parameters:\", ncol(X), \"\\n\")\n    cat(\"Effective rank:\", qr(X)$rank, \"\\n\")\n  }\n}\n\n# Check our broiler design matrices\ncheck_design(X_cell_broiler, \"Cell Means (Broiler)\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n=== Design Matrix Check: Cell Means (Broiler) ===\nDimensions: 20 × 2 \nRank: 2 \nFull rank? TRUE \n```\n\n\n:::\n\n```{.r .cell-code}\ncheck_design(model.matrix(fit_broiler), \"Effects Model (Broiler)\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n=== Design Matrix Check: Effects Model (Broiler) ===\nDimensions: 20 × 2 \nRank: 2 \nFull rank? TRUE \n```\n\n\n:::\n:::\n\n\n## Summary\n\n### Key Takeaways\n\n::: {.callout-note}\n## What We Learned\n\n1. **Design Matrix is the Bridge**: $\\mathbf{X}$ connects raw data to the model $\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{e}$\n\n2. **Predictor Types**:\n   - Continuous predictors → columns of numeric values\n   - Categorical predictors → indicator (dummy) variables\n\n3. **Coding Schemes**:\n   - **Cell means**: One parameter per group, always full rank\n   - **Effects model**: Intercept + group effects, requires constraints for full rank\n   - **Reference cell**: Set one group to zero, others are deviations\n\n4. **Gauss-Markov Assumptions**:\n   - Linearity: $E(\\mathbf{y}) = \\mathbf{X}\\boldsymbol{\\beta}$\n   - Zero mean errors: $E(\\mathbf{e}) = \\mathbf{0}$\n   - Constant variance and independence: $\\text{Var}(\\mathbf{e}) = \\sigma^2\\mathbf{I}$\n\n5. **Different Coding, Same Fit**: Coding schemes change parameter interpretation but not fitted values, residuals, or $R^2$\n\n6. **Always Check**: Verify dimensions, rank, and linear independence of $\\mathbf{X}$\n:::\n\n### Looking Ahead\n\nNext week (**Week 4: Simple Linear Regression**), we'll:\n\n- Derive least squares estimates for the simplest case: one continuous predictor\n- Understand the geometry of least squares (projection)\n- Interpret slope and intercept in biological contexts\n- Compute fitted values, residuals, and measures of fit\n- Build our first complete solver for regression\n\nThe design matrix concepts from this week provide the foundation for all subsequent work with linear models.\n\n## Additional Resources\n\n### R Functions Reference\n\n| Function | Purpose | Example |\n|----------|---------|---------|\n| `model.matrix()` | Create design matrix from formula | `model.matrix(~ breed, data)` |\n| `cbind()` | Combine vectors/matrices by columns | `cbind(1, x1, x2)` |\n| `qr()$rank` | Compute matrix rank | `qr(X)$rank` |\n| `solve()` | Matrix inverse | `solve(XtX)` |\n| `t()` | Matrix transpose | `t(X)` |\n| `%*%` | Matrix multiplication | `X %*% beta` |\n\n### Key Concepts\n\n- **Design matrix**: Known constants relating observations to parameters\n- **Cell means model**: Estimates group means directly (full rank)\n- **Effects model**: Estimates overall mean + group deviations (may be rank deficient)\n- **Reference cell coding**: One group set to zero, others are contrasts\n- **Gauss-Markov conditions**: Assumptions ensuring OLS is BLUE\n- **Estimable function**: Linear combination of parameters that can be uniquely estimated\n\n---\n\n**Previous**: [Week 2: Linear Algebra Essentials](../Week02_LinearAlgebra/Week02_LinearAlgebra.qmd)\n**Next**: [Week 4: Simple Linear Regression](../Week04_SimpleRegression/Week04_SimpleRegression.qmd)\n",
    "supporting": [
      "Week03_DesignMatrix_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}