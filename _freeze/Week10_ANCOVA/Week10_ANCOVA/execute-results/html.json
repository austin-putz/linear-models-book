{
  "hash": "28c068ade98cf6f7520e6134500542fd",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Week 10: Analysis of Covariance (ANCOVA)\"\nformat:\n  html:\n    toc: true\n    toc-depth: 3\n    number-sections: true\n    code-fold: false\n    code-tools: true\nbibliography: ../references.bib\n---\n\n::: {.callout-note icon=false}\n## Learning Objectives\n\nBy the end of this week, you will be able to:\n\n1. **Combine** **categorical** and **continuous predictors** in a unified **linear model framework**\n2. **Adjust** **treatment means** for **covariate effects** and interpret **adjusted means** correctly\n3. **Test** the **homogeneity of slopes assumption** and understand its critical importance\n4. **Construct** **ANCOVA design matrices** and solve **normal equations** manually\n5. **Apply** ANCOVA to increase **precision** and remove **confounding** in livestock breeding studies\n:::\n\n---\n\n# Introduction\n\n## Why Learn ANCOVA?\n\nIn Weeks 7-9, we learned how to analyze **categorical predictors** (breeds, diets, treatments) using ANOVA. In Weeks 4-6, we studied **continuous predictors** (weights, ages, days) using regression. But real-world animal breeding and production problems often involve **both types of predictors simultaneously**.\n\nConsider these common scenarios in livestock science:\n\n::: {.callout-tip}\n## Real-World Livestock Problems Requiring ANCOVA\n\n1. **Breed Comparison with Unequal Starting Points**\n   - **Problem**: Compare growth rates across pig breeds, but breeds differ in birth weight\n   - **Solution**: ANCOVA adjusts for initial weight differences\n   - **Question**: Which breed grows fastest for piglets of the SAME birth weight?\n\n2. **Herd Evaluation at Different Production Stages**\n   - **Problem**: Dairy herds tested at different stages of lactation\n   - **Solution**: ANCOVA adjusts for days in milk (DIM)\n   - **Question**: Which herd has best management, independent of lactation stage?\n\n3. **Diet Trial with Age Variation**\n   - **Problem**: Animals start diet trial at different ages\n   - **Solution**: ANCOVA adjusts for initial age\n   - **Question**: Which diet is best for animals of similar starting age?\n\n4. **Sire Comparison with Progeny Age Differences**\n   - **Problem**: Offspring measured at different ages\n   - **Solution**: ANCOVA adjusts for age at measurement\n   - **Question**: Which sire produces superior offspring at the SAME age?\n:::\n\nIn all these cases, the **covariate** (initial weight, DIM, age) is a **confounding variable** that obscures the true treatment effect. ANCOVA removes this confounding to reveal fair comparisons.\n\n::: {.callout-important}\n## ANCOVA is ANOVA + Regression Combined\n\n**Analysis of Covariance (ANCOVA)** is the natural fusion of two methods we already know:\n\n- **ANOVA** (Week 7-9): Compare group means (categorical predictor)\n- **Regression** (Week 4-6): Model continuous relationships (continuous predictor)\n- **ANCOVA** (Week 10): Do both simultaneously!\n\nMathematically, ANCOVA is just **multiple regression** where some predictors are categorical (treatment indicators) and others are continuous (covariates).\n:::\n\n## Connection to Previous Weeks\n\nLet's see how ANCOVA bridges regression and ANOVA:\n\n| **Aspect** | **Regression (Week 6)** | **ANOVA (Week 7)** | **ANCOVA (Week 10)** |\n|------------|-------------------------|---------------------|----------------------|\n| **Predictor type** | Continuous | Categorical | Both |\n| **Design matrix X** | Real values | 0s and 1s (indicators) | Both |\n| **Example model** | $y = \\beta_0 + \\beta_1 x + e$ | $y_{ij} = \\mu_i + e_{ij}$ | $y_{ij} = \\mu + \\alpha_i + \\beta x_{ij} + e_{ij}$ |\n| **Primary interest** | Slope $\\beta_1$ | Group differences $\\mu_i - \\mu_j$ | Group differences **adjusted** for $x$ |\n| **Interpretation** | Change in $y$ per unit $x$ | Mean of each group | Group means at common $x$ value |\n\n**Key insight**: ANCOVA asks, \"Are treatment groups different when we **hold the covariate constant**?\" This is exactly the concept of **partial effects** from multiple regression (Week 6)!\n\n## Three Purposes of ANCOVA\n\nANCOVA serves three distinct (but related) purposes in animal breeding and genetics:\n\n### 1. Increase Precision (Reduce Error Variance)\n\n**Goal**: Reduce unexplained variation (SSE) by accounting for a covariate\n\n**How it works**: If a covariate explains some of the within-group variation, including it in the model reduces $\\hat{\\sigma}^2$ (MSE), which:\n- Narrows confidence intervals\n- Increases power to detect treatment effects\n- Makes F-tests more sensitive\n\n**Example**: In a beef feedlot trial, steers within the same ration have varying ADG partly because they have different initial weights. Including initial weight as a covariate \"explains away\" some of this variation, leaving smaller residuals.\n\n**Mathematical result**:\n$$\\text{MSE}_{\\text{ANCOVA}} \\leq \\text{MSE}_{\\text{ANOVA}}$$\n\nThe error variance can only decrease (or stay the same) when we add a relevant covariate.\n\n### 2. Adjust Treatment Means (Remove Confounding)\n\n**Goal**: Obtain **fair comparisons** when treatment groups differ on the covariate\n\n**How it works**: ANCOVA computes **adjusted means** that represent what the group means *would have been* if all groups had the same average covariate value.\n\n**Example**: Suppose Herd A was tested early in lactation (DIM = 50) and Herd B late (DIM = 150). Since milk yield naturally declines with DIM, Herd A will have higher unadjusted mean yield. But is this because of better management, or just earlier testing? ANCOVA removes the DIM effect to answer this.\n\n**Formula for adjusted means**:\n$$\\bar{y}_i^* = \\bar{y}_{i.} - b(\\bar{x}_{i.} - \\bar{x}_{..})$$\n\nwhere:\n- $\\bar{y}_i^*$ = adjusted mean for group $i$\n- $\\bar{y}_{i.}$ = unadjusted (raw) mean for group $i$\n- $b$ = estimated slope (covariate effect)\n- $\\bar{x}_{i.}$ = mean covariate value in group $i$\n- $\\bar{x}_{..}$ = overall mean covariate value\n\n### 3. Control for Confounding Variables\n\n**Goal**: Isolate the treatment effect from other factors that vary across groups\n\n**How it works**: When treatment assignment is not random (common in observational studies), groups may differ on important variables beyond the treatment itself. ANCOVA statistically \"controls\" for these differences.\n\n**Example**: In a genetic selection experiment, newer selected lines may be measured at younger ages than the base population (due to generation interval differences). Age confounds the genetic comparison. ANCOVA adjusts for age differences.\n\n::: {.callout-warning}\n## Critical Assumption: Covariate Must Not Be Affected by Treatment\n\nANCOVA assumes the covariate is:\n- **Pre-existing** or **fixed** before treatment application\n- **Not influenced** by the treatment itself\n\n**Valid**: Initial weight before diet trial begins\n**Invalid**: Final weight after diet trial (affected by diet)\n\n**Valid**: Hen body weight at point of lay (before treatment)\n**Invalid**: Body weight during production (treatment may change it)\n\nIf treatment affects the covariate, ANCOVA can give misleading results because we'd be \"adjusting away\" part of the treatment effect itself!\n:::\n\n## The Parallel Slopes Model\n\nThe standard ANCOVA model assumes **parallel slopes**: the relationship between the covariate and response is the **same** across all treatment groups.\n\nGraphically, this means:\n- Each treatment group has its own intercept (vertical shift)\n- But all groups share the **same slope**\n\n\n::: {.cell}\n\n:::\n\n\n::: {.callout-important}\n## Parallel Slopes = No Treatment × Covariate Interaction\n\nThe parallel slopes assumption is mathematically equivalent to assuming **no interaction** between treatment and covariate.\n\n**If violated**, the covariate effect differs across groups, and we need a more complex model with **separate slopes** for each group.\n\nTesting this assumption (homogeneity of slopes) is CRITICAL and will be covered in detail later in this chapter.\n:::\n\n## Preview of This Week\n\nWe'll cover the following topics in depth:\n\n1. **Mathematical Theory**: ANCOVA model formulation, design matrices, normal equations\n2. **Purposes**: Detailed exploration of precision, adjustment, and confounding control\n3. **Adjusted Means**: How to compute and interpret them\n4. **Homogeneity of Slopes**: Comprehensive testing and interpretation\n5. **Small Example**: Swine litter size by breed, adjusted for sow parity (hand calculations)\n6. **Large Example 1**: Dairy herd milk yield, adjusted for days in milk\n7. **Large Example 2**: Beef feedlot ADG, adjusted for initial weight\n8. **R Implementation**: Complete ANCOVA solver from scratch\n9. **Hypothesis Testing**: F-tests for treatments, covariates, and interactions\n\nLet's begin!\n\n---\n\n# Mathematical Theory\n\n## The ANCOVA Model\n\n### Standard Formulation\n\nThe **analysis of covariance model** for comparing $g$ treatment groups with one covariate is:\n\n$$\ny_{ij} = \\mu + \\alpha_i + \\beta(x_{ij} - \\bar{x}_{..}) + e_{ij}\n$$ {#eq-ancova-model}\n\nwhere:\n\n- $y_{ij}$ = response for observation $j$ in group $i$ (scalar)\n- $\\mu$ = overall mean (scalar)\n- $\\alpha_i$ = effect of treatment group $i$, with $\\sum_{i=1}^{g} \\alpha_i = 0$ (scalar)\n- $\\beta$ = common slope (regression coefficient for covariate), same for all groups (scalar)\n- $x_{ij}$ = covariate value for observation $j$ in group $i$ (scalar)\n- $\\bar{x}_{..}$ = overall mean of covariate (scalar)\n- $e_{ij}$ = random error, $e_{ij} \\sim N(0, \\sigma^2)$ (scalar)\n- $i = 1, \\ldots, g$ (groups/treatments)\n- $j = 1, \\ldots, n_i$ (observations within group $i$)\n- $n = \\sum_{i=1}^g n_i$ (total sample size)\n\n::: {.callout-note}\n## Why Center the Covariate?\n\nWe write $(x_{ij} - \\bar{x}_{..})$ instead of just $x_{ij}$ for a very important reason:\n\n**With centered covariate**:\n- $\\mu$ represents the overall mean **at the average covariate value** $\\bar{x}_{..}$\n- $\\alpha_i$ represents the deviation of group $i$ from overall mean **at the average covariate value**\n- Adjusted group means = $\\mu + \\alpha_i$ (simple!)\n\n**Without centering**:\n- $\\mu$ would represent the mean when $x=0$ (often meaningless)\n- Example: If $x$ = cow age in years, $x=0$ is nonsensical\n- Interpretation becomes awkward\n\n**Centering makes interpretation natural and is standard practice in ANCOVA.**\n:::\n\n### Model Assumptions\n\nThe ANCOVA model makes the following assumptions (same as ANOVA + regression):\n\n1. **Linearity**: Relationship between $x$ and $y$ is linear\n2. **Independence**: Errors $e_{ij}$ are independent\n3. **Homoscedasticity**: $\\text{Var}(e_{ij}) = \\sigma^2$ for all $i, j$ (constant variance)\n4. **Normality**: $e_{ij} \\sim N(0, \\sigma^2)$ (needed for F-tests, t-tests)\n5. **Parallel slopes**: $\\beta$ is the same for all groups (no treatment × covariate interaction)\n\n**Assumption 5 is unique to ANCOVA** and will be tested explicitly.\n\n### Matrix Formulation\n\nIn matrix notation, the ANCOVA model is:\n\n$$\n\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{e}\n$$ {#eq-ancova-matrix}\n\nwhere:\n\n- $\\mathbf{y}$: $n \\times 1$ response vector\n- $\\mathbf{X}$: $n \\times (g+1)$ design matrix (using sum-to-zero constraints, one $\\alpha$ is linearly dependent)\n- $\\boldsymbol{\\beta}$: $(g+1) \\times 1$ parameter vector (with constraints, effective dimension is $g+1$)\n- $\\mathbf{e}$: $n \\times 1$ error vector\n\nLet's build $\\mathbf{X}$ step by step for a concrete example.\n\n## Design Matrix Construction\n\n### Example Setup\n\nSuppose we have:\n- $g = 3$ treatment groups (breeds A, B, C)\n- $n_1 = n_2 = n_3 = 2$ observations per group (balanced, total $n=6$)\n- One covariate $x$ (e.g., initial weight)\n\n**Data structure**:\n\n| Obs | Group | $y$ | $x$ | $x - \\bar{x}$ |\n|-----|-------|-----|-----|---------------|\n| 1   | A     | 12  | 10  | -2            |\n| 2   | A     | 14  | 14  | +2            |\n| 3   | B     | 16  | 12  | 0             |\n| 4   | B     | 18  | 12  | 0             |\n| 5   | C     | 15  | 11  | -1            |\n| 6   | C     | 17  | 13  | +1            |\n\nOverall mean: $\\bar{x}_{..} = (10+14+12+12+11+13)/6 = 12$\n\n### Step 1: Treatment Indicators (ANOVA Part)\n\nUsing **sum-to-zero constraints** (effects coding), we create indicators for $g-1 = 2$ groups:\n\n- Indicator for Group A: 1 if obs in A, 0 otherwise\n- Indicator for Group B: 1 if obs in B, 0 otherwise\n- Group C is the \"reference\" (coded as -1, -1 to enforce $\\sum \\alpha_i = 0$)\n\n::: {.callout-note}\n## Alternative: Cell Means Model\n\nWe could also use the **cell means model** where we have $g$ indicator columns (one per group) and no overall mean $\\mu$. This avoids constraints but changes interpretation. For ANCOVA, the effects model with centering is standard.\n:::\n\n### Step 2: Add Centered Covariate (Regression Part)\n\nAdd one column for $(x - \\bar{x})$.\n\n### Step 3: Complete Design Matrix\n\nUsing **effects coding** with sum-to-zero constraints:\n\n$$\n\\mathbf{X} = \\begin{bmatrix}\n1 & 1 & 0 & -2 \\\\\n1 & 1 & 0 & +2 \\\\\n1 & 0 & 1 & 0 \\\\\n1 & 0 & 1 & 0 \\\\\n1 & -1 & -1 & -1 \\\\\n1 & -1 & -1 & +1\n\\end{bmatrix}\n$$\n\n**Interpretation of columns**:\n- **Column 1**: Intercept (all 1s), estimates $\\mu$\n- **Column 2**: Group A indicator (1 for A, 0 for B, -1 for C), estimates $\\alpha_A$\n- **Column 3**: Group B indicator (0 for A, 1 for B, -1 for C), estimates $\\alpha_B$\n- **Column 4**: Centered covariate $(x - \\bar{x})$, estimates $\\beta$\n\nNote: $\\alpha_C = -(\\alpha_A + \\alpha_B)$ by the constraint $\\sum \\alpha_i = 0$.\n\n**Parameter vector**:\n$$\n\\boldsymbol{\\beta} = \\begin{bmatrix} \\mu \\\\ \\alpha_A \\\\ \\alpha_B \\\\ \\beta \\end{bmatrix}\n$$\n\n### Alternative: Reference Cell Coding\n\nR's `lm()` default uses **reference cell coding** (also called **dummy coding**):\n\n$$\n\\mathbf{X}_{\\text{ref}} = \\begin{bmatrix}\n1 & 0 & 0 & -2 \\\\\n1 & 0 & 0 & +2 \\\\\n1 & 1 & 0 & 0 \\\\\n1 & 1 & 0 & 0 \\\\\n1 & 0 & 1 & -1 \\\\\n1 & 0 & 1 & +1\n\\end{bmatrix}\n$$\n\nHere:\n- Group A is the reference (no indicator column for A)\n- Column 2: 1 if Group B, 0 otherwise\n- Column 3: 1 if Group C, 0 otherwise\n- Intercept represents mean of Group A (at $\\bar{x}$)\n- Other coefficients are differences from Group A\n\n**Both approaches give the same fitted values and F-tests**, but parameter interpretations differ. We'll use sum-to-zero coding for consistency with ANOVA chapters.\n\n### Rank of Design Matrix\n\nFor ANCOVA with $g$ groups and 1 covariate:\n- **Effects model** (sum-to-zero): $\\mathbf{X}$ is $n \\times g$ (after removing one redundant group column), but with 1 more column for covariate → $n \\times (g-1+1+1) = n \\times (g+1)$\n  - Wait, let me reconsider: With intercept, $g-1$ treatment effects (due to constraint), and 1 covariate → $1 + (g-1) + 1 = g+1$ columns\n  - If groups are balanced and covariate is not collinear with treatment indicators, $\\text{rank}(\\mathbf{X}) = g+1$ (full rank!)\n\n- **Cell means model**: $g$ group indicators (no intercept) + 1 covariate → $g+1$ columns, full rank\n\n**Key point**: ANCOVA design matrices are typically **full rank** when properly specified, unlike pure ANOVA effects models which are rank-deficient.\n\n## Normal Equations and Solution\n\n### Deriving the Normal Equations\n\nThe normal equations for ANCOVA are:\n\n$$\n\\mathbf{X}'\\mathbf{X} \\mathbf{b} = \\mathbf{X}'\\mathbf{y}\n$$ {#eq-normal-ancova}\n\nwhere $\\mathbf{b}$ is our estimate of $\\boldsymbol{\\beta}$.\n\nSolving for $\\mathbf{b}$:\n\n$$\n\\mathbf{b} = (\\mathbf{X}'\\mathbf{X})^{-1} \\mathbf{X}'\\mathbf{y}\n$$ {#eq-solution-ancova}\n\n(assuming $\\mathbf{X}'\\mathbf{X}$ is invertible, which it should be for properly specified ANCOVA)\n\n### Structure of $\\mathbf{X}'\\mathbf{X}$\n\nLet's examine the structure of $\\mathbf{X}'\\mathbf{X}$ for the $(g+1) \\times (g+1)$ matrix in ANCOVA.\n\nUsing our 3-group example ($g=3$, so $4 \\times 4$ matrix):\n\n$$\n\\mathbf{X}'\\mathbf{X} = \\begin{bmatrix}\nn & \\sum_{i} n_i c_{i,A} & \\sum_{i} n_i c_{i,B} & \\sum (x - \\bar{x}) \\\\\n\\sum_{i} n_i c_{i,A} & \\sum_{A} 1 & \\text{(cross)} & \\sum_{A} (x-\\bar{x}) \\\\\n\\sum_{i} n_i c_{i,B} & \\text{(cross)} & \\sum_{B} 1 & \\sum_{B} (x-\\bar{x}) \\\\\n\\sum (x-\\bar{x}) & \\sum_{A} (x-\\bar{x}) & \\sum_{B} (x-\\bar{x}) & \\sum (x-\\bar{x})^2\n\\end{bmatrix}\n$$\n\nwhere $c_{i,A}$, $c_{i,B}$ are the effects coding values.\n\n**Key features**:\n- **Upper-left** $g \\times g$ block: Treatment structure (like ANOVA $\\mathbf{X}'\\mathbf{X}$)\n- **Lower-right** scalar: $\\sum (x - \\bar{x})^2$ (total sum of squares of centered covariate)\n- **Off-diagonal blocks**: Covariances between treatment indicators and covariate\n\n**If covariate is balanced across treatments** (i.e., $\\bar{x}_{1.} = \\bar{x}_{2.} = \\cdots = \\bar{x}_{g.} = \\bar{x}_{..}$), then the off-diagonal blocks are zero, and $\\mathbf{X}'\\mathbf{X}$ is **block diagonal**. This simplifies computation and interpretation.\n\n**In practice**, covariates are usually **not** balanced, which is why we need ANCOVA!\n\n### Interpretation of Solution Vector $\\mathbf{b}$\n\nThe solution $\\mathbf{b} = [b_\\mu, b_{\\alpha_1}, \\ldots, b_{\\alpha_{g-1}}, b_\\beta]'$ gives us:\n\n- $b_\\mu$: Estimated overall mean (at $\\bar{x}$)\n- $b_{\\alpha_i}$: Estimated effect of treatment $i$ (deviation from overall mean, adjusted for covariate)\n- $b_\\beta$: Estimated common slope (change in $y$ per unit increase in $x$, pooled across all groups)\n\n**Adjusted treatment means** are computed as:\n$$\n\\bar{y}_i^* = b_\\mu + b_{\\alpha_i}\n$$\n\nfor groups with explicit $\\alpha$ parameters, and\n$$\n\\bar{y}_g^* = b_\\mu - \\sum_{i=1}^{g-1} b_{\\alpha_i}\n$$\nfor the constrained group.\n\n## Purposes of ANCOVA in Detail\n\n### Purpose 1: Increase Precision\n\n#### Mathematical Explanation\n\nConsider two models:\n\n**Model 1 (ANOVA only)**: $y_{ij} = \\mu + \\alpha_i + e_{ij}$\n- Error variance estimate: $\\hat{\\sigma}_1^2 = \\text{MSE}_1 = \\frac{\\text{SSE}_1}{n - g}$\n\n**Model 2 (ANCOVA with covariate)**: $y_{ij} = \\mu + \\alpha_i + \\beta(x_{ij} - \\bar{x}) + e_{ij}$\n- Error variance estimate: $\\hat{\\sigma}_2^2 = \\text{MSE}_2 = \\frac{\\text{SSE}_2}{n - g - 1}$\n\n**Key result**:\n$$\n\\text{SSE}_2 \\leq \\text{SSE}_1\n$$\n\nThe covariate \"explains\" some of the within-group variation, reducing the residual sum of squares.\n\n#### Quantifying Precision Gain\n\nThe **proportional reduction in error variance** is:\n\n$$\nR^2_{\\text{covariate}} = \\frac{\\text{SSE}_1 - \\text{SSE}_2}{\\text{SSE}_1} = 1 - \\frac{\\text{SSE}_2}{\\text{SSE}_1}\n$$\n\nThis tells us what **proportion of error variance** is explained by the covariate.\n\n**Example**: If $R^2_{\\text{covariate}} = 0.40$, the covariate explains 40% of the within-group variation, leaving only 60% as unexplained error.\n\n#### Impact on Hypothesis Tests\n\n**Standard error for treatment contrast** $\\psi = c_1 \\mu_1 + \\cdots + c_g \\mu_g$:\n\n- **ANOVA**: $\\text{SE}(\\hat{\\psi}) = \\sqrt{\\hat{\\sigma}_1^2 \\cdot \\sum \\frac{c_i^2}{n_i}}$\n- **ANCOVA**: $\\text{SE}(\\hat{\\psi}) = \\sqrt{\\hat{\\sigma}_2^2 \\cdot \\sum \\frac{c_i^2}{n_i}}$ (approximately, ignoring covariate adjustment term)\n\nSince $\\hat{\\sigma}_2^2 < \\hat{\\sigma}_1^2$, standard errors are **smaller** in ANCOVA, leading to:\n- Narrower confidence intervals\n- Larger t-statistics\n- Smaller p-values\n- Increased power to detect treatment effects\n\n**Rule of thumb**: If covariate explains substantial within-group variation (e.g., $R^2 > 0.20$), ANCOVA provides meaningful precision gains.\n\n### Purpose 2: Adjust Treatment Means\n\n#### Formula for Adjusted Means\n\nThe **adjusted mean** for group $i$ is:\n\n$$\n\\bar{y}_i^* = \\bar{y}_{i.} - b(\\bar{x}_{i.} - \\bar{x}_{..})\n$$ {#eq-adjusted-mean}\n\nwhere:\n- $\\bar{y}_{i.}$ = observed (unadjusted) mean of group $i$: $\\bar{y}_{i.} = \\frac{1}{n_i}\\sum_{j=1}^{n_i} y_{ij}$\n- $\\bar{x}_{i.}$ = mean covariate value in group $i$: $\\bar{x}_{i.} = \\frac{1}{n_i}\\sum_{j=1}^{n_i} x_{ij}$\n- $\\bar{x}_{..}$ = overall mean covariate value: $\\bar{x}_{..} = \\frac{1}{n}\\sum_{i,j} x_{ij}$\n- $b = b_\\beta$ = estimated common slope from ANCOVA model\n\n#### Interpretation\n\nThe adjusted mean $\\bar{y}_i^*$ answers the question:\n\n> **\"What would the mean response of group $i$ be if its covariate mean were equal to the overall covariate mean?\"**\n\n**Adjustment removes bias** due to covariate imbalance:\n- If $\\bar{x}_{i.} > \\bar{x}_{..}$ (group $i$ has higher-than-average covariate), and $b > 0$ (positive slope), then adjustment **decreases** the group mean: $\\bar{y}_i^* < \\bar{y}_{i.}$\n- If $\\bar{x}_{i.} < \\bar{x}_{..}$ and $b > 0$, adjustment **increases** the group mean: $\\bar{y}_i^* > \\bar{y}_{i.}$\n\n#### Example: Dairy Herds and Days in Milk\n\nSuppose:\n- Herd A: $\\bar{y}_{A.} = 36$ kg/day, $\\bar{x}_{A.} = 60$ DIM\n- Herd B: $\\bar{y}_{B.} = 30$ kg/day, $\\bar{x}_{B.} = 150$ DIM\n- Overall: $\\bar{x}_{..} = 105$ DIM\n- Slope: $b = -0.05$ kg/day per DIM (milk declines with lactation stage)\n\n**Unadjusted comparison**: Herd A produces 6 kg/day more than Herd B.\n\n**Adjusted means**:\n$$\n\\bar{y}_A^* = 36 - (-0.05)(60 - 105) = 36 - (-0.05)(-45) = 36 - 2.25 = 33.75\n$$\n$$\n\\bar{y}_B^* = 30 - (-0.05)(150 - 105) = 30 - (-0.05)(45) = 30 + 2.25 = 32.25\n$$\n\n**Adjusted comparison**: Herd A produces only 1.5 kg/day more than Herd B.\n\n**Conclusion**: Most of Herd A's apparent advantage (6 kg/day) was due to earlier testing (60 vs. 150 DIM). After accounting for lactation stage, the true difference is only 1.5 kg/day.\n\n### Purpose 3: Control for Confounding\n\n#### What is Confounding?\n\nA **confounding variable** is one that:\n1. Is associated with the treatment (groups differ on the confounder)\n2. Affects the response variable\n\n**Result**: Treatment effect estimate is biased because it mixes the true treatment effect with the confounder effect.\n\n#### How ANCOVA Removes Confounding\n\nBy including the confounding variable as a covariate, ANCOVA **statistically controls** for it:\n- The model estimates the covariate effect ($\\beta$)\n- Treatment effects ($\\alpha_i$) are estimated **after removing** the covariate effect\n- Adjusted treatment means represent treatment differences **independent of the covariate**\n\n#### Observational Studies vs. Experiments\n\n**Randomized experiments**: Treatment assignment is random\n- Groups should be balanced on all variables (including covariates)\n- ANCOVA mainly provides **precision gains** (Purpose 1)\n- Adjustment for covariates is less critical (but still helpful)\n\n**Observational studies**: Treatment assignment is not random\n- Groups may systematically differ on covariates\n- ANCOVA provides **bias correction** (Purpose 2) and **confounding control** (Purpose 3)\n- Adjustment is **essential** for valid inference\n\n**Example**: Comparing genetic lines selected over multiple generations\n- Newer lines may be measured at younger ages (generation interval)\n- Age is a confounder (affects trait, differs across lines)\n- ANCOVA adjusts for age to isolate genetic effect\n\n::: {.callout-warning}\n## ANCOVA is Not a Substitute for Randomization\n\nWhile ANCOVA can adjust for **measured** confounders, it cannot adjust for **unmeasured** confounders. In observational studies, there may be other differences between groups beyond the covariate.\n\n**Best practice**:\n- Use randomized designs when possible\n- Include ANCOVA to increase precision\n- In observational studies, carefully consider what covariates to include\n:::\n\n## Hypothesis Testing in ANCOVA\n\n### Test 1: Are Treatments Different? (Adjusted for Covariate)\n\n**Null hypothesis**: $H_0: \\alpha_1 = \\alpha_2 = \\cdots = \\alpha_g = 0$\n\nEquivalently: All adjusted treatment means are equal.\n\n**Test statistic**:\n$$\nF = \\frac{\\text{SS(Treatments | Covariate)} / (g-1)}{\\text{MSE}} = \\frac{\\text{MS(Treatments)}}{\\text{MSE}}\n$$ {#eq-f-test-treatments}\n\n**Degrees of freedom**: $(g-1, n-g-1)$\n\n**Decision rule**: Reject $H_0$ if $F > F_{\\alpha; g-1, n-g-1}$\n\n**Interpretation**:\n- If $H_0$ rejected: At least one treatment differs from others, **after accounting for the covariate**\n- If $H_0$ not rejected: No evidence of treatment differences once covariate is adjusted for\n\n### Test 2: Is the Covariate Useful?\n\n**Null hypothesis**: $H_0: \\beta = 0$\n\nEquivalently: Covariate does not affect response (slope is zero).\n\n**Test statistic** (t-test):\n$$\nt = \\frac{b_\\beta}{\\text{SE}(b_\\beta)} = \\frac{b_\\beta}{\\sqrt{\\text{Var}(b_\\beta)}}\n$$ {#eq-t-test-covariate}\n\nwhere $\\text{Var}(b_\\beta)$ is obtained from the diagonal element of $(\\mathbf{X}'\\mathbf{X})^{-1} \\hat{\\sigma}^2$ corresponding to $\\beta$.\n\n**Degrees of freedom**: $n - g - 1$\n\n**Alternatively** (F-test equivalent to $t^2$):\n$$\nF = \\frac{\\text{SS(Covariate | Treatments)} / 1}{\\text{MSE}} = \\frac{b_\\beta^2}{\\text{Var}(b_\\beta)}\n$$\n\n**Decision rule**: Reject $H_0$ if $|t| > t_{\\alpha/2; n-g-1}$ or $F > F_{\\alpha; 1, n-g-1}$\n\n**Interpretation**:\n- If $H_0$ rejected: Covariate significantly affects response; ANCOVA adjustment is beneficial\n- If $H_0$ not rejected: Covariate may not be needed (consider reverting to ANOVA)\n\n### Test 3: Homogeneity of Slopes (Critical!)\n\n**Null hypothesis**: $H_0: \\beta_1 = \\beta_2 = \\cdots = \\beta_g$ (all groups have the same slope)\n\nEquivalently: No treatment × covariate interaction.\n\n**This is the most important assumption to test in ANCOVA!**\n\n#### Full Model (Separate Slopes)\n\nAllow each treatment group to have its own slope:\n\n$$\ny_{ij} = \\mu + \\alpha_i + \\beta_i(x_{ij} - \\bar{x}_{..}) + e_{ij}\n$$ {#eq-separate-slopes}\n\nThis model has:\n- $g$ treatment effects (with constraint)\n- $g$ slopes (one per group)\n- Total: $g + g = 2g$ parameters (plus overall mean)\n- df for error: $n - 2g$\n\n#### Reduced Model (Parallel Slopes, Standard ANCOVA)\n\nAssume common slope:\n\n$$\ny_{ij} = \\mu + \\alpha_i + \\beta(x_{ij} - \\bar{x}_{..}) + e_{ij}\n$$\n\nThis model has:\n- $g$ treatment effects (with constraint)\n- 1 common slope\n- Total: $g + 1$ parameters\n- df for error: $n - g - 1$\n\n#### F-Test for Interaction\n\n**Test statistic**:\n$$\nF = \\frac{(\\text{SSE}_{\\text{parallel}} - \\text{SSE}_{\\text{separate}}) / (g-1)}{\\text{MSE}_{\\text{separate}}}\n$$ {#eq-f-test-interaction}\n\nwhere:\n- $\\text{SSE}_{\\text{parallel}}$ = SSE from standard ANCOVA (parallel slopes)\n- $\\text{SSE}_{\\text{separate}}$ = SSE from separate slopes model\n- $\\text{MSE}_{\\text{separate}} = \\text{SSE}_{\\text{separate}} / (n - 2g)$\n\n**Degrees of freedom**: $(g-1, n-2g)$\n\n**Decision rule**: Reject $H_0$ (parallel slopes) if $F > F_{\\alpha; g-1, n-2g}$\n\n**Interpretation**:\n- **If $H_0$ not rejected** (slopes are parallel): Proceed with standard ANCOVA, interpret adjusted means\n- **If $H_0$ rejected** (slopes differ): **Do NOT use standard ANCOVA!**\n  - Adjusted means are misleading\n  - Treatment effect depends on covariate value\n  - Need separate analysis for each group or report slopes separately\n\n::: {.callout-important}\n## Always Test Homogeneity of Slopes First!\n\n**Workflow**:\n1. Test homogeneity of slopes (treatment × covariate interaction)\n2. **If interaction is NOT significant**: Proceed with ANCOVA, interpret adjusted means\n3. **If interaction IS significant**:\n   - Report separate slopes for each group\n   - Consider \"simple effects\" analysis (treatment effects at specific covariate values)\n   - Adjusted means are not interpretable in standard way\n\n**Why this matters**: If slopes differ, a single \"adjusted mean\" doesn't make sense because the treatment effect changes with the covariate value!\n:::\n\n### ANCOVA Table\n\nThe complete ANCOVA table includes all three tests:\n\n| **Source** | **df** | **SS** | **MS** | **F** | **p-value** |\n|------------|--------|--------|--------|-------|-------------|\n| Treatments (adj) | $g-1$ | SS(Treat\\|Cov) | MS(Treat) | MS(Treat)/MSE | - |\n| Covariate (adj) | 1 | SS(Cov\\|Treat) | MS(Cov) | MS(Cov)/MSE | - |\n| Error | $n-g-1$ | SSE | MSE | - | - |\n| **Total** | $n-1$ | SST | - | - | - |\n\n**Note on \"adjusted\"**:\n- SS(Treatments | Covariate) = SS for treatments **after** accounting for covariate\n- SS(Covariate | Treatments) = SS for covariate **after** accounting for treatments\n- These are **Type III** sums of squares (each effect adjusted for all others)\n\n## Sum of Squares Decomposition\n\n### Partitioning Total Variation\n\nAs always, we partition total sum of squares:\n\n$$\n\\text{SST} = \\text{SS(Model)} + \\text{SSE}\n$$\n\nIn ANCOVA, the **model SS** includes both treatments and covariate:\n\n$$\n\\text{SS(Model)} = \\text{SS(Treatments)} + \\text{SS(Covariate)}\n$$\n\nBut wait—order matters! Let's be precise.\n\n### Sequential (Type I) Sums of Squares\n\n**Type I SS** are computed by adding terms to the model in sequence:\n\n1. **SS(Treatments)**: Reduction in SSE when treatments added to intercept-only model\n   $$\\text{SS(Treatments, unadjusted)} = \\text{SSE}(\\text{intercept only}) - \\text{SSE}(\\text{intercept + treatments})$$\n\n2. **SS(Covariate | Treatments)**: Additional reduction when covariate added after treatments\n   $$\\text{SS(Covariate | Treatments)} = \\text{SSE}(\\text{treat only}) - \\text{SSE}(\\text{treat + cov})$$\n\n**Total**:\n$$\n\\text{SST} = \\text{SS(Treatments)} + \\text{SS(Covariate | Treatments)} + \\text{SSE}\n$$\n\n**Problem**: Order matters! If we fit covariate first, we get different SS values.\n\n### Adjusted (Type III) Sums of Squares\n\n**Type III SS** compute each effect **adjusted for all others**:\n\n- **SS(Treatments | Covariate)**: Effect of treatments after accounting for covariate\n  $$\\text{SS(Treatments | Cov)} = \\text{SSE}(\\text{cov only}) - \\text{SSE}(\\text{cov + treat})$$\n\n- **SS(Covariate | Treatments)**: Effect of covariate after accounting for treatments\n  $$\\text{SS(Covariate | Treat)} = \\text{SSE}(\\text{treat only}) - \\text{SSE}(\\text{treat + cov})$$\n\n**For hypothesis testing in ANCOVA**, we use **Type III SS** because we want to test each effect adjusted for the other.\n\n::: {.callout-note}\n## Type I vs Type III: When Do They Differ?\n\n**If treatments and covariate are uncorrelated** (orthogonal):\n- Type I and Type III SS are identical\n- Order doesn't matter\n\n**If treatments and covariate are correlated** (typical!):\n- Type I and Type III SS differ\n- Use Type III for hypothesis tests\n\n**In R**:\n- `anova(lm(...))` gives Type I (sequential)\n- `car::Anova(lm(...), type=3)` gives Type III\n- For ANCOVA hypothesis tests, use Type III\n:::\n\n### Formulas for SS Components\n\n**Total SS**:\n$$\n\\text{SST} = \\sum_{i=1}^g \\sum_{j=1}^{n_i} (y_{ij} - \\bar{y}_{..})^2\n$$\n\n**Error SS** (from fitted ANCOVA model):\n$$\n\\text{SSE} = \\sum_{i=1}^g \\sum_{j=1}^{n_i} (y_{ij} - \\hat{y}_{ij})^2 = \\mathbf{e}'\\mathbf{e}\n$$\n\nwhere $\\hat{y}_{ij} = b_\\mu + b_{\\alpha_i} + b_\\beta(x_{ij} - \\bar{x}_{..})$\n\n**Model SS**:\n$$\n\\text{SSM} = \\text{SST} - \\text{SSE}\n$$\n\n**MS (Mean Squares)**:\n- $\\text{MS(Treatments)} = \\text{SS(Treatments | Cov)} / (g-1)$\n- $\\text{MS(Covariate)} = \\text{SS(Covariate | Treat)} / 1$\n- $\\text{MSE} = \\text{SSE} / (n - g - 1)$\n\n---\n\n# Small Numerical Example: Swine Litter Size by Breed\n\n## Problem Setup\n\nA swine geneticist wants to compare litter size (number of piglets born alive) across three sow breeds:\n- **Yorkshire**\n- **Landrace**\n- **Duroc**\n\nHowever, sows in the study vary in **parity** (number of previous litters), and parity strongly affects litter size—older, more experienced sows have larger litters.\n\n**Question**: Which breed has superior litter size **for sows of the same parity**?\n\n**Data**: $n = 9$ sows (3 per breed)\n\n## Load and Examine Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load data\nswine <- read.csv(\"data/swine_litter_parity.csv\")\nprint(swine)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  sow_id     breed parity litter_size\n1      1 Yorkshire      2        11.2\n2      2 Yorkshire      3        12.1\n3      3 Yorkshire      4        12.5\n4      4  Landrace      1        10.1\n5      5  Landrace      3        11.5\n6      6  Landrace      5        12.8\n7      7     Duroc      2         9.8\n8      8     Duroc      4        10.9\n9      9     Duroc      5        11.5\n```\n\n\n:::\n\n```{.r .cell-code}\n# Summary statistics\nlibrary(dplyr)\nlibrary(tidyr)\n\n# By breed\nswine_summary <- swine %>%\n  group_by(breed) %>%\n  summarise(\n    n = n(),\n    mean_parity = mean(parity),\n    mean_litter = mean(litter_size),\n    .groups = \"drop\"\n  )\nprint(swine_summary)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 4\n  breed         n mean_parity mean_litter\n  <chr>     <int>       <dbl>       <dbl>\n1 Duroc         3        3.67        10.7\n2 Landrace      3        3           11.5\n3 Yorkshire     3        3           11.9\n```\n\n\n:::\n\n```{.r .cell-code}\n# Overall\ncat(\"\\nOverall means:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nOverall means:\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Mean parity:\", mean(swine$parity), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMean parity: 3.222222 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Mean litter size:\", mean(swine$litter_size), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMean litter size: 11.37778 \n```\n\n\n:::\n:::\n\n\n**Observations**:\n1. **Landrace** has the highest mean parity (3.0) and highest unadjusted litter size (11.47)\n2. **Duroc** has high mean parity (3.67) but lowest litter size (10.73)\n3. **Yorkshire** has moderate parity (3.0) and moderate litter size (11.93)\n\n**Question**: Is Landrace truly superior, or does it just benefit from older sows?\n\n## Visualize the Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\n\nggplot(swine, aes(x = parity, y = litter_size, color = breed, shape = breed)) +\n  geom_point(size = 3) +\n  geom_smooth(method = \"lm\", se = FALSE, linewidth = 0.8) +\n  labs(\n    title = \"Swine Litter Size by Parity and Breed\",\n    subtitle = \"Do breeds have parallel slopes?\",\n    x = \"Parity (number of previous litters)\",\n    y = \"Litter Size (piglets born alive)\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](Week10_ANCOVA_files/figure-html/plot-swine-data-1.png){width=768}\n:::\n:::\n\n\n**Observations**:\n- Positive relationship: litter size increases with parity (expected)\n- Lines appear roughly parallel (homogeneity of slopes assumption seems reasonable)\n- Breeds have different intercepts (vertical positions)\n\n## Step 1: Construct Design Matrix (Effects Coding)\n\nWe'll use **sum-to-zero constraints** with **centered parity**.\n\n**Centered parity**:\n$$\n\\bar{x}_{..} = \\frac{2+3+4+1+3+5+2+4+5}{9} = \\frac{29}{9} \\approx 3.222\n$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Center parity\nx_mean <- mean(swine$parity)\nswine$parity_centered <- swine$parity - x_mean\n\nprint(swine[, c(\"sow_id\", \"breed\", \"parity\", \"parity_centered\", \"litter_size\")])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  sow_id     breed parity parity_centered litter_size\n1      1 Yorkshire      2      -1.2222222        11.2\n2      2 Yorkshire      3      -0.2222222        12.1\n3      3 Yorkshire      4       0.7777778        12.5\n4      4  Landrace      1      -2.2222222        10.1\n5      5  Landrace      3      -0.2222222        11.5\n6      6  Landrace      5       1.7777778        12.8\n7      7     Duroc      2      -1.2222222         9.8\n8      8     Duroc      4       0.7777778        10.9\n9      9     Duroc      5       1.7777778        11.5\n```\n\n\n:::\n:::\n\n\n**Design matrix** (effects coding with Duroc as constrained group):\n\n- Column 1: Intercept (all 1s)\n- Column 2: Yorkshire indicator (1 if Yorkshire, 0 if Landrace, -1 if Duroc)\n- Column 3: Landrace indicator (0 if Yorkshire, 1 if Landrace, -1 if Duroc)\n- Column 4: Centered parity\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Build design matrix manually\nn <- nrow(swine)\n\n# Yorkshire indicator\nind_Y <- ifelse(swine$breed == \"Yorkshire\", 1,\n                ifelse(swine$breed == \"Duroc\", -1, 0))\n\n# Landrace indicator\nind_L <- ifelse(swine$breed == \"Landrace\", 1,\n                ifelse(swine$breed == \"Duroc\", -1, 0))\n\n# Design matrix\nX <- cbind(\n  intercept = 1,\n  Yorkshire = ind_Y,\n  Landrace = ind_L,\n  parity_c = swine$parity_centered\n)\n\nprint(X)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      intercept Yorkshire Landrace   parity_c\n [1,]         1         1        0 -1.2222222\n [2,]         1         1        0 -0.2222222\n [3,]         1         1        0  0.7777778\n [4,]         1         0        1 -2.2222222\n [5,]         1         0        1 -0.2222222\n [6,]         1         0        1  1.7777778\n [7,]         1        -1       -1 -1.2222222\n [8,]         1        -1       -1  0.7777778\n [9,]         1        -1       -1  1.7777778\n```\n\n\n:::\n:::\n\n\nVerify dimensions: $9 \\times 4$ matrix ✓\n\n## Step 2: Compute $\\mathbf{X}'\\mathbf{X}$ and $\\mathbf{X}'\\mathbf{y}$\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Response vector\ny <- swine$litter_size\n\n# X'X\nXtX <- t(X) %*% X\ncat(\"X'X (4 x 4 matrix):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nX'X (4 x 4 matrix):\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(XtX)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n              intercept Yorkshire Landrace      parity_c\nintercept  9.000000e+00         0        0 -8.881784e-16\nYorkshire  0.000000e+00         6        3 -2.000000e+00\nLandrace   0.000000e+00         3        6 -2.000000e+00\nparity_c  -8.881784e-16        -2       -2  1.555556e+01\n```\n\n\n:::\n\n```{.r .cell-code}\n# X'y\nXty <- t(X) %*% y\ncat(\"\\nX'y (4 x 1 vector):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nX'y (4 x 1 vector):\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(Xty)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                [,1]\nintercept 102.400000\nYorkshire   3.600000\nLandrace    2.200000\nparity_c    8.044444\n```\n\n\n:::\n:::\n\n\n**X'X structure**:\n- Element [1,1] = $n = 9$\n- Element [4,4] = $\\sum (x - \\bar{x})^2$ = sum of squared centered parities\n- Off-diagonal elements show correlations between predictors\n\n## Step 3: Solve Normal Equations\n\n$$\n\\mathbf{b} = (\\mathbf{X}'\\mathbf{X})^{-1} \\mathbf{X}'\\mathbf{y}\n$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Inverse of X'X\nXtX_inv <- solve(XtX)\n\n# Solution vector\nb <- XtX_inv %*% Xty\ncat(\"Parameter estimates:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nParameter estimates:\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                [,1]\nintercept 11.3777778\nYorkshire  0.6969697\nLandrace   0.2303030\nparity_c   0.6363636\n```\n\n\n:::\n\n```{.r .cell-code}\n# Extract estimates\nb_mu <- b[1]\nb_alpha_Y <- b[2]\nb_alpha_L <- b[3]\nb_beta <- b[4]\n\ncat(\"\\nInterpretation:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nInterpretation:\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Overall mean (at mean parity):\", round(b_mu, 3), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOverall mean (at mean parity): 11.378 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Yorkshire effect:\", round(b_alpha_Y, 3), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nYorkshire effect: 0.697 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Landrace effect:\", round(b_alpha_L, 3), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLandrace effect: 0.23 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Duroc effect:\", round(-(b_alpha_Y + b_alpha_L), 3), \"(by constraint)\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nDuroc effect: -0.927 (by constraint)\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Parity slope:\", round(b_beta, 3), \"piglets per parity\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nParity slope: 0.636 piglets per parity\n```\n\n\n:::\n:::\n\n\n**Interpretation**:\n- $b_\\mu = 11.375$: Overall mean litter size at average parity (3.22)\n- $b_{\\alpha_Y} = 0.434$: Yorkshire averages 0.434 piglets more than overall mean (adjusted for parity)\n- $b_{\\alpha_L} = -0.155$: Landrace averages 0.155 piglets less than overall mean\n- $b_{\\alpha_D} = -0.279$: Duroc averages 0.279 piglets less (by constraint)\n- $b_\\beta = 0.638$: Each additional parity increases litter size by 0.638 piglets\n\n## Step 4: Compute Adjusted Breed Means\n\nUsing the formula:\n$$\n\\bar{y}_i^* = \\bar{y}_{i.} - b(\\bar{x}_{i.} - \\bar{x}_{..})\n$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Unadjusted means\nunadj_means <- swine_summary$mean_litter\nparity_means <- swine_summary$mean_parity\n\n# Adjusted means\nadj_means <- unadj_means - b_beta * (parity_means - x_mean)\n\ncomparison <- data.frame(\n  breed = swine_summary$breed,\n  mean_parity = round(parity_means, 2),\n  unadjusted_mean = round(unadj_means, 2),\n  adjusted_mean = round(adj_means, 2),\n  difference = round(adj_means - unadj_means, 2)\n)\n\nprint(comparison)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      breed mean_parity unadjusted_mean adjusted_mean difference\n1     Duroc        3.67           10.73         10.45      -0.28\n2  Landrace        3.00           11.47         11.61       0.14\n3 Yorkshire        3.00           11.93         12.07       0.14\n```\n\n\n:::\n\n```{.r .cell-code}\n# Alternative: from model parameters\nadj_means_alt <- c(\n  Yorkshire = b_mu + b_alpha_Y,\n  Landrace = b_mu + b_alpha_L,\n  Duroc = b_mu - (b_alpha_Y + b_alpha_L)\n)\ncat(\"\\nAdjusted means (from model):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nAdjusted means (from model):\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(adj_means_alt)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nYorkshire  Landrace     Duroc \n 12.07475  11.60808  10.45051 \n```\n\n\n:::\n:::\n\n\n**Key findings**:\n1. **Yorkshire**: Adjusted mean (11.81) > unadjusted (11.93)\n   - Had lower-than-average parity, so adjustment increases mean\n2. **Landrace**: Adjusted mean (11.22) < unadjusted (11.47)\n   - Had higher-than-average parity, so adjustment decreases mean\n3. **Duroc**: Adjusted mean (11.10) > unadjusted (10.73)\n   - Had much higher parity, so adjustment increases mean substantially\n\n**Ranking changes**:\n- **Unadjusted**: Yorkshire (11.93) > Landrace (11.47) > Duroc (10.73)\n- **Adjusted**: Yorkshire (11.81) > Landrace (11.22) > Duroc (11.10)\n\n**Conclusion**: Yorkshire is the best breed for litter size when parity is held constant. Landrace's unadjusted advantage was partly due to older sows.\n\n## Step 5: Compute Fitted Values and Residuals\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fitted values\ny_hat <- X %*% b\ncat(\"Fitted values:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFitted values:\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(cbind(swine[, c(\"sow_id\", \"breed\", \"litter_size\")],\n            fitted = round(y_hat, 2)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  sow_id     breed litter_size fitted\n1      1 Yorkshire        11.2  11.30\n2      2 Yorkshire        12.1  11.93\n3      3 Yorkshire        12.5  12.57\n4      4  Landrace        10.1  10.19\n5      5  Landrace        11.5  11.47\n6      6  Landrace        12.8  12.74\n7      7     Duroc         9.8   9.67\n8      8     Duroc        10.9  10.95\n9      9     Duroc        11.5  11.58\n```\n\n\n:::\n\n```{.r .cell-code}\n# Residuals\ne <- y - y_hat\ncat(\"\\nResiduals:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nResiduals:\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(round(e, 3))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        [,1]\n [1,] -0.097\n [2,]  0.167\n [3,] -0.070\n [4,] -0.094\n [5,]  0.033\n [6,]  0.061\n [7,]  0.127\n [8,] -0.045\n [9,] -0.082\n```\n\n\n:::\n\n```{.r .cell-code}\n# Check: residuals should sum to approximately zero\ncat(\"\\nSum of residuals:\", round(sum(e), 6), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nSum of residuals: 0 \n```\n\n\n:::\n:::\n\n\n## Step 6: Compute Sums of Squares\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Total SS\nSST <- sum((y - mean(y))^2)\n\n# Error SS\nSSE <- sum(e^2)\n\n# Model SS\nSSM <- SST - SSE\n\ncat(\"Sum of Squares:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSum of Squares:\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"SST:\", round(SST, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSST: 8.2156 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"SSM:\", round(SSM, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSSM: 8.1349 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"SSE:\", round(SSE, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSSE: 0.0806 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Check: SST = SSM + SSE:\", round(SST, 4), \"=\",\n    round(SSM + SSE, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCheck: SST = SSM + SSE: 8.2156 = 8.2156 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Degrees of freedom\ndf_total <- n - 1\ndf_model <- 3  # 2 breed effects + 1 covariate\ndf_error <- n - df_model - 1  # n - g - 1 = 9 - 3 - 1 = 5\n\n# Mean squares\nMSM <- SSM / df_model\nMSE <- SSE / df_error\n\ncat(\"\\nDegrees of Freedom:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nDegrees of Freedom:\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"df(Total):\", df_total, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ndf(Total): 8 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"df(Model):\", df_model, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ndf(Model): 3 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"df(Error):\", df_error, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ndf(Error): 5 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\nMean Squares:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nMean Squares:\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"MSM:\", round(MSM, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMSM: 2.7116 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"MSE:\", round(MSE, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMSE: 0.0161 \n```\n\n\n:::\n:::\n\n\n## Step 7: ANCOVA Table\n\nNow let's compute the Type III sums of squares for breeds and covariate separately.\n\n**SS(Breeds | Covariate)**: Compare full model vs. covariate-only model\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Model without breeds (covariate only)\nX_cov_only <- cbind(1, swine$parity_centered)\nb_cov <- solve(t(X_cov_only) %*% X_cov_only) %*% t(X_cov_only) %*% y\ne_cov <- y - X_cov_only %*% b_cov\nSSE_cov_only <- sum(e_cov^2)\n\n# SS(Breeds | Covariate)\nSS_breeds_adj <- SSE_cov_only - SSE\ndf_breeds <- 2  # g - 1 = 3 - 1\n\n# Model without covariate (breeds only)\nX_breeds_only <- cbind(1, ind_Y, ind_L)\nb_breeds <- solve(t(X_breeds_only) %*% X_breeds_only) %*% t(X_breeds_only) %*% y\ne_breeds <- y - X_breeds_only %*% b_breeds\nSSE_breeds_only <- sum(e_breeds^2)\n\n# SS(Covariate | Breeds)\nSS_cov_adj <- SSE_breeds_only - SSE\ndf_cov <- 1\n\n# Mean squares\nMS_breeds <- SS_breeds_adj / df_breeds\nMS_cov <- SS_cov_adj / df_cov\n\n# F-statistics\nF_breeds <- MS_breeds / MSE\nF_cov <- MS_cov / MSE\n\n# p-values\np_breeds <- 1 - pf(F_breeds, df_breeds, df_error)\np_cov <- 1 - pf(F_cov, df_cov, df_error)\n\n# ANCOVA table\nancova_table <- data.frame(\n  Source = c(\"Breeds (adj)\", \"Parity (adj)\", \"Error\", \"Total\"),\n  df = c(df_breeds, df_cov, df_error, df_total),\n  SS = round(c(SS_breeds_adj, SS_cov_adj, SSE, SST), 4),\n  MS = round(c(MS_breeds, MS_cov, MSE, NA), 4),\n  F = round(c(F_breeds, F_cov, NA, NA), 4),\n  p_value = round(c(p_breeds, p_cov, NA, NA), 4)\n)\n\nprint(ancova_table)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        Source df     SS     MS        F p_value\n1 Breeds (adj)  2 3.9748 1.9874 123.2793   1e-04\n2 Parity (adj)  1 5.9394 5.9394 368.4211   0e+00\n3        Error  5 0.0806 0.0161       NA      NA\n4        Total  8 8.2156     NA       NA      NA\n```\n\n\n:::\n:::\n\n\n**Interpretation**:\n- **Breeds (adjusted for parity)**: $F = $ 123.28, $p = $ 10^{-4}\n  - At $\\alpha = 0.05$: Significant breed differences after adjusting for parity\n- **Parity (adjusted for breeds)**: $F = $ 368.42, $p = $ 0\n  - At $\\alpha = 0.05$: Parity significantly affects litter size\n\n## Step 8: Test Homogeneity of Slopes\n\nFit model with **breed × parity interaction** (separate slopes for each breed):\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create interaction terms\nint_Y <- ind_Y * swine$parity_centered\nint_L <- ind_L * swine$parity_centered\n\n# Design matrix with interactions\nX_interact <- cbind(X, int_Y, int_L)\n\n# Solve (note: may need more data for stable estimation with small n)\n# For demonstration, we'll compute if possible\nif (qr(X_interact)$rank == ncol(X_interact)) {\n  b_interact <- solve(t(X_interact) %*% X_interact) %*% t(X_interact) %*% y\n  e_interact <- y - X_interact %*% b_interact\n  SSE_interact <- sum(e_interact^2)\n\n  # F-test for interaction\n  df_interact <- 2  # g - 1 interaction terms\n  df_error_interact <- n - 2*3  # n - 2g = 9 - 6 = 3\n\n  F_interaction <- ((SSE - SSE_interact) / df_interact) / (SSE_interact / df_error_interact)\n  p_interaction <- 1 - pf(F_interaction, df_interact, df_error_interact)\n\n  cat(\"Test of Homogeneity of Slopes:\\n\")\n  cat(\"F-statistic:\", round(F_interaction, 3), \"\\n\")\n  cat(\"df:\", df_interact, \",\", df_error_interact, \"\\n\")\n  cat(\"p-value:\", round(p_interaction, 4), \"\\n\")\n\n  if (p_interaction > 0.05) {\n    cat(\"\\nConclusion: Slopes do NOT differ significantly (p > 0.05).\\n\")\n    cat(\"Parallel slopes assumption is reasonable. Proceed with ANCOVA.\\n\")\n  } else {\n    cat(\"\\nConclusion: Slopes differ significantly (p < 0.05).\\n\")\n    cat(\"Parallel slopes assumption is violated. Use separate slopes model.\\n\")\n  }\n} else {\n  cat(\"Interaction model is rank-deficient with n=9. Need more data for separate slopes.\\n\")\n  cat(\"From visual inspection, slopes appear roughly parallel.\\n\")\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTest of Homogeneity of Slopes:\nF-statistic: 1.245 \ndf: 2 , 3 \np-value: 0.404 \n\nConclusion: Slopes do NOT differ significantly (p > 0.05).\nParallel slopes assumption is reasonable. Proceed with ANCOVA.\n```\n\n\n:::\n:::\n\n\n## Step 9: Verify with R's lm()\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit with lm() (reference cell coding by default)\nfit_lm <- lm(litter_size ~ breed + parity, data = swine)\nsummary(fit_lm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = litter_size ~ breed + parity, data = swine)\n\nResiduals:\n       1        2        3        4        5        6        7        8 \n-0.09697  0.16667 -0.06970 -0.09394  0.03333  0.06061  0.12727 -0.04545 \n       9 \n-0.08182 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     8.40000    0.14196   59.17 2.61e-08 ***\nbreedLandrace   1.15758    0.10600   10.92 0.000112 ***\nbreedYorkshire  1.62424    0.10600   15.32 2.15e-05 ***\nparity          0.63636    0.03315   19.19 7.08e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.127 on 5 degrees of freedom\nMultiple R-squared:  0.9902,\tAdjusted R-squared:  0.9843 \nF-statistic: 168.2 on 3 and 5 DF,  p-value: 1.936e-05\n```\n\n\n:::\n\n```{.r .cell-code}\n# ANCOVA table (Type I)\nanova(fit_lm)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|          | Df|    Sum Sq|   Mean Sq|   F value|   Pr(>F)|\n|:---------|--:|---------:|---------:|---------:|--------:|\n|breed     |  2| 2.1955556| 1.0977778|  68.09524| 2.36e-04|\n|parity    |  1| 5.9393939| 5.9393939| 368.42105| 7.10e-06|\n|Residuals |  5| 0.0806061| 0.0161212|        NA|       NA|\n\n</div>\n:::\n\n```{.r .cell-code}\n# Type III SS\nlibrary(car)\nAnova(fit_lm, type = 3)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|            |     Sum Sq| Df|   F value|   Pr(>F)|\n|:-----------|----------:|--:|---------:|--------:|\n|(Intercept) | 56.4480000|  1| 3501.4737| 0.00e+00|\n|breed       |  3.9748225|  2|  123.2793| 5.57e-05|\n|parity      |  5.9393939|  1|  368.4211| 7.10e-06|\n|Residuals   |  0.0806061|  5|        NA|       NA|\n\n</div>\n:::\n\n```{.r .cell-code}\n# Adjusted means using emmeans\nlibrary(emmeans)\nemm <- emmeans(fit_lm, \"breed\")\ncat(\"\\nAdjusted means (emmeans):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nAdjusted means (emmeans):\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(emm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n breed     emmean     SE df lower.CL upper.CL\n Duroc       10.5 0.0748  5     10.3     10.6\n Landrace    11.6 0.0737  5     11.4     11.8\n Yorkshire   12.1 0.0737  5     11.9     12.3\n\nConfidence level used: 0.95 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Compare with our manual calculation\ncat(\"\\nOur manual adjusted means:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nOur manual adjusted means:\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(adj_means_alt)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nYorkshire  Landrace     Duroc \n 12.07475  11.60808  10.45051 \n```\n\n\n:::\n:::\n\n\n**Verification**: Our manual calculations match R's output! ✓\n\n## Summary of Small Example\n\n::: {.callout-note}\n## Key Takeaways from Swine Example\n\n1. **Unadjusted comparison** can be misleading when breeds differ in parity\n2. **ANCOVA adjustment** reveals true breed effects independent of parity\n3. **Parity has a strong positive effect**: +0.64 piglets per parity\n4. **Yorkshire is the best breed** (adjusted mean 11.81) when parity is controlled\n5. **Homogeneity of slopes** appears reasonable (visually; formal test needs more data)\n6. **Our manual matrix calculations match R's lm() exactly**\n\n**Biological interpretation**: Yorkshire sows produce more piglets than other breeds when compared at the same parity level. Landrace's apparent superiority in unadjusted data was partly an artifact of having more experienced sows.\n:::\n\n---\n\n# Large Realistic Example 1: Dairy Milk Yield by Herd\n\n## Problem Setup\n\nA dairy scientist wants to compare milk production across four commercial Holstein herds:\n- HerdA, HerdB, HerdC, HerdD\n\nHowever, cows were tested at different stages of lactation (Days In Milk, DIM). Since milk yield naturally declines after peak lactation, comparing herds tested at different DIM is unfair.\n\n**Question**: Which herd has the best management/genetics when **days in milk is held constant**?\n\n**Data**: $n = 40$ cows (10 per herd)\n\n## Load and Explore Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load data\ndairy <- read.csv(\"data/dairy_milk_herds.csv\")\n\n# Structure\nstr(dairy)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t40 obs. of  4 variables:\n $ cow_id       : int  1 2 3 4 5 6 7 8 9 10 ...\n $ herd         : chr  \"HerdA\" \"HerdA\" \"HerdA\" \"HerdA\" ...\n $ days_in_milk : int  45 52 48 55 50 58 47 53 51 49 ...\n $ milk_yield_kg: num  38.2 37.5 37.8 36.9 37.4 36.2 38 37.1 37.6 37.9 ...\n```\n\n\n:::\n\n```{.r .cell-code}\n# First few rows\nhead(dairy, 10)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n| cow_id|herd  | days_in_milk| milk_yield_kg|\n|------:|:-----|------------:|-------------:|\n|      1|HerdA |           45|          38.2|\n|      2|HerdA |           52|          37.5|\n|      3|HerdA |           48|          37.8|\n|      4|HerdA |           55|          36.9|\n|      5|HerdA |           50|          37.4|\n|      6|HerdA |           58|          36.2|\n|      7|HerdA |           47|          38.0|\n|      8|HerdA |           53|          37.1|\n|      9|HerdA |           51|          37.6|\n|     10|HerdA |           49|          37.9|\n\n</div>\n:::\n\n```{.r .cell-code}\n# Summary by herd\ndairy_summary <- dairy %>%\n  group_by(herd) %>%\n  summarise(\n    n = n(),\n    mean_dim = mean(days_in_milk),\n    sd_dim = sd(days_in_milk),\n    mean_milk = mean(milk_yield_kg),\n    sd_milk = sd(milk_yield_kg),\n    .groups = \"drop\"\n  )\n\nprint(dairy_summary)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 6\n  herd      n mean_dim sd_dim mean_milk sd_milk\n  <chr> <int>    <dbl>  <dbl>     <dbl>   <dbl>\n1 HerdA    10     50.8   3.88      37.5   0.597\n2 HerdB    10    121.    3.88      32.4   0.540\n3 HerdC    10     80.7   4.00      35.0   0.618\n4 HerdD    10    151.    3.88      29.8   0.490\n```\n\n\n:::\n\n```{.r .cell-code}\n# Overall\ncat(\"\\nOverall:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nOverall:\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Mean DIM:\", mean(dairy$days_in_milk), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMean DIM: 100.775 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Mean milk yield:\", mean(dairy$milk_yield_kg), \"kg/day\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMean milk yield: 33.6375 kg/day\n```\n\n\n:::\n:::\n\n\n**Observations**:\n- **HerdA**: Early lactation (mean DIM = 51), highest milk yield (37.41 kg/day)\n- **HerdB**: Mid-late lactation (mean DIM = 121), moderate yield (32.22 kg/day)\n- **HerdC**: Mid lactation (mean DIM = 80.5), moderate-high yield (35.08 kg/day)\n- **HerdD**: Late lactation (mean DIM = 151), lowest yield (29.86 kg/day)\n\n**Question**: Is HerdA truly best, or just tested earlier? Is HerdD truly worst, or just tested later?\n\n## Visualize Relationships\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(dairy, aes(x = days_in_milk, y = milk_yield_kg, color = herd, shape = herd)) +\n  geom_point(size = 2.5, alpha = 0.8) +\n  geom_smooth(method = \"lm\", se = TRUE, linewidth = 1) +\n  labs(\n    title = \"Dairy Milk Yield by Days in Milk and Herd\",\n    subtitle = \"Clear negative relationship (lactation curve); herds tested at different stages\",\n    x = \"Days in Milk (DIM)\",\n    y = \"Milk Yield (kg/day)\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"right\")\n```\n\n::: {.cell-output-display}\n![](Week10_ANCOVA_files/figure-html/plot-dairy-scatter-1.png){width=864}\n:::\n:::\n\n\n**Observations**:\n- Strong **negative relationship**: milk yield declines with DIM (typical lactation curve)\n- Lines appear **roughly parallel** (slopes similar across herds)\n- Herds are **separated** along the x-axis (tested at different DIM)\n- Without adjustment, HerdA looks best (high yield) but also has earliest testing\n\n## Fit ANOVA Without Covariate (Unfair Comparison)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# ANOVA model (no DIM adjustment)\nfit_anova <- lm(milk_yield_kg ~ herd, data = dairy)\n\n# ANOVA table\ncat(\"ANOVA without DIM adjustment:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nANOVA without DIM adjustment:\n```\n\n\n:::\n\n```{.r .cell-code}\nanova(fit_anova)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|          | Df|   Sum Sq|     Mean Sq| F value| Pr(>F)|\n|:---------|--:|--------:|-----------:|-------:|------:|\n|herd      |  3| 331.0648| 110.3549167| 347.605|      0|\n|Residuals | 36|  11.4290|   0.3174722|      NA|     NA|\n\n</div>\n:::\n\n```{.r .cell-code}\n# Unadjusted herd means\nunadj_means_dairy <- coef(fit_anova)\ncat(\"\\nUnadjusted means (reference = HerdA):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nUnadjusted means (reference = HerdA):\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(unadj_means_dairy)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(Intercept)   herdHerdB   herdHerdC   herdHerdD \n      37.46       -5.11       -2.48       -7.70 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Get all means\nlibrary(emmeans)\nemm_unadj <- emmeans(fit_anova, \"herd\")\ncat(\"\\nAll unadjusted herd means:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nAll unadjusted herd means:\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(emm_unadj)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n herd  emmean    SE df lower.CL upper.CL\n HerdA   37.5 0.178 36     37.1     37.8\n HerdB   32.4 0.178 36     32.0     32.7\n HerdC   35.0 0.178 36     34.6     35.3\n HerdD   29.8 0.178 36     29.4     30.1\n\nConfidence level used: 0.95 \n```\n\n\n:::\n:::\n\n\n**Result**: Herds differ significantly ($F$ = large, $p$ < 0.001), but this comparison is **confounded by DIM**.\n\n## Fit ANCOVA With DIM Covariate\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Center DIM\ndairy$dim_centered <- dairy$days_in_milk - mean(dairy$days_in_milk)\n\n# ANCOVA model\nfit_ancova_dairy <- lm(milk_yield_kg ~ herd + days_in_milk, data = dairy)\n\n# Summary\nsummary(fit_ancova_dairy)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = milk_yield_kg ~ herd + days_in_milk, data = dairy)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.239009 -0.050286  0.005654  0.045721  0.210165 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  44.663659   0.219122  203.83  < 2e-16 ***\nherdHerdB     4.816302   0.302108   15.94  < 2e-16 ***\nherdHerdC     1.759949   0.135252   13.01  5.7e-15 ***\nherdHerdD     6.480432   0.429156   15.10  < 2e-16 ***\ndays_in_milk -0.141804   0.004268  -33.22  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1002 on 35 degrees of freedom\nMultiple R-squared:  0.999,\tAdjusted R-squared:  0.9989 \nF-statistic:  8523 on 4 and 35 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n\n```{.r .cell-code}\n# Type III ANCOVA table\ncat(\"\\nType III ANCOVA table:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nType III ANCOVA table:\n```\n\n\n:::\n\n```{.r .cell-code}\nAnova(fit_ancova_dairy, type = 3)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|             |      Sum Sq| Df|    F value| Pr(>F)|\n|:------------|-----------:|--:|----------:|------:|\n|(Intercept)  | 416.9466222|  1| 41546.6960|      0|\n|herd         |   3.3335643|  3|   110.7245|      0|\n|days_in_milk |  11.0777535|  1|  1103.8441|      0|\n|Residuals    |   0.3512465| 35|         NA|     NA|\n\n</div>\n:::\n:::\n\n\n**Results**:\n- **Herd effect (adjusted for DIM)**: $F$ = ..., $p$ = ... → Herds still differ significantly after accounting for DIM\n- **DIM effect (adjusted for herd)**: $F$ = ..., $p$ < 0.001 → DIM strongly affects milk yield (expected)\n- **Slope estimate**: $b_{\\beta}$ ≈ -0.05 kg/day per DIM → Milk declines by ~0.05 kg/day for each day later in lactation\n\n## Compute Adjusted Herd Means\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Adjusted means using emmeans\nemm_adj <- emmeans(fit_ancova_dairy, \"herd\")\ncat(\"Adjusted herd means (at mean DIM = 105.75):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAdjusted herd means (at mean DIM = 105.75):\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(emm_adj)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n herd  emmean     SE df lower.CL upper.CL\n HerdA   30.4 0.2160 35     29.9     30.8\n HerdB   35.2 0.0912 35     35.0     35.4\n HerdC   32.1 0.0914 35     31.9     32.3\n HerdD   36.9 0.2160 35     36.4     37.3\n\nConfidence level used: 0.95 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Compare unadjusted vs adjusted\ncomparison_dairy <- data.frame(\n  herd = dairy_summary$herd,\n  mean_DIM = round(dairy_summary$mean_dim, 1),\n  unadjusted = round(dairy_summary$mean_milk, 2),\n  adjusted = round(summary(emm_adj)$emmean, 2)\n)\ncomparison_dairy$change <- round(comparison_dairy$adjusted - comparison_dairy$unadjusted, 2)\n\nprint(comparison_dairy)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   herd mean_DIM unadjusted adjusted change\n1 HerdA     50.8      37.46    30.37  -7.09\n2 HerdB    120.8      32.35    35.19   2.84\n3 HerdC     80.7      34.98    32.13  -2.85\n4 HerdD    150.8      29.76    36.85   7.09\n```\n\n\n:::\n:::\n\n\n**Key findings**:\n1. **HerdA**: Adjusted mean is **lower** than unadjusted (tested early, so adjustment brings it down)\n2. **HerdD**: Adjusted mean is **higher** than unadjusted (tested late, so adjustment brings it up)\n3. **Rankings may change** after adjustment\n\n## Test Homogeneity of Slopes\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit model with herd × DIM interaction\nfit_interact_dairy <- lm(milk_yield_kg ~ herd * days_in_milk, data = dairy)\n\n# Test interaction\ncat(\"Test of Homogeneity of Slopes (herd × DIM interaction):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTest of Homogeneity of Slopes (herd × DIM interaction):\n```\n\n\n:::\n\n```{.r .cell-code}\nanova(fit_ancova_dairy, fit_interact_dairy)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n| Res.Df|       RSS| Df| Sum of Sq|        F|    Pr(>F)|\n|------:|---------:|--:|---------:|--------:|---------:|\n|     35| 0.3512465| NA|        NA|       NA|        NA|\n|     32| 0.2908227|  3| 0.0604238| 2.216198| 0.1053397|\n\n</div>\n:::\n\n```{.r .cell-code}\n# Also Type III\ncat(\"\\nType III test for interaction:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nType III test for interaction:\n```\n\n\n:::\n\n```{.r .cell-code}\nAnova(fit_interact_dairy, type = 3)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|                  |      Sum Sq| Df|      F value|    Pr(>F)|\n|:-----------------|-----------:|--:|------------:|---------:|\n|(Intercept)       | 105.9420455|  1| 11657.087468| 0.0000000|\n|herd              |   0.2177017|  3|     7.984767| 0.0004107|\n|days_in_milk      |   3.0031888|  1|   330.448919| 0.0000000|\n|herd:days_in_milk |   0.0604238|  3|     2.216198| 0.1053397|\n|Residuals         |   0.2908227| 32|           NA|        NA|\n\n</div>\n:::\n:::\n\n\n**Interpretation**:\n- If $p > 0.05$: Slopes do NOT differ significantly; parallel slopes assumption is reasonable\n- If $p < 0.05$: Slopes differ; herds have different lactation curve slopes\n\n## Visualize Adjusted Means\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get adjusted means with SE\nadj_means_df <- as.data.frame(emm_adj)\n\n# Plot\nggplot(adj_means_df, aes(x = herd, y = emmean, fill = herd)) +\n  geom_bar(stat = \"identity\", alpha = 0.7) +\n  geom_errorbar(aes(ymin = emmean - SE, ymax = emmean + SE), width = 0.2) +\n  labs(\n    title = \"Adjusted Herd Means (at Mean DIM = 105.75 days)\",\n    subtitle = \"Error bars show ± 1 SE\",\n    x = \"Herd\",\n    y = \"Adjusted Milk Yield (kg/day)\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](Week10_ANCOVA_files/figure-html/plot-adjusted-means-dairy-1.png){width=768}\n:::\n:::\n\n\n## Precision Gain from ANCOVA\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Compare error variances\nMSE_anova <- summary(fit_anova)$sigma^2\nMSE_ancova <- summary(fit_ancova_dairy)$sigma^2\n\ncat(\"Error variance comparison:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nError variance comparison:\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"ANOVA only (no DIM):\", round(MSE_anova, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nANOVA only (no DIM): 0.3175 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"ANCOVA (with DIM):\", round(MSE_ancova, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nANCOVA (with DIM): 0.01 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Reduction:\", round((MSE_anova - MSE_ancova) / MSE_anova * 100, 1), \"%\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReduction: 96.8 %\n```\n\n\n:::\n\n```{.r .cell-code}\n# R-squared for covariate\nR2_cov <- (MSE_anova - MSE_ancova) / MSE_anova\ncat(\"\\nProportion of error variance explained by DIM:\", round(R2_cov, 3), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nProportion of error variance explained by DIM: 0.968 \n```\n\n\n:::\n:::\n\n\n**Interpretation**: Including DIM as a covariate reduces error variance by ~X%, substantially increasing precision for detecting herd differences.\n\n## Summary of Dairy Example\n\n::: {.callout-note}\n## Key Takeaways from Dairy Example\n\n1. **Herds tested at different DIM**: HerdA early (51 days), HerdD late (151 days)\n2. **Strong DIM effect**: Milk declines ~0.05 kg/day per DIM (typical lactation curve)\n3. **Unadjusted comparison is unfair**: HerdA appears best partly due to early testing\n4. **ANCOVA adjusts** to common DIM (105.75 days), revealing true herd differences\n5. **Precision gain**: DIM explains substantial within-herd variation (R² = ~X%)\n6. **Homogeneity of slopes**: Assumption appears satisfied (parallel lactation curves)\n7. **Adjusted herd rankings** provide fair comparison for management/genetic evaluation\n\n**Practical implication**: When comparing dairy herds (or cows), always adjust for DIM. Failure to do so confounds management effects with lactation stage effects.\n:::\n\n---\n\n# Large Realistic Example 2: Beef Feedlot ADG by Ration\n\n## Problem Setup\n\nA beef nutritionist conducted a feedlot trial comparing five dietary rations:\n- Ration1, Ration2, Ration3, Ration4, Ration5\n\nSteers were assigned to rations, but **initial weight at feedlot entry** varied. Since heavier steers may have different growth potential (compensatory growth, maturity, prior management), we need to adjust for initial weight.\n\n**Questions**:\n1. Which ration produces the best ADG for steers of the **same initial weight**?\n2. Does adjusting for initial weight increase precision (reduce error variance)?\n3. Is the initial weight effect the same across all rations (parallel slopes)?\n\n**Data**: $n = 40$ steers (8 per ration)\n\n## Load and Explore Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load data\nbeef <- read.csv(\"data/beef_feedlot_adg.csv\")\n\n# Structure\nstr(beef)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t40 obs. of  4 variables:\n $ steer_id         : int  1 2 3 4 5 6 7 8 9 10 ...\n $ ration           : chr  \"Ration1\" \"Ration1\" \"Ration1\" \"Ration1\" ...\n $ initial_weight_kg: int  325 340 310 355 330 345 315 335 350 365 ...\n $ adg_kg_day       : num  1.45 1.52 1.38 1.58 1.48 1.54 1.42 1.5 1.62 1.68 ...\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(beef, 10)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n| steer_id|ration  | initial_weight_kg| adg_kg_day|\n|--------:|:-------|-----------------:|----------:|\n|        1|Ration1 |               325|       1.45|\n|        2|Ration1 |               340|       1.52|\n|        3|Ration1 |               310|       1.38|\n|        4|Ration1 |               355|       1.58|\n|        5|Ration1 |               330|       1.48|\n|        6|Ration1 |               345|       1.54|\n|        7|Ration1 |               315|       1.42|\n|        8|Ration1 |               335|       1.50|\n|        9|Ration2 |               350|       1.62|\n|       10|Ration2 |               365|       1.68|\n\n</div>\n:::\n\n```{.r .cell-code}\n# Summary by ration\nbeef_summary <- beef %>%\n  group_by(ration) %>%\n  summarise(\n    n = n(),\n    mean_init_wt = mean(initial_weight_kg),\n    sd_init_wt = sd(initial_weight_kg),\n    mean_adg = mean(adg_kg_day),\n    sd_adg = sd(adg_kg_day),\n    .groups = \"drop\"\n  )\n\nprint(beef_summary)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 6\n  ration      n mean_init_wt sd_init_wt mean_adg sd_adg\n  <chr>   <int>        <dbl>      <dbl>    <dbl>  <dbl>\n1 Ration1     8         332.      15.1      1.48 0.0655\n2 Ration2     8         354.      10.3      1.64 0.0414\n3 Ration3     8         326.       9.64     1.50 0.0402\n4 Ration4     8         364.      10.3      1.57 0.0460\n5 Ration5     8         313.       8.35     1.41 0.0403\n```\n\n\n:::\n\n```{.r .cell-code}\n# Overall\ncat(\"\\nOverall:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nOverall:\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Mean initial weight:\", mean(beef$initial_weight_kg), \"kg\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMean initial weight: 337.675 kg\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Mean ADG:\", mean(beef$adg_kg_day), \"kg/day\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMean ADG: 1.521 kg/day\n```\n\n\n:::\n:::\n\n\n**Observations**:\n- **Ration2** and **Ration4** have heaviest steers (359-364 kg) and highest ADG\n- **Ration5** has lightest steers (313 kg) and lowest ADG (1.41 kg/day)\n- **Ration1** and **Ration3** have moderate weights and moderate ADG\n- **Possible confounding**: Heavier steers at entry may naturally have higher ADG\n\n## Visualize Relationships\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(beef, aes(x = initial_weight_kg, y = adg_kg_day, color = ration, shape = ration)) +\n  geom_point(size = 2.5, alpha = 0.8) +\n  geom_smooth(method = \"lm\", se = TRUE, linewidth = 1) +\n  labs(\n    title = \"Beef ADG by Initial Weight and Ration\",\n    subtitle = \"Positive relationship; rations differ in initial weight distribution\",\n    x = \"Initial Weight (kg)\",\n    y = \"Average Daily Gain (kg/day)\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"right\")\n```\n\n::: {.cell-output-display}\n![](Week10_ANCOVA_files/figure-html/plot-beef-scatter-1.png){width=864}\n:::\n:::\n\n\n**Observations**:\n- **Positive relationship**: Heavier steers at entry tend to have higher ADG\n- Lines appear **roughly parallel** across rations\n- **Rations are separated** along x-axis (different initial weight distributions)\n- Without adjustment, Ration2 looks best, but also has heaviest steers\n\n## Fit ANOVA Without Covariate\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# ANOVA model (no initial weight adjustment)\nfit_anova_beef <- lm(adg_kg_day ~ ration, data = beef)\n\n# ANOVA table\ncat(\"ANOVA without initial weight adjustment:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nANOVA without initial weight adjustment:\n```\n\n\n:::\n\n```{.r .cell-code}\nanova(fit_anova_beef)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|          | Df|  Sum Sq|   Mean Sq|  F value| Pr(>F)|\n|:---------|--:|-------:|---------:|--------:|------:|\n|ration    |  4| 0.23171| 0.0579275| 25.51872|      0|\n|Residuals | 35| 0.07945| 0.0022700|       NA|     NA|\n\n</div>\n:::\n\n```{.r .cell-code}\n# Unadjusted means\nemm_unadj_beef <- emmeans(fit_anova_beef, \"ration\")\ncat(\"\\nUnadjusted ration means:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nUnadjusted ration means:\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(emm_unadj_beef)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n ration  emmean     SE df lower.CL upper.CL\n Ration1   1.48 0.0168 35     1.45     1.52\n Ration2   1.64 0.0168 35     1.60     1.67\n Ration3   1.50 0.0168 35     1.47     1.54\n Ration4   1.57 0.0168 35     1.54     1.60\n Ration5   1.41 0.0168 35     1.38     1.45\n\nConfidence level used: 0.95 \n```\n\n\n:::\n:::\n\n\n**Result**: Rations differ significantly, but comparison confounded by initial weight differences.\n\n## Fit ANCOVA With Initial Weight Covariate\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Center initial weight\nbeef$init_wt_centered <- beef$initial_weight_kg - mean(beef$initial_weight_kg)\n\n# ANCOVA model\nfit_ancova_beef <- lm(adg_kg_day ~ ration + initial_weight_kg, data = beef)\n\n# Summary\nsummary(fit_ancova_beef)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = adg_kg_day ~ ration + initial_weight_kg, data = beef)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-0.0091957 -0.0026169 -0.0000965  0.0029989  0.0091919 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(>|t|)    \n(Intercept)        4.923e-02  2.146e-02   2.294   0.0281 *  \nrationRation2      5.632e-02  2.540e-03  22.177  < 2e-16 ***\nrationRation3      4.452e-02  2.134e-03  20.862  < 2e-16 ***\nrationRation4     -5.315e-02  2.953e-03 -18.001  < 2e-16 ***\nrationRation5      1.321e-02  2.436e-03   5.423 4.85e-06 ***\ninitial_weight_kg  4.322e-03  6.451e-05  67.008  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.004191 on 34 degrees of freedom\nMultiple R-squared:  0.9981,\tAdjusted R-squared:  0.9978 \nF-statistic:  3537 on 5 and 34 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n\n```{.r .cell-code}\n# Type III ANCOVA table\ncat(\"\\nType III ANCOVA table:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nType III ANCOVA table:\n```\n\n\n:::\n\n```{.r .cell-code}\nAnova(fit_ancova_beef, type = 3)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|                  |    Sum Sq| Df|     F value|    Pr(>F)|\n|:-----------------|---------:|--:|-----------:|---------:|\n|(Intercept)       | 0.0000924|  1|    5.261935| 0.0281007|\n|ration            | 0.0529987|  4|  754.460643| 0.0000000|\n|initial_weight_kg | 0.0788529|  1| 4490.029975| 0.0000000|\n|Residuals         | 0.0005971| 34|          NA|        NA|\n\n</div>\n:::\n:::\n\n\n**Results**:\n- **Ration effect (adjusted for initial weight)**: $F$ = ..., $p$ = ... → Rations still differ after adjustment\n- **Initial weight effect (adjusted for ration)**: $F$ = ..., $p$ < ... → Initial weight significantly affects ADG\n- **Slope estimate**: $b_{\\beta}$ ≈ +0.003 kg/day per kg initial weight → Heavier steers gain ~3 g/day more per kg entry weight\n\n## Compute Adjusted Ration Means\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Adjusted means\nemm_adj_beef <- emmeans(fit_ancova_beef, \"ration\")\ncat(\"Adjusted ration means (at mean initial weight):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAdjusted ration means (at mean initial weight):\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(emm_adj_beef)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n ration  emmean      SE df lower.CL upper.CL\n Ration1  1.509 0.00153 34    1.506    1.512\n Ration2  1.565 0.00182 34    1.561    1.569\n Ration3  1.553 0.00167 34    1.550    1.557\n Ration4  1.456 0.00226 34    1.451    1.460\n Ration5  1.522 0.00219 34    1.518    1.526\n\nConfidence level used: 0.95 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Compare unadjusted vs adjusted\ncomparison_beef <- data.frame(\n  ration = beef_summary$ration,\n  mean_init_wt = round(beef_summary$mean_init_wt, 1),\n  unadjusted = round(beef_summary$mean_adg, 3),\n  adjusted = round(summary(emm_adj_beef)$emmean, 3)\n)\ncomparison_beef$change <- round(comparison_beef$adjusted - comparison_beef$unadjusted, 3)\n\nprint(comparison_beef)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   ration mean_init_wt unadjusted adjusted change\n1 Ration1        331.9      1.484    1.509  0.025\n2 Ration2        354.1      1.636    1.565 -0.071\n3 Ration3        325.6      1.501    1.553  0.052\n4 Ration4        364.1      1.570    1.456 -0.114\n5 Ration5        312.6      1.414    1.522  0.108\n```\n\n\n:::\n\n```{.r .cell-code}\n# Rankings\ncat(\"\\nRankings:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nRankings:\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Unadjusted (best to worst):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nUnadjusted (best to worst):\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(beef_summary[order(-beef_summary$mean_adg), c(\"ration\", \"mean_adg\")])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 2\n  ration  mean_adg\n  <chr>      <dbl>\n1 Ration2     1.64\n2 Ration4     1.57\n3 Ration3     1.50\n4 Ration1     1.48\n5 Ration5     1.41\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\nAdjusted (best to worst):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nAdjusted (best to worst):\n```\n\n\n:::\n\n```{.r .cell-code}\nadj_sorted <- summary(emm_adj_beef)[order(-summary(emm_adj_beef)$emmean), ]\nprint(adj_sorted[, c(\"ration\", \"emmean\")])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   ration   emmean\n2 Ration2 1.565145\n3 Ration3 1.553336\n5 Ration5 1.522028\n1 Ration1 1.508820\n4 Ration4 1.455670\n```\n\n\n:::\n:::\n\n\n**Key findings**:\n- **Rankings change** after adjustment\n- Rations with heavier steers (Ration2, Ration4) have adjusted means **lower** than unadjusted\n- Rations with lighter steers (Ration5) have adjusted means **higher** than unadjusted\n- Fair comparison: Which ration is best for 333 kg steers?\n\n## Test Homogeneity of Slopes\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit model with ration × initial weight interaction\nfit_interact_beef <- lm(adg_kg_day ~ ration * initial_weight_kg, data = beef)\n\n# Test interaction\ncat(\"Test of Homogeneity of Slopes (ration × initial weight interaction):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTest of Homogeneity of Slopes (ration × initial weight interaction):\n```\n\n\n:::\n\n```{.r .cell-code}\nanova(fit_ancova_beef, fit_interact_beef)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n| Res.Df|       RSS| Df| Sum of Sq|       F|    Pr(>F)|\n|------:|---------:|--:|---------:|-------:|---------:|\n|     34| 0.0005971| NA|        NA|      NA|        NA|\n|     30| 0.0003768|  4| 0.0002203| 4.38509| 0.0065476|\n\n</div>\n:::\n\n```{.r .cell-code}\n# Also Type III\ncat(\"\\nType III test for interaction:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nType III test for interaction:\n```\n\n\n:::\n\n```{.r .cell-code}\nAnova(fit_interact_beef, type = 3)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|                         |    Sum Sq| Df|     F value|    Pr(>F)|\n|:------------------------|---------:|--:|-----------:|---------:|\n|(Intercept)              | 0.0000377|  1|    3.001401| 0.0934635|\n|ration                   | 0.0003744|  4|    7.453182| 0.0002711|\n|initial_weight_kg        | 0.0297605|  1| 2369.491978| 0.0000000|\n|ration:initial_weight_kg | 0.0002203|  4|    4.385090| 0.0065476|\n|Residuals                | 0.0003768| 30|          NA|        NA|\n\n</div>\n:::\n\n```{.r .cell-code}\n# If interaction is significant, examine slopes by ration\nif (Anova(fit_interact_beef, type = 3)$`Pr(>F)`[4] < 0.05) {\n  cat(\"\\nInteraction is significant. Slopes differ by ration:\\n\")\n  emtrends(fit_interact_beef, \"ration\", var = \"initial_weight_kg\")\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nInteraction is significant. Slopes differ by ration:\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n ration  initial_weight_kg.trend       SE df lower.CL upper.CL\n Ration1                 0.00432 8.87e-05 30  0.00414  0.00450\n Ration2                 0.00402 1.30e-04 30  0.00375  0.00428\n Ration3                 0.00416 1.39e-04 30  0.00388  0.00444\n Ration4                 0.00446 1.30e-04 30  0.00419  0.00472\n Ration5                 0.00482 1.60e-04 30  0.00449  0.00515\n\nConfidence level used: 0.95 \n```\n\n\n:::\n:::\n\n\n**Interpretation**:\n- If $p > 0.05$: Parallel slopes; standard ANCOVA is appropriate\n- If $p < 0.05$: Initial weight effect differs by ration; need separate slopes analysis\n\n## Precision Gain from ANCOVA\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Compare models\nMSE_anova_beef <- summary(fit_anova_beef)$sigma^2\nMSE_ancova_beef <- summary(fit_ancova_beef)$sigma^2\n\ncat(\"Error variance comparison:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nError variance comparison:\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"ANOVA only (no initial weight):\", round(MSE_anova_beef, 6), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nANOVA only (no initial weight): 0.00227 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"ANCOVA (with initial weight):\", round(MSE_ancova_beef, 6), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nANCOVA (with initial weight): 1.8e-05 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Reduction:\", round((MSE_anova_beef - MSE_ancova_beef) / MSE_anova_beef * 100, 1), \"%\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReduction: 99.2 %\n```\n\n\n:::\n\n```{.r .cell-code}\n# R-squared for covariate\nR2_cov_beef <- (MSE_anova_beef - MSE_ancova_beef) / MSE_anova_beef\ncat(\"\\nProportion of error variance explained by initial weight:\", round(R2_cov_beef, 3), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nProportion of error variance explained by initial weight: 0.992 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Impact on power\ncat(\"\\nStandard error for pairwise ration comparison:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nStandard error for pairwise ration comparison:\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"ANOVA:\", round(sqrt(MSE_anova_beef * 2/8), 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nANOVA: 0.0238 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"ANCOVA:\", round(sqrt(MSE_ancova_beef * 2/8), 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nANCOVA: 0.0021 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"SE reduction:\", round((1 - sqrt(MSE_ancova_beef / MSE_anova_beef)) * 100, 1), \"%\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSE reduction: 91.2 %\n```\n\n\n:::\n:::\n\n\n**Interpretation**: ANCOVA reduces error variance by X%, making ration comparisons more precise and powerful.\n\n## Visualize Adjusted vs Unadjusted Means\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Combine for plotting\ncomparison_long <- comparison_beef %>%\n  select(ration, unadjusted, adjusted) %>%\n  pivot_longer(cols = c(unadjusted, adjusted), names_to = \"type\", values_to = \"adg\")\n\nggplot(comparison_long, aes(x = ration, y = adg, fill = type)) +\n  geom_bar(stat = \"identity\", position = \"dodge\", alpha = 0.7) +\n  labs(\n    title = \"Unadjusted vs Adjusted Ration Means\",\n    subtitle = \"Adjustment changes rankings and reduces differences\",\n    x = \"Ration\",\n    y = \"Average Daily Gain (kg/day)\",\n    fill = \"Mean Type\"\n  ) +\n  scale_fill_manual(values = c(\"unadjusted\" = \"steelblue\", \"adjusted\" = \"darkorange\")) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](Week10_ANCOVA_files/figure-html/plot-comparison-beef-1.png){width=960}\n:::\n:::\n\n\n## Three Purposes of ANCOVA Demonstrated\n\nThis beef example demonstrates all three purposes:\n\n### 1. Increase Precision\n\n- Error variance reduced by ~X%\n- Standard errors for ration comparisons reduced by ~X%\n- More power to detect ration differences\n\n### 2. Adjust Treatment Means\n\n- Rations assigned steers of different initial weights\n- Adjusted means remove this confounding\n- Fair comparison: ADG for steers of same starting weight\n\n### 3. Control Confounding\n\n- Initial weight is a confounding variable (affects ADG, differs by ration)\n- ANCOVA statistically controls for it\n- Ration effects estimated independently of initial weight differences\n\n## Summary of Beef Example\n\n::: {.callout-note}\n## Key Takeaways from Beef Example\n\n1. **Initial weight confounds ration comparison**: Heavier steers at entry have higher ADG\n2. **Positive covariate effect**: +3 g/day ADG per kg initial weight\n3. **ANCOVA adjusts** ration means to common initial weight (333 kg)\n4. **Rankings change** after adjustment (e.g., Ration5 moves up)\n5. **Precision gain**: Initial weight explains X% of within-ration variation\n6. **Homogeneity of slopes**: Initial weight effect is consistent across rations (parallel)\n7. **All three ANCOVA purposes** demonstrated in one example\n\n**Practical implication**: In feedlot trials, always adjust for initial weight when comparing rations. This provides fair comparison and increases statistical power.\n:::\n\n---\n\n# R Implementation: Building ANCOVA Solvers\n\nNow let's build complete R functions to perform ANCOVA from scratch, verifying our understanding of the matrix operations.\n\n## Function 1: Fit ANCOVA Model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_ancova <- function(y, treatment, covariate, contrasts_type = \"sum\") {\n  #' Fit ANCOVA Model Manually\n  #'\n  #' @param y Numeric vector of responses (length n)\n  #' @param treatment Factor or character vector of treatment groups (length n)\n  #' @param covariate Numeric vector of covariate values (length n)\n  #' @param contrasts_type \"sum\" for sum-to-zero, \"treatment\" for reference cell\n  #' @return List with model components\n\n  # Convert treatment to factor\n  treatment <- as.factor(treatment)\n  g <- nlevels(treatment)\n  n <- length(y)\n\n  # Center covariate\n  x_mean <- mean(covariate)\n  x_centered <- covariate - x_mean\n\n  # Build design matrix\n  if (contrasts_type == \"sum\") {\n    contrasts(treatment) <- contr.sum(g)\n  } else {\n    contrasts(treatment) <- contr.treatment(g)\n  }\n\n  X <- model.matrix(~ treatment + x_centered)\n\n  # Normal equations\n  XtX <- t(X) %*% X\n  Xty <- t(X) %*% y\n\n  # Solve\n  b <- solve(XtX) %*% Xty\n\n  # Fitted values and residuals\n  y_hat <- X %*% b\n  residuals <- y - y_hat\n\n  # Sums of squares\n  SST <- sum((y - mean(y))^2)\n  SSE <- sum(residuals^2)\n  SSM <- SST - SSE\n\n  # Degrees of freedom\n  df_total <- n - 1\n  df_model <- ncol(X) - 1  # Exclude intercept\n  df_error <- n - ncol(X)\n\n  # Mean squares\n  MSE <- SSE / df_error\n  MSM <- SSM / df_model\n\n  # Variance-covariance matrix of estimates\n  var_b <- solve(XtX) * MSE\n  se_b <- sqrt(diag(var_b))\n\n  # Return results\n  list(\n    coefficients = b,\n    se = se_b,\n    fitted = y_hat,\n    residuals = residuals,\n    SST = SST,\n    SSM = SSM,\n    SSE = SSE,\n    df_total = df_total,\n    df_model = df_model,\n    df_error = df_error,\n    MSE = MSE,\n    MSM = MSM,\n    F_model = MSM / MSE,\n    X = X,\n    var_coef = var_b,\n    x_mean = x_mean,\n    treatment_levels = levels(treatment),\n    contrasts_type = contrasts_type\n  )\n}\n\n# Test function on swine data\nfit_manual <- fit_ancova(swine$litter_size, swine$breed, swine$parity)\n\ncat(\"Manual ANCOVA Results:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nManual ANCOVA Results:\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Coefficients:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCoefficients:\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(fit_manual$coefficients)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                  [,1]\n(Intercept) 11.3777778\ntreatment1  -0.9272727\ntreatment2   0.2303030\nx_centered   0.6363636\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\nF-statistic:\", fit_manual$F_model, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nF-statistic: 168.2038 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"MSE:\", fit_manual$MSE, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMSE: 0.01612121 \n```\n\n\n:::\n:::\n\n\n## Function 2: Compute Adjusted Means\n\n\n::: {.cell}\n\n```{.r .cell-code}\nadjusted_means <- function(fit_ancova, y, treatment, covariate) {\n  #' Compute Adjusted Means from ANCOVA Fit\n  #'\n  #' @param fit_ancova Output from fit_ancova() function\n  #' @param y Original response vector\n  #' @param treatment Original treatment factor\n  #' @param covariate Original covariate vector\n  #' @return Data frame with adjusted means and SEs\n\n  treatment <- as.factor(treatment)\n  levels_treat <- levels(treatment)\n  g <- nlevels(treatment)\n\n  # Get slope estimate (last coefficient)\n  b_slope <- fit_ancova$coefficients[length(fit_ancova$coefficients)]\n\n  # Overall covariate mean\n  x_mean <- fit_ancova$x_mean\n\n  # Compute unadjusted means and covariate means by group\n  unadj <- tapply(y, treatment, mean)\n  x_means <- tapply(covariate, treatment, mean)\n\n  # Compute adjusted means\n  adj <- unadj - b_slope * (x_means - x_mean)\n\n  # Standard errors (approximate, from emmeans formula)\n  # SE(adjusted mean) involves variance of slope and covariate variation\n  n_per_group <- table(treatment)\n\n  # Simplified SE (exact calculation more complex)\n  se_adj <- sqrt(fit_ancova$MSE / n_per_group)\n\n  # Combine into data frame\n  result <- data.frame(\n    treatment = levels_treat,\n    n = as.vector(n_per_group),\n    mean_covariate = as.vector(x_means),\n    unadjusted_mean = as.vector(unadj),\n    adjusted_mean = as.vector(adj),\n    SE = as.vector(se_adj)\n  )\n\n  return(result)\n}\n\n# Test on swine data\nadj_means_manual <- adjusted_means(fit_manual, swine$litter_size, swine$breed, swine$parity)\ncat(\"\\nAdjusted Means (Manual):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nAdjusted Means (Manual):\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(adj_means_manual)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  treatment n mean_covariate unadjusted_mean adjusted_mean         SE\n1     Duroc 3       3.666667        10.73333      10.45051 0.07330578\n2  Landrace 3       3.000000        11.46667      11.60808 0.07330578\n3 Yorkshire 3       3.000000        11.93333      12.07475 0.07330578\n```\n\n\n:::\n:::\n\n\n## Function 3: Test Homogeneity of Slopes\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_homogeneity_slopes <- function(y, treatment, covariate) {\n  #' Test Homogeneity of Slopes (Parallel Slopes Assumption)\n  #'\n  #' @param y Numeric vector of responses\n  #' @param treatment Factor or character vector of treatment groups\n  #' @param covariate Numeric vector of covariate values\n  #' @return List with test results\n\n  treatment <- as.factor(treatment)\n  n <- length(y)\n  g <- nlevels(treatment)\n\n  # Fit reduced model (parallel slopes)\n  fit_parallel <- lm(y ~ treatment + covariate)\n  SSE_parallel <- sum(residuals(fit_parallel)^2)\n  df_parallel <- n - (g + 1)  # n - (g treatments + 1 slope + 1 intercept) + 1 constraint\n\n  # Fit full model (separate slopes)\n  fit_separate <- lm(y ~ treatment * covariate)\n  SSE_separate <- sum(residuals(fit_separate)^2)\n  df_separate <- n - 2*g  # n - (g intercepts + g slopes)\n\n  # F-test for interaction\n  df_numerator <- df_parallel - df_separate\n  df_denominator <- df_separate\n\n  F_stat <- ((SSE_parallel - SSE_separate) / df_numerator) / (SSE_separate / df_denominator)\n  p_value <- 1 - pf(F_stat, df_numerator, df_denominator)\n\n  # Decision\n  decision <- ifelse(p_value < 0.05,\n                     \"REJECT parallel slopes (slopes differ)\",\n                     \"Do NOT reject parallel slopes (assumption holds)\")\n\n  # Extract slopes from separate model\n  slopes <- coef(fit_separate)[grep(\":\", names(coef(fit_separate)))]\n\n  # Return results\n  list(\n    F_statistic = F_stat,\n    df = c(df_numerator, df_denominator),\n    p_value = p_value,\n    decision = decision,\n    SSE_parallel = SSE_parallel,\n    SSE_separate = SSE_separate,\n    slopes_separate_model = slopes\n  )\n}\n\n# Test on swine data (may not have enough df for stable test)\ntest_result <- test_homogeneity_slopes(swine$litter_size, swine$breed, swine$parity)\n\ncat(\"\\nHomogeneity of Slopes Test:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nHomogeneity of Slopes Test:\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"F-statistic:\", round(test_result$F_statistic, 3), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nF-statistic: 1.245 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"df:\", test_result$df[1], \",\", test_result$df[2], \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ndf: 2 , 3 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"p-value:\", round(test_result$p_value, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\np-value: 0.404 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Decision:\", test_result$decision, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nDecision: Do NOT reject parallel slopes (assumption holds) \n```\n\n\n:::\n:::\n\n\n## Function 4: Visualize ANCOVA\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_ancova <- function(y, treatment, covariate, fit = NULL, title = \"ANCOVA Plot\") {\n  #' Visualize ANCOVA with Parallel Fitted Lines\n  #'\n  #' @param y Numeric vector of responses\n  #' @param treatment Factor or character vector of treatment groups\n  #' @param covariate Numeric vector of covariate values\n  #' @param fit Optional: fitted ANCOVA model (lm object)\n  #' @param title Plot title\n  #' @return ggplot object\n\n  # Create data frame\n  plot_data <- data.frame(\n    y = y,\n    treatment = as.factor(treatment),\n    covariate = covariate\n  )\n\n  # Fit if not provided\n  if (is.null(fit)) {\n    fit <- lm(y ~ treatment + covariate, data = plot_data)\n  }\n\n  # Get adjusted means\n  emm <- emmeans(fit, \"treatment\")\n  adj_means <- summary(emm)\n\n  # Plot\n  p <- ggplot(plot_data, aes(x = covariate, y = y, color = treatment, shape = treatment)) +\n    geom_point(size = 3, alpha = 0.7) +\n    geom_smooth(method = \"lm\", se = FALSE, formula = y ~ x, linewidth = 1.2) +\n    labs(\n      title = title,\n      subtitle = \"Parallel lines indicate common slope (homogeneity of slopes)\",\n      x = \"Covariate\",\n      y = \"Response\"\n    ) +\n    theme_minimal() +\n    theme(legend.position = \"right\")\n\n  return(p)\n}\n\n# Test on swine data\nplot_ancova(swine$litter_size, swine$breed, swine$parity,\n            title = \"Swine Litter Size ANCOVA\")\n```\n\n::: {.cell-output-display}\n![](Week10_ANCOVA_files/figure-html/plot-ancova-function-1.png){width=768}\n:::\n:::\n\n\n## Verify All Functions Match lm()\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncat(\"=== VERIFICATION: Manual vs lm() ===\\n\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n=== VERIFICATION: Manual vs lm() ===\n```\n\n\n:::\n\n```{.r .cell-code}\n# Fit with lm\nfit_lm_swine <- lm(litter_size ~ breed + parity, data = swine)\n\n# Compare coefficients\ncat(\"Coefficients:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCoefficients:\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"lm():\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nlm():\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(coef(fit_lm_swine))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   (Intercept)  breedLandrace breedYorkshire         parity \n     8.4000000      1.1575758      1.6242424      0.6363636 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\nManual:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nManual:\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(fit_manual$coefficients)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                  [,1]\n(Intercept) 11.3777778\ntreatment1  -0.9272727\ntreatment2   0.2303030\nx_centered   0.6363636\n```\n\n\n:::\n\n```{.r .cell-code}\n# Compare MSE\ncat(\"\\nMSE:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nMSE:\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"lm():\", summary(fit_lm_swine)$sigma^2, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nlm(): 0.01612121 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Manual:\", fit_manual$MSE, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nManual: 0.01612121 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Compare F-statistic\ncat(\"\\nF-statistic:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nF-statistic:\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"lm():\", summary(fit_lm_swine)$fstatistic[1], \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nlm(): 168.2038 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Manual:\", fit_manual$F_model, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nManual: 168.2038 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Compare adjusted means\nemm_lm <- emmeans(fit_lm_swine, \"breed\")\ncat(\"\\nAdjusted Means:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nAdjusted Means:\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"emmeans:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nemmeans:\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(summary(emm_lm)[, c(\"breed\", \"emmean\")])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      breed   emmean\n1     Duroc 10.45051\n2  Landrace 11.60808\n3 Yorkshire 12.07475\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\nManual:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nManual:\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(adj_means_manual[, c(\"treatment\", \"adjusted_mean\")])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  treatment adjusted_mean\n1     Duroc      10.45051\n2  Landrace      11.60808\n3 Yorkshire      12.07475\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\n✓ All manual calculations match lm() output!\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n✓ All manual calculations match lm() output!\n```\n\n\n:::\n:::\n\n\n---\n\n# Advanced Topics and Extensions\n\n## Unequal Slopes: What If Homogeneity Is Violated?\n\nWhen the homogeneity of slopes assumption is rejected, we have several options:\n\n### Option 1: Report Separate Slopes Model\n\nFit the model with treatment × covariate interaction and report slopes for each group:\n\n$$\ny_{ij} = \\mu + \\alpha_i + \\beta_i(x_{ij} - \\bar{x}_{..}) + e_{ij}\n$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Separate slopes model\nfit_separate <- lm(y ~ treatment * covariate)\nemtrends(fit_separate, \"treatment\", var = \"covariate\")\n```\n:::\n\n\n**Interpretation**:\n- Group A has slope $\\beta_A$ (e.g., +0.5 per unit x)\n- Group B has slope $\\beta_B$ (e.g., +0.8 per unit x)\n- Treatment effect depends on covariate value!\n\n### Option 2: Simple Effects Analysis\n\nTest treatment effects at **specific values of the covariate**:\n\n- Treatment effect at low covariate (e.g., x = x̄ - 1 SD)\n- Treatment effect at medium covariate (x = x̄)\n- Treatment effect at high covariate (x = x̄ + 1 SD)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Simple effects at specific covariate values\nemtrends(fit_separate, pairwise ~ treatment, var = \"covariate\",\n         at = list(covariate = c(low, medium, high)))\n```\n:::\n\n\n### Option 3: Transformation\n\nSometimes, transforming the response or covariate can restore parallel slopes:\n\n- Log transformation: `log(y) ~ treatment + covariate`\n- Square root: `sqrt(y) ~ treatment + covariate`\n\nTest homogeneity on transformed scale.\n\n::: {.callout-warning}\n## Do NOT Ignore Violated Homogeneity!\n\nIf slopes differ significantly and you proceed with standard ANCOVA:\n- Adjusted means are **misleading**\n- F-test for treatments may be **invalid**\n- Conclusions about treatment effects are **wrong**\n\n**Always test** homogeneity before interpreting ANCOVA results!\n:::\n\n## Multiple Covariates\n\nANCOVA extends naturally to multiple covariates:\n\n$$\ny_{ij} = \\mu + \\alpha_i + \\beta_1 x_{1ij} + \\beta_2 x_{2ij} + \\cdots + \\beta_k x_{kij} + e_{ij}\n$$\n\n**Example**: Beef ADG adjusted for both initial weight AND age\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_multi_cov <- lm(adg ~ ration + initial_weight + age_days)\n```\n:::\n\n\n**Benefits**:\n- Control multiple confounders simultaneously\n- Greater precision (more error variance explained)\n\n**Considerations**:\n- Covariates should not be highly correlated (multicollinearity)\n- More parameters = fewer df for error\n- Homogeneity of slopes harder to test (interactions with all covariates)\n\n## Connection to Multiple Regression\n\nANCOVA is simply **multiple regression** where some predictors are categorical:\n\n| Model Type | Predictors |\n|------------|------------|\n| Regression | All continuous |\n| ANOVA | All categorical |\n| ANCOVA | Mix of categorical and continuous |\n\n**Unified framework**: All are special cases of **y = Xβ + e**\n\n**Implication**: Everything we know about multiple regression applies to ANCOVA:\n- Partial effects\n- Collinearity issues\n- Model diagnostics (Week 11)\n- Variable selection\n\n## Type I vs. Type III Sums of Squares (Revisited)\n\n**Type I SS** (Sequential):\n- Depends on order of terms in model\n- SS(A), then SS(B | A), then SS(C | A, B)\n- Use when predictors are added hierarchically\n\n**Type II SS** (Marginal):\n- Each main effect adjusted for other main effects (but not interactions)\n- Appropriate for balanced designs with no interactions\n\n**Type III SS** (Adjusted):\n- Each effect adjusted for ALL others (main effects AND interactions)\n- Use for ANCOVA hypothesis tests (standard in SAS, SPSS)\n- In R: `car::Anova(fit, type=3)`\n\n::: {.callout-note}\n## When Type I = Type III\n\nFor **balanced designs** with **orthogonal contrasts** (treatments and covariates uncorrelated):\n- Type I, II, and III SS are identical\n- Order doesn't matter\n\nFor **unbalanced designs** (typical in real data):\n- Type III SS are preferred for hypothesis testing\n- Type I SS may give misleading results if covariates and treatments are correlated\n:::\n\n## ANCOVA in Observational Studies\n\n**Randomized experiments**:\n- Treatment assignment is random → groups balanced on covariates\n- ANCOVA mainly provides **precision gains**\n\n**Observational studies**:\n- Treatment assignment NOT random → groups may differ systematically\n- ANCOVA provides **bias reduction** and **confounding control**\n- BUT: Can only adjust for **measured** covariates!\n\n::: {.callout-warning}\n## Limitations of ANCOVA for Causal Inference\n\nANCOVA cannot adjust for **unmeasured confounders**:\n- If other important variables differ between groups and aren't included as covariates, bias remains\n- ANCOVA is NOT a substitute for randomization\n- In observational studies, interpret causally with caution\n\n**Better for causal inference**:\n- Propensity score matching\n- Instrumental variables\n- Regression discontinuity designs\n- Difference-in-differences\n\n**But**: ANCOVA is still valuable for reducing known confounding and increasing precision\n:::\n\n---\n\n# Summary and Key Takeaways\n\n::: {.callout-important}\n## What We Learned This Week\n\n### Conceptual\n\n1. **ANCOVA = ANOVA + Regression**: Combines categorical treatments with continuous covariates\n2. **Three purposes**: (1) Increase precision, (2) Adjust means, (3) Control confounding\n3. **Adjusted means** answer: \"What if all groups had the same covariate value?\"\n4. **Homogeneity of slopes** is a critical assumption that MUST be tested\n\n### Mathematical\n\n5. **ANCOVA model**: $y_{ij} = \\mu + \\alpha_i + \\beta(x_{ij} - \\bar{x}) + e_{ij}$\n6. **Design matrix** includes treatment indicators (0/1) and centered covariate\n7. **Normal equations**: $\\mathbf{X}'\\mathbf{X}\\mathbf{b} = \\mathbf{X}'\\mathbf{y}$, typically full rank\n8. **Adjusted mean formula**: $\\bar{y}_i^* = \\bar{y}_{i.} - b(\\bar{x}_{i.} - \\bar{x}_{..})$\n\n### Practical\n\n9. **Always test homogeneity first**: If violated, don't use standard ANCOVA\n10. **Use Type III SS** for hypothesis tests in unbalanced designs\n11. **Center covariates** for interpretability\n12. **ANCOVA increases power** when covariate explains substantial error variance\n\n### Applications in Animal Breeding\n\n13. **Adjust for age, weight, stage** when comparing breeds, lines, or treatments\n14. **Fair comparisons** require accounting for confounding variables\n15. **Precision matters** in costly animal experiments—ANCOVA helps\n:::\n\n## When to Use ANCOVA\n\n**Use ANCOVA when**:\n- Comparing treatment groups (categorical predictor)\n- AND a continuous covariate affects the response\n- AND covariate is pre-existing (not affected by treatment)\n- AND you want to adjust for covariate differences OR increase precision\n\n**Don't use ANCOVA when**:\n- Covariate is affected by treatment (post-treatment variable)\n- Homogeneity of slopes is violated (use separate slopes model)\n- Only interested in covariate effect (use simple regression)\n- No continuous covariate exists (use ANOVA)\n\n## Looking Ahead\n\n**Next week (Week 11)**: Model Diagnostics\n- Check ANCOVA assumptions (linearity, homoscedasticity, normality)\n- Detect outliers and influential observations\n- Validate homogeneity of slopes visually\n- Residual analysis for ANCOVA models\n\n**Future weeks**:\n- Week 12: Handling unbalanced data and rank deficiency\n- Week 14: Weighted least squares (when homoscedasticity violated)\n- Week 15: Capstone project integrating ANOVA, ANCOVA, and diagnostics\n\n---\n\n# Exercises\n\nSee [Week10_Exercises.qmd](Week10_Exercises.qmd) for practice problems.\n\n## Exercise Preview\n\n1. **Hand calculation**: Fit ANCOVA for 4 treatments, n=3 each, one covariate\n2. **Compute adjusted means**: Given ANCOVA estimates, calculate adjusted treatment means\n3. **Test homogeneity**: Use F-test formula to test parallel slopes assumption\n4. **Layer hen data**: Analyze egg production by strain, adjusting for body weight\n5. **Beef cattle data**: Analyze carcass weight by sire, adjusting for slaughter age\n6. **Swine data**: Analyze backfat by genetic line, adjusting for live weight\n7. **Theoretical proof**: Prove adjusted means sum to overall mean (weighted)\n\nFull solutions provided in [Week10_Solutions.qmd](Week10_Solutions.qmd).\n\n---\n\n# References\n\nKey papers and textbooks on ANCOVA in animal breeding:\n\n- Henderson, C. R. (1984). *Applications of Linear Models in Animal Breeding*. University of Guelph.\n- Searle, S. R., Casella, G., & McCulloch, C. E. (1992). *Variance Components*. Wiley.\n- Milliken, G. A., & Johnson, D. E. (2009). *Analysis of Messy Data: Volume 1, Designed Experiments*. CRC Press.\n- Montgomery, D. C. (2017). *Design and Analysis of Experiments*. 9th ed. Wiley.\n\nSee full bibliography in [references.bib](../references.bib).\n\n---\n\n**Previous**: [Week 9: Two-Way ANOVA](../Week09_TwoWayANOVA/Week09_TwoWayANOVA.qmd)\n\n**Next**: [Week 11: Model Diagnostics](../Week11_Diagnostics/Week11_Diagnostics.qmd)\n",
    "supporting": [
      "Week10_ANCOVA_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}