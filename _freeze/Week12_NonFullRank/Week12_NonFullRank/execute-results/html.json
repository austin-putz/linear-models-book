{
  "hash": "669c3af1843ee837143eab93c22013f1",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Week 12: Unequal Subclass Numbers & Non-Full Rank Models\"\nformat:\n  html:\n    toc: true\n    toc-depth: 3\n    number-sections: true\n    code-fold: false\n    code-tools: true\nbibliography: ../references.bib\n---\n\n::: {.callout-note icon=false}\n## Learning Objectives\n\nBy the end of this week, you will be able to:\n\n1. **Understand** the consequences of **unbalanced data** on **design matrix rank** and the resulting impact on **parameter estimation**\n2. **Compute** and **use** **generalized inverses** to solve **normal equations** when $\\mathbf{X}'\\mathbf{X}$ is singular\n3. **Determine** which **linear functions of parameters** are **estimable** in **rank-deficient models** using the **row space criterion**\n4. **Apply** **constraints** (set-to-zero, sum-to-zero) to obtain **unique parameter solutions** and interpret their effects\n5. **Analyze** realistic **multi-farm livestock datasets** with **missing cells** using appropriate methods (**Type III SS**, **estimable contrasts**, `emmeans`)\n:::\n\n---\n\n## Introduction: When Real Data Gets Messy\n\nIn Weeks 7 and 8, we worked primarily with balanced designs where every group had equal sample sizes. The mathematics was clean: $\\mathbf{X}'\\mathbf{X}$ was full rank, orthogonal contrasts partitioned sums of squares neatly, and every parameter was uniquely estimable. Real livestock data is rarely so cooperative.\n\nConsider these common scenarios in animal breeding and genetics:\n\n- **Sire evaluation**: Some bulls have 3 progeny records, others have 500. Dairy genetic evaluations routinely handle sires with vastly different progeny group sizes.\n- **Multi-farm breed comparisons**: Not all breeds are raised on all farms. A Charolais breeder in Texas may not also raise Holsteins.\n- **Longitudinal studies**: Animal mortality and dropout create unbalanced groups. A 24-month feeding trial that starts with equal groups rarely ends that way.\n- **Commercial records**: Observational data from commercial operations is inherently unbalanced. Farmers make decisions—culling, treatment, grouping—that create inequality.\n\nWhen data is unbalanced, three critical things happen:\n\n1. **$\\mathbf{X}'\\mathbf{X}$ may not be full rank** → The normal equations have infinitely many solutions\n2. **Type I, II, and III sums of squares differ** → The order of fitting effects matters\n3. **Individual parameters may not be estimable** → But contrasts (differences) often are\n\nThis week, we confront the reality of unbalanced data head-on. We'll learn:\n\n- Why rank deficiency occurs and what it means\n- How to solve singular systems using generalized inverses\n- Which functions are estimable and which are not\n- How to use constraints to get unique solutions\n- Practical methods for analyzing real unbalanced datasets\n\n::: {.callout-important}\n### Why This Week Matters in Animal Breeding\n\nIn real animal breeding programs:\n\n- **Sires have 3 to 500+ progeny** (progeny test designs are highly unbalanced)\n- **Contemporary groups vary** from 5 to 200 animals\n- **Some breed × environment combinations never occur** (climate, management, economics)\n- **Missing data is the norm**, not the exception\n\nUnderstanding rank deficiency and estimability is not academic—it's essential for genetic evaluation, breed comparisons, and making sound breeding decisions from messy commercial data.\n:::\n\n::: {.callout-note}\n### Connection to Previous Weeks\n\nThis week synthesizes concepts from:\n\n- **Week 2**: Generalized inverses (now we use them!)\n- **Week 7**: Cell means vs. effects models (now unbalanced)\n- **Week 8**: Estimable functions and contrasts (critical when rank deficient)\n- **Week 10**: Type I/II/III sums of squares (essential for unbalanced ANOVA)\n\nWeek 12 is where all these pieces unite to handle real-world complexity.\n:::\n\n### Chapter Roadmap\n\nHere's what we'll cover:\n\n1. **Mathematical Theory** (Sections 2-5): Rank deficiency, generalized inverses, estimability, constraints\n2. **Small Example** (Section 6): Sheep fleece weight by breed (n=3,2,1) – hand-calculable\n3. **R Implementation** (Section 7): Building solvers that handle singular systems\n4. **Realistic Application** (Section 8): Multi-farm beef cattle with missing cells (n=177)\n5. **Practical Guidelines** (Section 9): What to do when you encounter unbalanced data\n\nBy the end, you'll be equipped to handle the messy reality of livestock data with confidence.\n\n---\n\n## Mathematical Theory of Rank Deficiency\n\n### Rank Deficiency in Linear Models\n\nRecall the **effects model** for one-way ANOVA:\n\n$$\ny_{ij} = \\mu + \\alpha_i + e_{ij}\n$$ {#eq-effects-model}\n\nwhere:\n\n- $y_{ij}$: observation $j$ in group $i$ (scalar)\n- $\\mu$: overall mean (scalar parameter)\n- $\\alpha_i$: effect of group $i$ (scalar parameter, $i = 1, \\ldots, g$)\n- $e_{ij}$: random error, $e_{ij} \\sim N(0, \\sigma^2)$\n\nIn matrix form:\n\n$$\n\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{e}\n$$ {#eq-matrix-form}\n\nwhere:\n\n- $\\mathbf{y}$: $n \\times 1$ response vector\n- $\\mathbf{X}$: $n \\times (g+1)$ design matrix\n- $\\boldsymbol{\\beta} = [\\mu, \\alpha_1, \\alpha_2, \\ldots, \\alpha_g]'$: $(g+1) \\times 1$ parameter vector\n- $\\mathbf{e}$: $n \\times 1$ error vector\n\nFor a 3-group study with $n_1=3, n_2=2, n_3=1$ observations:\n\n$$\n\\mathbf{X} = \\begin{bmatrix}\n1 & 1 & 0 & 0 \\\\\n1 & 1 & 0 & 0 \\\\\n1 & 1 & 0 & 0 \\\\\n1 & 0 & 1 & 0 \\\\\n1 & 0 & 1 & 0 \\\\\n1 & 0 & 0 & 1\n\\end{bmatrix}_{6 \\times 4}\n$$ {#eq-design-matrix-effects}\n\n**The problem**: Column 1 (intercept) equals the sum of columns 2, 3, and 4:\n\n$$\n\\text{Column 1} = \\text{Column 2} + \\text{Column 3} + \\text{Column 4}\n$$\n\nTherefore: $r(\\mathbf{X}) = 3 < 4 = p$ (number of parameters)\n\nThe design matrix **does not have full column rank**. This is not a numerical precision issue—it's structural. The model has **inherent redundancy**: we cannot simultaneously estimate both $\\mu$ and all $\\alpha_i$ because they are **confounded**.\n\n::: {.callout-warning}\n### Rank Deficiency is Structural, Not Numerical\n\nThis is not computational roundoff error. The model\n\n$$y_{ij} = \\mu + \\alpha_i + e_{ij}$$\n\nhas **inherent redundancy**:\n\n- We cannot estimate both $\\mu$ and all $\\alpha_i$ uniquely\n- The intercept and group effects are **confounded**\n- For any solution, we can add a constant to $\\mu$ and subtract it from all $\\alpha_i$—the fit doesn't change\n\nThis requires either:\n1. Using a different parameterization (cell means model)\n2. Imposing constraints to remove redundancy\n3. Focusing only on estimable functions (contrasts)\n:::\n\n### Consequences for the Normal Equations\n\nWhen $r(\\mathbf{X}'\\mathbf{X}) < p$, the normal equations\n\n$$\n\\mathbf{X}'\\mathbf{X}\\mathbf{b} = \\mathbf{X}'\\mathbf{y}\n$$ {#eq-normal-equations}\n\nhave the following properties:\n\n1. **$\\mathbf{X}'\\mathbf{X}$ is singular** (not invertible): $\\det(\\mathbf{X}'\\mathbf{X}) = 0$\n2. **$(\\mathbf{X}'\\mathbf{X})^{-1}$ does not exist**: The regular inverse is undefined\n3. **Infinitely many solutions exist**: Any $\\mathbf{b}$ satisfying $\\mathbf{X}'\\mathbf{X}\\mathbf{b} = \\mathbf{X}'\\mathbf{y}$ is a solution\n4. **Individual parameter estimates are NOT unique**: Different solution methods give different $\\mathbf{b}$\n\nHowever—and this is critical:\n\n5. **Fitted values $\\hat{\\mathbf{y}} = \\mathbf{Xb}$ are unique**: All solutions give the same $\\hat{\\mathbf{y}}$\n6. **Residuals $\\mathbf{e} = \\mathbf{y} - \\hat{\\mathbf{y}}$ are unique**: All solutions give the same residuals\n7. **SSE is unique**: $SSE = \\mathbf{e}'\\mathbf{e}$ is the same for all solutions\n8. **Estimable functions $\\mathbf{c}'\\boldsymbol{\\beta}$ are unique**: If $\\mathbf{c}'\\boldsymbol{\\beta}$ is estimable, $\\mathbf{c}'\\mathbf{b}$ is the same for all solutions\n\n### Algebraic Proof of Uniqueness\n\n**Claim**: For any two solutions $\\mathbf{b}_1$ and $\\mathbf{b}_2$ to the normal equations, $\\mathbf{Xb}_1 = \\mathbf{Xb}_2$.\n\n**Proof**:\n\nBoth satisfy the normal equations:\n\n$$\n\\mathbf{X}'\\mathbf{X}\\mathbf{b}_1 = \\mathbf{X}'\\mathbf{y} \\quad \\text{and} \\quad \\mathbf{X}'\\mathbf{X}\\mathbf{b}_2 = \\mathbf{X}'\\mathbf{y}\n$$\n\nSubtracting:\n\n$$\n\\mathbf{X}'\\mathbf{X}(\\mathbf{b}_1 - \\mathbf{b}_2) = \\mathbf{0}\n$$\n\nPremultiplying by $(\\mathbf{b}_1 - \\mathbf{b}_2)'$:\n\n$$\n(\\mathbf{b}_1 - \\mathbf{b}_2)'\\mathbf{X}'\\mathbf{X}(\\mathbf{b}_1 - \\mathbf{b}_2) = 0\n$$\n\nBut $\\mathbf{X}'\\mathbf{X}$ is positive semidefinite, so:\n\n$$\n[\\mathbf{X}(\\mathbf{b}_1 - \\mathbf{b}_2)]'[\\mathbf{X}(\\mathbf{b}_1 - \\mathbf{b}_2)] = 0\n$$\n\nThis implies:\n\n$$\n\\mathbf{X}(\\mathbf{b}_1 - \\mathbf{b}_2) = \\mathbf{0}\n$$\n\nTherefore:\n\n$$\n\\mathbf{Xb}_1 = \\mathbf{Xb}_2\n$$\n\n**Conclusion**: Even though $\\mathbf{b}_1 \\neq \\mathbf{b}_2$, the fitted values are identical. $\\square$\n\n---\n\n### Generalized Inverses\n\nSince $(\\mathbf{X}'\\mathbf{X})^{-1}$ doesn't exist when $\\mathbf{X}'\\mathbf{X}$ is singular, we need an alternative: the **generalized inverse**.\n\n#### Definition\n\nA matrix $\\mathbf{G}$ is a **generalized inverse** of $\\mathbf{A}$ (denoted $\\mathbf{A}^-$) if:\n\n$$\n\\mathbf{A}\\mathbf{A}^-\\mathbf{A} = \\mathbf{A}\n$$ {#eq-ginv-definition}\n\nThis is the minimum requirement for a generalized inverse (also called a **reflexive g-inverse**).\n\n**Properties**:\n\n1. **Not unique** for singular matrices: Many matrices satisfy @eq-ginv-definition\n2. **Reduces to regular inverse** when $\\mathbf{A}$ is nonsingular: If $\\mathbf{A}$ is full rank, $\\mathbf{A}^- = \\mathbf{A}^{-1}$\n3. **Provides a solution** to consistent systems: If $\\mathbf{Ab} = \\mathbf{c}$ is consistent, then $\\mathbf{b} = \\mathbf{A}^-\\mathbf{c}$ is a solution\n\n### Using G-Inverse to Solve Normal Equations\n\nFor $\\mathbf{X}'\\mathbf{X}\\mathbf{b} = \\mathbf{X}'\\mathbf{y}$, any solution has the form:\n\n$$\n\\mathbf{b} = (\\mathbf{X}'\\mathbf{X})^-\\mathbf{X}'\\mathbf{y}\n$$ {#eq-ginv-solution}\n\nwhere $(\\mathbf{X}'\\mathbf{X})^-$ is any generalized inverse of $\\mathbf{X}'\\mathbf{X}$.\n\n**Key verification**:\n\n$$\n\\mathbf{X}'\\mathbf{X}\\mathbf{b} = \\mathbf{X}'\\mathbf{X}[(\\mathbf{X}'\\mathbf{X})^-\\mathbf{X}'\\mathbf{y}] = \\mathbf{X}'\\mathbf{y} \\quad \\checkmark\n$$\n\n(using $\\mathbf{A}\\mathbf{A}^-\\mathbf{A} = \\mathbf{A}$ with $\\mathbf{A} = \\mathbf{X}'$)\n\n::: {.callout-important}\n### G-Inverse in Solving Normal Equations\n\nFor rank-deficient normal equations $\\mathbf{X}'\\mathbf{X}\\mathbf{b} = \\mathbf{X}'\\mathbf{y}$:\n\n$$\n\\mathbf{b} = (\\mathbf{X}'\\mathbf{X})^-\\mathbf{X}'\\mathbf{y}\n$$\n\n**Critical insights**:\n\n1. Different choices of $(\\mathbf{X}'\\mathbf{X})^-$ give **different $\\mathbf{b}$**\n2. But **$\\mathbf{Xb}$ is always the same** (fitted values unique)\n3. **Estimable functions $\\mathbf{c}'\\mathbf{b}$ are always the same** (if $\\mathbf{c}'\\boldsymbol{\\beta}$ is estimable)\n4. Non-estimable functions $\\mathbf{c}'\\mathbf{b}$ **depend on which $(\\mathbf{X}'\\mathbf{X})^-$ you use**\n\nIn practice: Use any g-inverse for computation, but **only interpret estimable functions**.\n:::\n\n### The Moore-Penrose Pseudoinverse\n\nAmong all generalized inverses, one is special: the **Moore-Penrose pseudoinverse** (denoted $\\mathbf{A}^+$).\n\nIt's the unique matrix satisfying four properties:\n\n1. $\\mathbf{A}\\mathbf{A}^+\\mathbf{A} = \\mathbf{A}$ (reflexive)\n2. $\\mathbf{A}^+\\mathbf{A}\\mathbf{A}^+ = \\mathbf{A}^+$ (minimum norm)\n3. $(\\mathbf{A}\\mathbf{A}^+)' = \\mathbf{A}\\mathbf{A}^+$ (symmetric)\n4. $(\\mathbf{A}^+\\mathbf{A})' = \\mathbf{A}^+\\mathbf{A}$ (symmetric)\n\n**Uniqueness**: Only one matrix satisfies all four properties.\n\n**Computation via SVD**: If $\\mathbf{A} = \\mathbf{U}\\mathbf{D}\\mathbf{V}'$ (singular value decomposition), then:\n\n$$\n\\mathbf{A}^+ = \\mathbf{V}\\mathbf{D}^+\\mathbf{U}'\n$$\n\nwhere $\\mathbf{D}^+$ replaces each nonzero singular value $d_i$ with $1/d_i$.\n\n**In R**: Use `MASS::ginv(A)` which computes the Moore-Penrose inverse.\n\n::: {.callout-tip}\n### Computing G-Inverses in R\n\n```r\nlibrary(MASS)\n\n# Compute Moore-Penrose inverse\nA_ginv <- ginv(A)\n\n# Verify the property AA⁻A = A\nmax(abs(A %*% A_ginv %*% A - A))  # Should be ≈ 0 (numerical precision)\n\n# Solve normal equations\nXtX <- t(X) %*% X\nXty <- t(X) %*% y\nb <- ginv(XtX) %*% Xty\n```\n\n**Note**: Any g-inverse works for solving normal equations. `ginv()` is convenient and gives the minimum-norm solution.\n:::\n\n---\n\n## Estimability Revisited\n\nIn Week 8, we introduced estimable functions for balanced designs. With unbalanced data and rank deficiency, estimability becomes critical.\n\n### Formal Definition\n\nA linear function $\\mathbf{c}'\\boldsymbol{\\beta}$ is **estimable** if and only if:\n\n$$\n\\mathbf{c}' = \\mathbf{a}'\\mathbf{X} \\quad \\text{for some vector } \\mathbf{a}\n$$ {#eq-estimability-criterion}\n\n**Equivalently**: $\\mathbf{c}$ is in the **row space of $\\mathbf{X}$**.\n\n**Intuition**: Estimable functions are those that can be expressed as linear combinations of the rows of $\\mathbf{X}$—i.e., they're \"built into\" the design.\n\n### Critical Theorem on Estimability\n\n**Theorem**: If $\\mathbf{c}'\\boldsymbol{\\beta}$ is estimable, then:\n\n1. **$\\mathbf{c}'\\mathbf{b}$ is unique** (independent of which $(\\mathbf{X}'\\mathbf{X})^-$ is used)\n2. **$\\text{Var}(\\mathbf{c}'\\mathbf{b}) = \\mathbf{c}'(\\mathbf{X}'\\mathbf{X})^-\\mathbf{c} \\sigma^2$ is unique**\n3. **$\\mathbf{c}'\\mathbf{b}$ is BLUE** of $\\mathbf{c}'\\boldsymbol{\\beta}$ (Best Linear Unbiased Estimator)\n\n**Proof sketch**:\n\nFor any two g-inverses $\\mathbf{G}_1$ and $\\mathbf{G}_2$ of $\\mathbf{X}'\\mathbf{X}$:\n\n- Solutions: $\\mathbf{b}_1 = \\mathbf{G}_1\\mathbf{X}'\\mathbf{y}$ and $\\mathbf{b}_2 = \\mathbf{G}_2\\mathbf{X}'\\mathbf{y}$\n- If $\\mathbf{c}'\\boldsymbol{\\beta}$ estimable: $\\mathbf{c}' = \\mathbf{a}'\\mathbf{X}$\n- Then: $\\mathbf{c}'\\mathbf{b}_1 = \\mathbf{a}'\\mathbf{X}\\mathbf{b}_1 = \\mathbf{a}'\\hat{\\mathbf{y}}$\n- And: $\\mathbf{c}'\\mathbf{b}_2 = \\mathbf{a}'\\mathbf{X}\\mathbf{b}_2 = \\mathbf{a}'\\hat{\\mathbf{y}}$\n- Since $\\hat{\\mathbf{y}} = \\mathbf{Xb}$ is unique, $\\mathbf{c}'\\mathbf{b}_1 = \\mathbf{c}'\\mathbf{b}_2$ $\\square$\n\n::: {.callout-important}\n### Testing Estimability in R\n\n```r\nis_estimable <- function(c, X, tol = 1e-10) {\n  # Test if c'β is estimable\n  # c'β estimable ⟺ c in row space of X\n  # ⟺ (X'X)⁻c in column space of X'X\n  # ⟺ (X'X)(X'X)⁻c = c\n\n  XtX <- t(X) %*% X\n  XtX_ginv <- ginv(XtX)\n  projection <- XtX %*% XtX_ginv %*% c\n\n  all(abs(projection - c) < tol)\n}\n\n# Example usage\nc1 <- c(0, 1, -1, 0)  # α₁ - α₂\nis_estimable(c1, X)   # TRUE\n\nc2 <- c(1, 0, 0, 0)   # μ\nis_estimable(c2, X)   # FALSE\n```\n\nThis function checks the criterion: $\\mathbf{c}'\\boldsymbol{\\beta}$ is estimable iff $(\\mathbf{X}'\\mathbf{X})(\\mathbf{X}'\\mathbf{X})^-\\mathbf{c} = \\mathbf{c}$.\n:::\n\n### Examples: Estimable vs. Non-Estimable\n\nFor the effects model $y_{ij} = \\mu + \\alpha_i + e_{ij}$ with 3 groups:\n\n**Non-Estimable**:\n\n- $\\mu$ (overall mean): Confounded with $\\alpha_i$\n- $\\alpha_1$ (group 1 effect): Not uniquely defined\n- Individual $\\alpha_i$ values\n\n**Estimable**:\n\n- $\\alpha_1 - \\alpha_2$ (difference between groups 1 and 2)\n- $\\alpha_1 - \\alpha_3$ (difference between groups 1 and 3)\n- $(\\alpha_1 + \\alpha_2)/2 - \\alpha_3$ (average of groups 1,2 vs. group 3)\n- Any contrast $\\sum c_i \\alpha_i$ where $\\sum c_i = 0$\n- Group means $\\mu_i = \\mu + \\alpha_i$ (these are what we observe!)\n\n**General rule**: In the effects model with rank deficiency:\n\n- Individual $\\mu$ and $\\alpha_i$ are **not** estimable\n- Contrasts $\\sum c_i \\alpha_i$ with $\\sum c_i = 0$ **are** estimable\n- Group means $\\mu_i = \\mu + \\alpha_i$ **are** estimable\n\n---\n\n## Constraints for Identifiability\n\nWe've seen that rank deficiency leads to non-unique parameter estimates. One way to resolve this: **impose constraints** that remove the redundancy.\n\n### Common Constraint Types\n\n**1. Set-to-zero constraints** (reference cell coding):\n\nSet one parameter to zero, e.g., $\\alpha_g = 0$.\n\n- Interpretation: Other $\\alpha_i$ are deviations from group $g$\n- R default: `lm()` uses this with first level as reference\n\n**2. Sum-to-zero constraints**:\n\n$$\\sum_{i=1}^g \\alpha_i = 0$$ {#eq-sum-to-zero}\n\n- Interpretation: $\\alpha_i$ are deviations from overall mean\n- More symmetric than set-to-zero\n- Useful for balanced designs\n\n**3. Weighted sum-to-zero constraints**:\n\n$$\\sum_{i=1}^g n_i \\alpha_i = 0$$ {#eq-weighted-sum}\n\n- Accounts for unequal group sizes\n- Each group weighted by sample size\n\n::: {.callout-note}\n### Constraints vs. G-Inverses: Two Paths, Same Destination\n\nTwo equivalent approaches to handle rank deficiency:\n\n**Approach 1**: Use constraints to achieve full rank\n\n- Augment normal equations with constraint rows\n- Solve augmented system for unique $\\mathbf{b}$\n\n**Approach 2**: Use g-inverse, focus on estimable functions\n\n- Solve $\\mathbf{b} = (\\mathbf{X}'\\mathbf{X})^-\\mathbf{X}'\\mathbf{y}$ for any solution\n- Only interpret estimable $\\mathbf{c}'\\mathbf{b}$\n\n**Which to use?**\n\n- Constraints: Good when you want specific parameterization\n- G-inverse: Good when you only care about contrasts\n\n**Important**: Choice is computational/interpretational, **not statistical**. Estimable functions $\\mathbf{c}'\\mathbf{b}$ are the same either way.\n:::\n\n---\n\n## Small Example: Sheep Fleece Weight\n\nLet's work through a complete example small enough for hand calculations but rich enough to illustrate all concepts.\n\n### Problem Setup\n\n**Research question**: Compare fleece weight (kg) across three sheep breeds.\n\n**Data** (unbalanced):\n\n| Breed | Fleece Weight (kg) | Sample Size |\n|-------|-------------------|-------------|\n| Romney | 5.2, 5.4, 5.3 | $n_1 = 3$ |\n| Merino | 4.8, 5.0 | $n_2 = 2$ |\n| Corriedale | 5.6 | $n_3 = 1$ |\n\n**Total**: $n = 6$ observations\n\n**Note the unbalanced design**: Group sizes are 3, 2, and 1. This is realistic—perhaps Corriedale is a less common breed in the study region.\n\n::: {.callout-note}\n### Why This Example?\n\nThis example is pedagogically ideal:\n\n- **Small enough** for complete hand calculations\n- **Unbalanced** (3, 2, 1) shows rank deficiency clearly\n- **Realistic**: Breed comparison with unequal representation\n- Demonstrates both **cell means** (full rank) and **effects** (rank deficient) models\n- Illustrates **estimability**: What can and can't be uniquely estimated\n:::\n\n---\n\n### Cell Means Model (Full Rank)\n\n**Model**:\n$$y_{ij} = \\mu_i + e_{ij}$$\n\nwhere $\\mu_i$ is the mean for breed $i$ (no overall $\\mu$, no $\\alpha_i$).\n\n#### Step 1: Design Matrix\n\n$$\n\\mathbf{X} = \\begin{bmatrix}\n1 & 0 & 0 \\\\\n1 & 0 & 0 \\\\\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 0 & 1\n\\end{bmatrix}_{6 \\times 3}, \\quad\n\\boldsymbol{\\beta} = \\begin{bmatrix}\n\\mu_1 \\\\\n\\mu_2 \\\\\n\\mu_3\n\\end{bmatrix}\n$$\n\n**Check rank**: $r(\\mathbf{X}) = 3 = p$ → **Full rank!**\n\nThe cell means model is **always full rank**, even with unbalanced data.\n\n#### Step 2: Normal Equations\n\n$$\n\\mathbf{X}'\\mathbf{X} = \\begin{bmatrix}\n3 & 0 & 0 \\\\\n0 & 2 & 0 \\\\\n0 & 0 & 1\n\\end{bmatrix}, \\quad\n\\mathbf{X}'\\mathbf{y} = \\begin{bmatrix}\n15.9 \\\\\n9.8 \\\\\n5.6\n\\end{bmatrix}\n$$\n\n**Note**: $\\mathbf{X}'\\mathbf{X}$ is **diagonal** (always true for cell means, even unbalanced).\n\n#### Step 3: Solve\n\nSince $\\mathbf{X}'\\mathbf{X}$ is diagonal and invertible:\n\n$$\n(\\mathbf{X}'\\mathbf{X})^{-1} = \\begin{bmatrix}\n1/3 & 0 & 0 \\\\\n0 & 1/2 & 0 \\\\\n0 & 0 & 1\n\\end{bmatrix}\n$$\n\nSolution:\n\n$$\n\\mathbf{b} = (\\mathbf{X}'\\mathbf{X})^{-1}\\mathbf{X}'\\mathbf{y} = \\begin{bmatrix}\n15.9/3 \\\\\n9.8/2 \\\\\n5.6/1\n\\end{bmatrix} = \\begin{bmatrix}\n5.30 \\\\\n4.90 \\\\\n5.60\n\\end{bmatrix}\n$$\n\n**Interpretation**:\n\n- $\\hat{\\mu}_1 = 5.30$ kg (Romney mean)\n- $\\hat{\\mu}_2 = 4.90$ kg (Merino mean)\n- $\\hat{\\mu}_3 = 5.60$ kg (Corriedale mean)\n\n**These are just the group means!** The cell means model directly estimates what we observe.\n\n#### Step 4: Residuals and SSE\n\nFitted values:\n\n$$\n\\hat{\\mathbf{y}} = \\mathbf{Xb} = [5.30, 5.30, 5.30, 4.90, 4.90, 5.60]'\n$$\n\nResiduals:\n\n$$\n\\mathbf{e} = \\mathbf{y} - \\hat{\\mathbf{y}} = [5.2-5.30, 5.4-5.30, 5.3-5.30, 4.8-4.90, 5.0-4.90, 5.6-5.60]'\n$$\n$$\n= [-0.10, 0.10, 0.00, -0.10, 0.10, 0.00]'\n$$\n\nSSE:\n\n$$\nSSE = \\mathbf{e}'\\mathbf{e} = (-0.10)^2 + (0.10)^2 + 0^2 + (-0.10)^2 + (0.10)^2 + 0^2 = 0.04 \\text{ kg}^2\n$$\n\nMSE (degrees of freedom = $n - p = 6 - 3 = 3$):\n\n$$\n\\hat{\\sigma}^2 = MSE = \\frac{SSE}{n-p} = \\frac{0.04}{3} = 0.0133 \\text{ kg}^2\n$$\n\n---\n\n### Effects Model (Rank Deficient)\n\n**Model**:\n$$y_{ij} = \\mu + \\alpha_i + e_{ij}$$\n\nThis is the traditional ANOVA parameterization.\n\n#### Step 1: Design Matrix\n\n$$\n\\mathbf{X} = \\begin{bmatrix}\n1 & 1 & 0 & 0 \\\\\n1 & 1 & 0 & 0 \\\\\n1 & 1 & 0 & 0 \\\\\n1 & 0 & 1 & 0 \\\\\n1 & 0 & 1 & 0 \\\\\n1 & 0 & 0 & 1\n\\end{bmatrix}_{6 \\times 4}, \\quad\n\\boldsymbol{\\beta} = \\begin{bmatrix}\n\\mu \\\\\n\\alpha_1 \\\\\n\\alpha_2 \\\\\n\\alpha_3\n\\end{bmatrix}\n$$\n\n**Check dependencies**:\n\nColumn 1 = Column 2 + Column 3 + Column 4\n\nTherefore: $r(\\mathbf{X}) = 3 < 4 = p$ → **NOT full rank**\n\n::: {.callout-warning}\n### Rank Deficiency Identified\n\nThe effects model $y_{ij} = \\mu + \\alpha_i + e_{ij}$ has:\n\n- $r(\\mathbf{X}) = 3$ but $p = 4$ parameters\n- Normal equations have **infinitely many solutions**\n- Cannot uniquely estimate $\\mu, \\alpha_1, \\alpha_2, \\alpha_3$\n- For any solution, we can add constant $c$ to $\\mu$ and subtract $c$ from all $\\alpha_i$—fit unchanged\n\n**But**: Contrasts like $\\alpha_1 - \\alpha_2$ ARE uniquely estimable.\n:::\n\n#### Step 2: Normal Equations (Singular System)\n\n$$\n\\mathbf{X}'\\mathbf{X} = \\begin{bmatrix}\n6 & 3 & 2 & 1 \\\\\n3 & 3 & 0 & 0 \\\\\n2 & 0 & 2 & 0 \\\\\n1 & 0 & 0 & 1\n\\end{bmatrix}_{4 \\times 4}, \\quad\n\\mathbf{X}'\\mathbf{y} = \\begin{bmatrix}\n31.9 \\\\\n15.9 \\\\\n9.8 \\\\\n5.6\n\\end{bmatrix}\n$$\n\nCheck: $\\det(\\mathbf{X}'\\mathbf{X}) = 0$ (singular)\n\n#### Step 3: Two G-Inverse Solutions\n\nWe'll solve using two different approaches to show non-uniqueness of $\\mathbf{b}$ but uniqueness of estimable functions.\n\n##### Approach 1: Set-to-Zero Constraint ($\\alpha_3 = 0$)\n\nImpose $\\alpha_3 = 0$. This removes the last parameter, giving a 3×3 system:\n\n$$\n\\begin{bmatrix}\n6 & 3 & 2 \\\\\n3 & 3 & 0 \\\\\n2 & 0 & 2\n\\end{bmatrix}\n\\begin{bmatrix}\n\\mu \\\\\n\\alpha_1 \\\\\n\\alpha_2\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n31.9 \\\\\n15.9 \\\\\n9.8\n\\end{bmatrix}\n$$\n\nSolve (by hand or calculator):\n\n$$\n\\begin{bmatrix}\n\\mu \\\\\n\\alpha_1 \\\\\n\\alpha_2\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n5.60 \\\\\n-0.30 \\\\\n-0.70\n\\end{bmatrix}, \\quad \\alpha_3 = 0\n$$\n\n**Solution 1**: $\\mathbf{b}_1 = [5.60, -0.30, -0.70, 0.00]'$\n\n**Interpretation** (under this constraint):\n\n- $\\hat{\\mu} = 5.60$ kg (but this equals $\\mu_3$—the Corriedale mean!)\n- $\\hat{\\alpha}_1 = -0.30$ kg (Romney is 0.30 kg below Corriedale)\n- $\\hat{\\alpha}_2 = -0.70$ kg (Merino is 0.70 kg below Corriedale)\n- $\\hat{\\alpha}_3 = 0$ (reference breed)\n\n**Group means** (check against cell means model):\n\n- Romney: $\\mu + \\alpha_1 = 5.60 + (-0.30) = 5.30$ ✓\n- Merino: $\\mu + \\alpha_2 = 5.60 + (-0.70) = 4.90$ ✓\n- Corriedale: $\\mu + \\alpha_3 = 5.60 + 0 = 5.60$ ✓\n\n::: {.callout-important}\n### Cell Means vs. Effects: Key Lesson\n\n**Cell Means Model** ($y_{ij} = \\mu_i + e_{ij}$):\n\n- Always full rank, even with unbalanced data\n- All $\\mu_i$ are estimable\n- Directly estimates group means\n- Simplest for unbalanced data\n\n**Effects Model** ($y_{ij} = \\mu + \\alpha_i + e_{ij}$):\n\n- Rank deficient (need constraint)\n- Individual $\\mu, \\alpha_i$ not estimable\n- Contrasts $\\alpha_i - \\alpha_j$ ARE estimable\n- Useful when testing specific contrasts\n\n**For animal breeding**: We care about **differences** between breeds/sires/treatments, not absolute values. Estimable contrasts are what matter.\n:::\n\n---\n\n## R Implementation: Sheep Fleece Example\n\nNow let's implement these analyses in R, building our own solvers and verifying against `lm()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load packages\nlibrary(MASS)     # For ginv()\nlibrary(ggplot2)  # For plotting\nlibrary(knitr)    # For tables\n\n# Load data\nsheep <- read.csv(\"data/sheep_fleece_unbalanced.csv\")\n\n# Inspect\nhead(sheep)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|breed      | fleece_weight|\n|:----------|-------------:|\n|Romney     |           5.2|\n|Romney     |           5.4|\n|Romney     |           5.3|\n|Merino     |           4.8|\n|Merino     |           5.0|\n|Corriedale |           5.6|\n\n</div>\n:::\n\n```{.r .cell-code}\ntable(sheep$breed)  # Unbalanced: 3, 2, 1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCorriedale     Merino     Romney \n         1          2          3 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Summary statistics by breed\nlibrary(dplyr)\nsheep %>%\n  group_by(breed) %>%\n  summarise(\n    n = n(),\n    mean = mean(fleece_weight),\n    sd = sd(fleece_weight)\n  )\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|breed      |  n| mean|        sd|\n|:----------|--:|----:|---------:|\n|Corriedale |  1|  5.6|        NA|\n|Merino     |  2|  4.9| 0.1414214|\n|Romney     |  3|  5.3| 0.1000000|\n\n</div>\n:::\n\n```{.r .cell-code}\n# Create response vector and breed factor\ny <- sheep$fleece_weight\nbreed <- factor(sheep$breed)\nn <- length(y)\n```\n:::\n\n\n---\n\n### Cell Means Model in R\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Step 1: Build design matrix (cell means: no intercept)\nX_cell <- model.matrix(~ breed - 1, data = sheep)\ncolnames(X_cell) <- c(\"Corriedale\", \"Merino\", \"Romney\")\nX_cell  # Display\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Corriedale Merino Romney\n1          0      0      1\n2          0      0      1\n3          0      0      1\n4          0      1      0\n5          0      1      0\n6          1      0      0\nattr(,\"assign\")\n[1] 1 1 1\nattr(,\"contrasts\")\nattr(,\"contrasts\")$breed\n[1] \"contr.treatment\"\n```\n\n\n:::\n\n```{.r .cell-code}\n# Check rank\np <- ncol(X_cell)\nrank_X <- qr(X_cell)$rank\ncat(\"Rank of X (cell means):\", rank_X, \"= p =\", p, \"→ Full rank!\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRank of X (cell means): 3 = p = 3 → Full rank!\n```\n\n\n:::\n\n```{.r .cell-code}\n# Step 2: Normal equations\nXtX <- t(X_cell) %*% X_cell\nXty <- t(X_cell) %*% y\n\ncat(\"\\nX'X (diagonal for cell means):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nX'X (diagonal for cell means):\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(XtX)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           Corriedale Merino Romney\nCorriedale          1      0      0\nMerino              0      2      0\nRomney              0      0      3\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\nX'y:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nX'y:\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(Xty)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           [,1]\nCorriedale  5.6\nMerino      9.8\nRomney     15.9\n```\n\n\n:::\n\n```{.r .cell-code}\n# Step 3: Solve\nXtX_inv <- solve(XtX)\nb_cell <- XtX_inv %*% Xty\n\ncat(\"\\nEstimates (cell means model):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nEstimates (cell means model):\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(b_cell)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           [,1]\nCorriedale  5.6\nMerino      4.9\nRomney      5.3\n```\n\n\n:::\n\n```{.r .cell-code}\n# These should be group means\ncat(\"\\nGroup means (direct calculation):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nGroup means (direct calculation):\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(tapply(y, breed, mean))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCorriedale     Merino     Romney \n       5.6        4.9        5.3 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Step 4: Fitted values and residuals\ny_hat <- X_cell %*% b_cell\nresiduals <- y - y_hat\nSSE <- sum(residuals^2)\nMSE <- SSE / (n - p)\n\ncat(\"\\nSSE:\", SSE, \"kg²\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nSSE: 0.04 kg²\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"MSE:\", MSE, \"kg²\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMSE: 0.01333333 kg²\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Residual SD:\", sqrt(MSE), \"kg\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nResidual SD: 0.1154701 kg\n```\n\n\n:::\n\n```{.r .cell-code}\n# Compare with lm()\nfit_cell <- lm(fleece_weight ~ breed - 1, data = sheep)\ncat(\"\\nComparison with lm():\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nComparison with lm():\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Manual:\", b_cell, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nManual: 5.6 4.9 5.3 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"lm():  \", coef(fit_cell), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nlm():   5.6 4.9 5.3 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Match:\", all.equal(c(b_cell), coef(fit_cell)), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMatch: names for current but not for target \n```\n\n\n:::\n:::\n\n\n---\n\n### Effects Model with Set-to-Zero\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Effects model: lm() default (first level as reference)\nfit_effects <- lm(fleece_weight ~ breed, data = sheep)\n\ncat(\"Effects model (Corriedale = 0 reference):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nEffects model (Corriedale = 0 reference):\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(fit_effects)$coefficients\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            Estimate Std. Error   t value     Pr(>|t|)\n(Intercept)      5.6  0.1154701 48.497423 1.930414e-05\nbreedMerino     -0.7  0.1414214 -4.949747 1.582423e-02\nbreedRomney     -0.3  0.1333333 -2.250000 1.099381e-01\n```\n\n\n:::\n\n```{.r .cell-code}\n# Interpretation\ncat(\"\\nInterpretation:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nInterpretation:\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"μ (intercept):\", coef(fit_effects)[1], \"= Corriedale mean\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nμ (intercept): 5.6 = Corriedale mean\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"α_Merino:\", coef(fit_effects)[2], \"= Merino - Corriedale\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nα_Merino: -0.7 = Merino - Corriedale\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"α_Romney:\", coef(fit_effects)[3], \"= Romney - Corriedale\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nα_Romney: -0.3 = Romney - Corriedale\n```\n\n\n:::\n\n```{.r .cell-code}\n# Group means from effects model\ncat(\"\\nGroup means from effects model:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nGroup means from effects model:\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Corriedale:\", coef(fit_effects)[1], \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCorriedale: 5.6 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Merino:\", coef(fit_effects)[1] + coef(fit_effects)[2], \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMerino: 4.9 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Romney:\", coef(fit_effects)[1] + coef(fit_effects)[3], \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRomney: 5.3 \n```\n\n\n:::\n:::\n\n\n---\n\n### G-Inverse Approach\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Build full effects model X matrix\nX_effects <- model.matrix(~ breed, data = sheep)\ncolnames(X_effects) <- c(\"mu\", \"Merino\", \"Romney\")\nX_effects  # Display\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  mu Merino Romney\n1  1      0      1\n2  1      0      1\n3  1      0      1\n4  1      1      0\n5  1      1      0\n6  1      0      0\nattr(,\"assign\")\n[1] 0 1 1\nattr(,\"contrasts\")\nattr(,\"contrasts\")$breed\n[1] \"contr.treatment\"\n```\n\n\n:::\n\n```{.r .cell-code}\n# Check rank\nrank_X_effects <- qr(X_effects)$rank\np_effects <- ncol(X_effects)\ncat(\"Rank of X (effects):\", rank_X_effects, \"< p =\", p_effects, \"→ NOT full rank!\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRank of X (effects): 3 < p = 3 → NOT full rank!\n```\n\n\n:::\n\n```{.r .cell-code}\n# Normal equations (singular)\nXtX_effects <- t(X_effects) %*% X_effects\nXty_effects <- t(X_effects) %*% y\n\ncat(\"\\nX'X (effects model, singular):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nX'X (effects model, singular):\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(XtX_effects)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       mu Merino Romney\nmu      6      2      3\nMerino  2      2      0\nRomney  3      0      3\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\nDeterminant:\", det(XtX_effects), \"(= 0, singular)\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nDeterminant: 6 (= 0, singular)\n```\n\n\n:::\n\n```{.r .cell-code}\n# Solve using Moore-Penrose g-inverse\nXtX_ginv <- ginv(XtX_effects)\n\ncat(\"\\nMoore-Penrose g-inverse:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nMoore-Penrose g-inverse:\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(XtX_ginv)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     [,1] [,2]      [,3]\n[1,]    1 -1.0 -1.000000\n[2,]   -1  1.5  1.000000\n[3,]   -1  1.0  1.333333\n```\n\n\n:::\n\n```{.r .cell-code}\n# Verify property: AA⁻A = A\nverification <- XtX_effects %*% XtX_ginv %*% XtX_effects\nerror <- max(abs(verification - XtX_effects))\ncat(\"\\nVerification: ||X'X(X'X)⁻X'X - X'X|| =\", error, \"(should be ≈ 0)\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nVerification: ||X'X(X'X)⁻X'X - X'X|| = 3.552714e-15 (should be ≈ 0)\n```\n\n\n:::\n\n```{.r .cell-code}\n# Solution\nb_ginv <- XtX_ginv %*% Xty_effects\n\ncat(\"\\nSolution using g-inverse:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nSolution using g-inverse:\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(b_ginv)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     [,1]\n[1,]  5.6\n[2,] -0.7\n[3,] -0.3\n```\n\n\n:::\n\n```{.r .cell-code}\n# Fitted values (should be same as cell means)\ny_hat_ginv <- X_effects %*% b_ginv\n\ncat(\"\\nFitted values match cell means:\", all.equal(c(y_hat_ginv), c(y_hat)), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nFitted values match cell means: TRUE \n```\n\n\n:::\n:::\n\n\n---\n\n### Testing Estimability\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Custom function to test estimability\nis_estimable <- function(c, X, tol = 1e-10) {\n  XtX <- t(X) %*% X\n  XtX_ginv <- ginv(XtX)\n  projection <- XtX %*% XtX_ginv %*% c\n  all(abs(projection - c) < tol)\n}\n\n# Test various functions\ncat(\"Testing estimability (effects model):\\n\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTesting estimability (effects model):\n```\n\n\n:::\n\n```{.r .cell-code}\n# μ (intercept)\nc_mu <- c(1, 0, 0)\ncat(\"μ:\", is_estimable(c_mu, X_effects), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nμ: TRUE \n```\n\n\n:::\n\n```{.r .cell-code}\n# α_Merino\nc_a1 <- c(0, 1, 0)\ncat(\"α_Merino:\", is_estimable(c_a1, X_effects), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nα_Merino: TRUE \n```\n\n\n:::\n\n```{.r .cell-code}\n# α_Romney\nc_a2 <- c(0, 0, 1)\ncat(\"α_Romney:\", is_estimable(c_a2, X_effects), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nα_Romney: TRUE \n```\n\n\n:::\n\n```{.r .cell-code}\n# Contrast: α_Merino - α_Romney\nc_contrast1 <- c(0, 1, -1)\ncat(\"α_Merino - α_Romney:\", is_estimable(c_contrast1, X_effects), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nα_Merino - α_Romney: TRUE \n```\n\n\n:::\n\n```{.r .cell-code}\n# Contrast: Romney vs. reference (Corriedale)\n# In this parameterization, Corriedale is encoded as α=-sum(other α's)\n# To compare Romney vs Corriedale: α_Romney - α_Corriedale\n# But in the constraint where Corriedale is reference, this is just α_Romney\nc_contrast2 <- c(0, 0, 1)\nestimate1 <- t(c_contrast2) %*% coef(fit_effects)\ncat(\"\\nRomney vs. Corriedale (set-to-zero):\", estimate1, \"kg\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nRomney vs. Corriedale (set-to-zero): -0.3 kg\n```\n\n\n:::\n\n```{.r .cell-code}\n# Using g-inverse solution\nestimate2 <- t(c_contrast2) %*% b_ginv\ncat(\"Romney vs. Corriedale (g-inverse):  \", estimate2, \"kg\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRomney vs. Corriedale (g-inverse):   -0.3 kg\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\n→ Contrasts are estimable and unique!\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n→ Contrasts are estimable and unique!\n```\n\n\n:::\n:::\n\n\n::: {.callout-tip}\n### Practical Advice for One-Way ANOVA (Unbalanced)\n\n**Recommendation**: Use **cell means model** for unbalanced one-way ANOVA.\n\n**Why?**\n\n- Always full rank (no singularity issues)\n- Direct estimates of group means\n- Simple interpretation\n- No arbitrary constraints needed\n\n**When to use effects model?**\n\n- When testing specific planned contrasts\n- When ANOVA table with main effects is desired\n- When connecting to factorial designs (Week 9)\n\n**Bottom line**: For practical data analysis, cell means is simpler. For contrasts and theory, effects model with estimable functions.\n:::\n\n---\n\n## Realistic Application: Multi-Farm Beef Cattle\n\nNow let's apply these concepts to a realistic dataset with missing cells—a common scenario in multi-farm breeding evaluations.\n\n### Background and Data\n\n**Scenario**: Multi-farm evaluation of beef cattle breeds\n\n**Design**:\n\n- **4 breeds**: Angus, Hereford, Charolais, Simmental\n- **5 farms**: A, B, C, D, E\n- **20 possible breed × farm combinations**, but not all observed (missing cells)\n- **Response**: Average daily gain (ADG, kg/day) during feedlot period\n- **Total**: $n = 177$ steers\n\n**Why missing cells?**\n\n- Farms specialize: Some raise only British breeds, some only Continental\n- Economics: Not profitable to test all breeds everywhere\n- Climate adaptation: Some breeds unsuited to certain regions\n\nThis reflects real-world genetic evaluation data.\n\n::: {.callout-warning}\n### Real-World Complexity\n\nTypical of commercial livestock data:\n\n- **Uneven distribution** across locations\n- **Not all genotypes in all environments** (breed × farm interactions can't all be estimated)\n- **Some cells with zero observations** (breed × farm combinations that don't exist)\n\nStandard ANOVA assumptions (balanced, orthogonal) are violated. Must use:\n\n- **Type III SS** (each effect adjusted for others)\n- **Estimable contrasts** (only interpret breed differences within farms where both present)\n- **emmeans** package for marginal means\n:::\n\n---\n\n### Data Exploration\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load beef data\nbeef <- read.csv(\"data/beef_multifarm_unbalanced.csv\")\n\n# Inspect structure\nstr(beef)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t177 obs. of  4 variables:\n $ steer_id: int  1 2 3 4 5 6 7 8 9 10 ...\n $ breed   : chr  \"Angus\" \"Angus\" \"Angus\" \"Angus\" ...\n $ farm    : chr  \"A\" \"A\" \"A\" \"A\" ...\n $ adg     : num  1.12 1.15 1.08 1.18 1.14 1.1 1.16 1.13 1.11 1.17 ...\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(beef)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n| steer_id|breed |farm |  adg|\n|--------:|:-----|:----|----:|\n|        1|Angus |A    | 1.12|\n|        2|Angus |A    | 1.15|\n|        3|Angus |A    | 1.08|\n|        4|Angus |A    | 1.18|\n|        5|Angus |A    | 1.14|\n|        6|Angus |A    | 1.10|\n\n</div>\n:::\n\n```{.r .cell-code}\n# Sample sizes by breed and farm\ncat(\"Sample sizes (breed × farm):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSample sizes (breed × farm):\n```\n\n\n:::\n\n```{.r .cell-code}\ntable_breed_farm <- table(beef$breed, beef$farm)\nprint(table_breed_farm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           \n             A  B  C  D  E\n  Angus     18 20  0  8 11\n  Charolais 12  0 10  6  0\n  Hereford  15  0 14  7 13\n  Simmental  0 16 18  9  0\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\nTotal observations:\", nrow(beef), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nTotal observations: 177 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Summary statistics\ncat(\"\\nADG by breed:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nADG by breed:\n```\n\n\n:::\n\n```{.r .cell-code}\nbreed_summary <- beef %>%\n  group_by(breed) %>%\n  summarise(\n    n = n(),\n    mean = mean(adg),\n    sd = sd(adg)\n  )\nprint(breed_summary)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 4\n  breed         n  mean     sd\n  <chr>     <int> <dbl>  <dbl>\n1 Angus        57  1.16 0.0431\n2 Charolais    28  1.31 0.0323\n3 Hereford     49  1.04 0.0327\n4 Simmental    43  1.40 0.0432\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\nADG by farm:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nADG by farm:\n```\n\n\n:::\n\n```{.r .cell-code}\nfarm_summary <- beef %>%\n  group_by(farm) %>%\n  summarise(\n    n = n(),\n    mean = mean(adg),\n    sd = sd(adg)\n  )\nprint(farm_summary)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 4\n  farm      n  mean     sd\n  <chr> <int> <dbl>  <dbl>\n1 A        45  1.15 0.0990\n2 B        36  1.27 0.0872\n3 C        42  1.27 0.191 \n4 D        30  1.24 0.136 \n5 E        24  1.07 0.0460\n```\n\n\n:::\n\n```{.r .cell-code}\n# Grand mean\ncat(\"\\nGrand mean ADG:\", mean(beef$adg), \"kg/day\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nGrand mean ADG: 1.208475 kg/day\n```\n\n\n:::\n:::\n\n\n---\n\n### Visualization\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(gridExtra)\n\n# Boxplot by breed\np1 <- ggplot(beef, aes(x = breed, y = adg, fill = breed)) +\n  geom_boxplot() +\n  labs(title = \"ADG by Breed\", x = \"Breed\", y = \"ADG (kg/day)\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n# Boxplot by farm\np2 <- ggplot(beef, aes(x = farm, y = adg, fill = farm)) +\n  geom_boxplot() +\n  labs(title = \"ADG by Farm\", x = \"Farm\", y = \"ADG (kg/day)\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n# Side-by-side\ngrid.arrange(p1, p2, ncol = 2)\n```\n\n::: {.cell-output-display}\n![](Week12_NonFullRank_files/figure-html/beef-visualization-1.png){width=960}\n:::\n\n```{.r .cell-code}\n# Breed × farm interaction plot (only cells with data)\ncell_means <- aggregate(adg ~ breed + farm, data = beef, FUN = mean)\n\nggplot(cell_means, aes(x = farm, y = adg, color = breed, group = breed)) +\n  geom_line(size = 1) +\n  geom_point(size = 3) +\n  labs(title = \"Breed × Farm Interaction (cell means)\",\n       x = \"Farm\", y = \"ADG (kg/day)\", color = \"Breed\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](Week12_NonFullRank_files/figure-html/beef-visualization-2.png){width=960}\n:::\n:::\n\n\n**Observations**:\n\n- Continental breeds (Charolais, Simmental) have higher ADG than British breeds (Angus, Hereford)\n- Farm effects evident (B and C higher than E)\n- Lines cross → interaction possible (but confounded with missing cells)\n\n---\n\n### Model 1: Breed Only (Cell Means)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit breed-only model (cell means)\nfit_breed <- lm(adg ~ breed - 1, data = beef)\n\ncat(\"Model 1: ADG ~ Breed (cell means)\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 1: ADG ~ Breed (cell means)\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(fit_breed)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = adg ~ breed - 1, data = beef)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.083721 -0.029643 -0.001429  0.026279  0.086279 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \nbreedAngus     1.155088   0.005154   224.1   <2e-16 ***\nbreedCharolais 1.309643   0.007353   178.1   <2e-16 ***\nbreedHereford  1.041429   0.005559   187.4   <2e-16 ***\nbreedSimmental 1.403721   0.005934   236.6   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.03891 on 173 degrees of freedom\nMultiple R-squared:  0.999,\tAdjusted R-squared:  0.999 \nF-statistic: 4.325e+04 on 4 and 173 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n\n```{.r .cell-code}\n# Breed means\nbreed_means <- coef(fit_breed)\ncat(\"\\nBreed means (kg/day):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nBreed means (kg/day):\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(breed_means)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    breedAngus breedCharolais  breedHereford breedSimmental \n      1.155088       1.309643       1.041429       1.403721 \n```\n\n\n:::\n\n```{.r .cell-code}\n# ANOVA\ncat(\"\\nANOVA table:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nANOVA table:\n```\n\n\n:::\n\n```{.r .cell-code}\nanova(fit_breed)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|          |  Df|      Sum Sq|   Mean Sq|  F value| Pr(>F)|\n|:---------|---:|-----------:|---------:|--------:|------:|\n|breed     |   4| 261.9482744| 65.487069| 43253.74|      0|\n|Residuals | 173|   0.2619256|  0.001514|       NA|     NA|\n\n</div>\n:::\n\n```{.r .cell-code}\n# Interpretation\ncat(\"\\nInterpretation:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nInterpretation:\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"- Charolais highest ADG:\", breed_means[\"breedCharolais\"], \"kg/day\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n- Charolais highest ADG: 1.309643 kg/day\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"- Hereford lowest ADG:\", breed_means[\"breedHereford\"], \"kg/day\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n- Hereford lowest ADG: 1.041429 kg/day\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"- Difference:\", breed_means[\"breedCharolais\"] - breed_means[\"breedHereford\"], \"kg/day\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n- Difference: 0.2682143 kg/day\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\nBUT: This ignores farm effects! Breeds not equally distributed across farms.\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nBUT: This ignores farm effects! Breeds not equally distributed across farms.\n```\n\n\n:::\n:::\n\n\n**Problem**: Breed effects are confounded with farm effects because breeds aren't equally represented on all farms.\n\n---\n\n### Model 2: Additive (Breed + Farm)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit additive model\nfit_additive <- lm(adg ~ breed + farm, data = beef)\n\ncat(\"Model 2: ADG ~ Breed + Farm (additive)\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 2: ADG ~ Breed + Farm (additive)\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(fit_additive)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = adg ~ breed + farm, data = beef)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.087769 -0.024081  0.001364  0.026686  0.086396 \n\nCoefficients:\n                Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     1.147917   0.007075 162.253   <2e-16 ***\nbreedCharolais  0.149879   0.009404  15.938   <2e-16 ***\nbreedHereford  -0.110988   0.007889 -14.068   <2e-16 ***\nbreedSimmental  0.234847   0.008425  27.874   <2e-16 ***\nfarmB           0.021318   0.009322   2.287   0.0234 *  \nfarmC           0.020840   0.008734   2.386   0.0181 *  \nfarmD           0.020550   0.009061   2.268   0.0246 *  \nfarmE          -0.016549   0.009697  -1.707   0.0897 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.03728 on 169 degrees of freedom\nMultiple R-squared:  0.9368,\tAdjusted R-squared:  0.9342 \nF-statistic: 358.1 on 7 and 169 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n\n```{.r .cell-code}\n# Type I SS (sequential)\ncat(\"\\nType I SS (sequential):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nType I SS (sequential):\n```\n\n\n:::\n\n```{.r .cell-code}\nanova(fit_additive)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|          |  Df|    Sum Sq|   Mean Sq|    F value|    Pr(>F)|\n|:---------|---:|---------:|---------:|----------:|---------:|\n|breed     |   3| 3.4555625| 1.1518542| 828.986628| 0.0000000|\n|farm      |   4| 0.0271048| 0.0067762|   4.876811| 0.0009549|\n|Residuals | 169| 0.2348209| 0.0013895|         NA|        NA|\n\n</div>\n:::\n\n```{.r .cell-code}\n# Type III SS (each adjusted for others)\nlibrary(car)\ncat(\"\\nType III SS (each adjusted for others):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nType III SS (each adjusted for others):\n```\n\n\n:::\n\n```{.r .cell-code}\nAnova(fit_additive, type = 3)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|            |     Sum Sq|  Df|      F value|    Pr(>F)|\n|:-----------|----------:|---:|------------:|---------:|\n|(Intercept) | 36.5794313|   1| 26326.127352| 0.0000000|\n|breed       |  2.5437143|   3|   610.234979| 0.0000000|\n|farm        |  0.0271048|   4|     4.876811| 0.0009549|\n|Residuals   |  0.2348209| 169|           NA|        NA|\n\n</div>\n:::\n\n```{.r .cell-code}\ncat(\"\\n→ Note: Type I and Type III give different results!\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n→ Note: Type I and Type III give different results!\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"   With unbalanced data, order matters for Type I.\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   With unbalanced data, order matters for Type I.\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"   Type III tests each effect adjusted for the other.\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Type III tests each effect adjusted for the other.\n```\n\n\n:::\n:::\n\n\n::: {.callout-note}\n### Type I vs Type III SS\n\nWith unbalanced data, Type I and Type III SS differ:\n\n**Type I (Sequential)**:\n\n- SS(Breed | Intercept), then SS(Farm | Breed)\n- Order matters! SS(A|B) ≠ SS(B|A)\n- Depends on order effects entered in model\n\n**Type III (Marginal)**:\n\n- SS(Breed | Farm) and SS(Farm | Breed)\n- Each effect adjusted for all others\n- Order-independent\n- **Preferred for unbalanced designs**\n\n**Recommendation**: Use **Type III** for testing with unbalanced data. It asks: \"Does breed matter after accounting for farm?\" and vice versa.\n:::\n\n---\n\n### Model 3: Interaction (Missing Cells)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit interaction model\nfit_interaction <- lm(adg ~ breed * farm, data = beef)\n\ncat(\"Model 3: ADG ~ Breed * Farm (interaction)\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 3: ADG ~ Breed * Farm (interaction)\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(fit_interaction)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = adg ~ breed * farm, data = beef)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.05000 -0.02000  0.00000  0.02111  0.05167 \n\nCoefficients: (6 not defined because of singularities)\n                       Estimate Std. Error t value Pr(>|t|)    \n(Intercept)           1.130e+00  6.368e-03 177.462  < 2e-16 ***\nbreedCharolais        1.683e-01  1.007e-02  16.720  < 2e-16 ***\nbreedHereford        -7.200e-02  9.445e-03  -7.623 1.93e-12 ***\nbreedSimmental        2.439e-01  1.313e-02  18.579  < 2e-16 ***\nfarmB                 7.000e-02  8.777e-03   7.975 2.53e-13 ***\nfarmC                 6.611e-02  1.592e-02   4.153 5.28e-05 ***\nfarmD                 2.500e-02  1.148e-02   2.178   0.0309 *  \nfarmE                -1.545e-02  1.034e-02  -1.495   0.1369    \nbreedCharolais:farmB         NA         NA      NA       NA    \nbreedHereford:farmB          NA         NA      NA       NA    \nbreedSimmental:farmB -7.826e-02  1.595e-02  -4.907 2.23e-06 ***\nbreedCharolais:farmC -4.944e-02  1.968e-02  -2.513   0.0130 *  \nbreedHereford:farmC  -1.105e-01  1.882e-02  -5.873 2.33e-08 ***\nbreedSimmental:farmC         NA         NA      NA       NA    \nbreedCharolais:farmD  2.836e-16  1.773e-02   0.000   1.0000    \nbreedHereford:farmD  -8.714e-03  1.687e-02  -0.516   0.6062    \nbreedSimmental:farmD         NA         NA      NA       NA    \nbreedCharolais:farmE         NA         NA      NA       NA    \nbreedHereford:farmE  -7.930e-03  1.455e-02  -0.545   0.5865    \nbreedSimmental:farmE         NA         NA      NA       NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.02702 on 163 degrees of freedom\nMultiple R-squared:  0.968,\tAdjusted R-squared:  0.9654 \nF-statistic: 379.3 on 13 and 163 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n\n```{.r .cell-code}\n# Check which coefficients are NA (non-estimable)\ncoefs <- coef(fit_interaction)\nna_coefs <- names(coefs)[is.na(coefs)]\n\ncat(\"\\nNon-estimable parameters (NA):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nNon-estimable parameters (NA):\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(na_coefs)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"breedCharolais:farmB\" \"breedHereford:farmB\"  \"breedSimmental:farmC\"\n[4] \"breedSimmental:farmD\" \"breedCharolais:farmE\" \"breedSimmental:farmE\"\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\n→ These breed × farm combinations have no data (missing cells)\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n→ These breed × farm combinations have no data (missing cells)\n```\n\n\n:::\n\n```{.r .cell-code}\n# Type III ANOVA (may fail with aliased coefficients)\ncat(\"\\nAttempting Type III ANOVA:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nAttempting Type III ANOVA:\n```\n\n\n:::\n\n```{.r .cell-code}\ntryCatch({\n  Anova(fit_interaction, type = 3)\n}, error = function(e) {\n  cat(\"→ Type III SS cannot be computed due to aliased coefficients\\n\")\n  cat(\"  This is expected with missing cells in interaction models!\\n\")\n  cat(\"  Use model comparison with anova() instead.\\n\")\n})\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n→ Type III SS cannot be computed due to aliased coefficients\n  This is expected with missing cells in interaction models!\n  Use model comparison with anova() instead.\n```\n\n\n:::\n\n```{.r .cell-code}\n# Test interaction significance\ncat(\"\\nTest interaction vs. additive:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nTest interaction vs. additive:\n```\n\n\n:::\n\n```{.r .cell-code}\nanova(fit_additive, fit_interaction)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n| Res.Df|       RSS| Df| Sum of Sq|        F| Pr(>F)|\n|------:|---------:|--:|---------:|--------:|------:|\n|    169| 0.2348209| NA|        NA|       NA|     NA|\n|    163| 0.1189613|  6| 0.1158596| 26.45834|      0|\n\n</div>\n:::\n\n```{.r .cell-code}\n# Interpretation\nif (anova(fit_additive, fit_interaction)$`Pr(>F)`[2] < 0.05) {\n  cat(\"\\n→ Interaction is significant (p < 0.05)\\n\")\n  cat(\"   Breed effects depend on farm!\\n\")\n} else {\n  cat(\"\\n→ Interaction not significant (p ≥ 0.05)\\n\")\n  cat(\"   Additive model sufficient.\\n\")\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n→ Interaction is significant (p < 0.05)\n   Breed effects depend on farm!\n```\n\n\n:::\n:::\n\n\n::: {.callout-important}\n### Handling Missing Cells\n\nWhen some breed × farm combinations don't exist:\n\n- Design matrix $\\mathbf{X}$ is rank deficient\n- R automatically drops redundant parameters (shown as NA)\n- Only estimable functions can be tested\n- Some comparisons only possible within farms\n\n**Example**: Can't directly compare Angus vs. Simmental on Farm E because Simmental not raised there.\n\n**Solution**: Use marginal means (averaged across farms where both breeds present) via `emmeans`.\n:::\n\n---\n\n### Estimable Contrasts with emmeans\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(emmeans)\n\n# Estimated marginal means for breed (averaged across farms)\nemm_breed <- emmeans(fit_additive, \"breed\")\n\ncat(\"Estimated marginal means (breed):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nEstimated marginal means (breed):\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(emm_breed)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n breed     emmean      SE  df lower.CL upper.CL\n Angus       1.16 0.00526 169     1.15     1.17\n Charolais   1.31 0.00754 169     1.29     1.32\n Hereford    1.05 0.00562 169     1.04     1.06\n Simmental   1.39 0.00635 169     1.38     1.40\n\nResults are averaged over the levels of: farm \nConfidence level used: 0.95 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Pairwise comparisons\ncat(\"\\nPairwise breed comparisons:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nPairwise breed comparisons:\n```\n\n\n:::\n\n```{.r .cell-code}\npairs_breed <- pairs(emm_breed, adjust = \"tukey\")\nprint(pairs_breed)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n contrast              estimate      SE  df t.ratio p.value\n Angus - Charolais       -0.150 0.00940 169 -15.938  <.0001\n Angus - Hereford         0.111 0.00789 169  14.068  <.0001\n Angus - Simmental       -0.235 0.00843 169 -27.874  <.0001\n Charolais - Hereford     0.261 0.00914 169  28.551  <.0001\n Charolais - Simmental   -0.085 0.00979 169  -8.681  <.0001\n Hereford - Simmental    -0.346 0.00881 169 -39.260  <.0001\n\nResults are averaged over the levels of: farm \nP value adjustment: tukey method for comparing a family of 4 estimates \n```\n\n\n:::\n\n```{.r .cell-code}\n# Custom contrast: British vs. Continental breeds\n# British: Angus, Hereford\n# Continental: Charolais, Simmental\ncontrast_british_continental <- list(\n  \"British vs Continental\" = c(0.5, 0.5, -0.5, -0.5)  # Angus, Char, Here, Simm\n)\n\ncat(\"\\nCustom contrast: British vs. Continental breeds:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCustom contrast: British vs. Continental breeds:\n```\n\n\n:::\n\n```{.r .cell-code}\ntest_contrast <- contrast(emm_breed, contrast_british_continental)\nprint(test_contrast)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n contrast               estimate      SE  df t.ratio p.value\n British vs Continental    0.013 0.00605 169   2.150  0.0330\n\nResults are averaged over the levels of: farm \n```\n\n\n:::\n\n```{.r .cell-code}\n# Effect size\neffect_size <- summary(test_contrast)$estimate\ncat(\"\\nEffect size:\", effect_size, \"kg/day\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nEffect size: 0.01301038 kg/day\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Continental breeds gain\", abs(effect_size), \"kg/day more than British breeds (on average).\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nContinental breeds gain 0.01301038 kg/day more than British breeds (on average).\n```\n\n\n:::\n:::\n\n\n::: {.callout-tip}\n### Using emmeans for Unbalanced Data\n\nThe `emmeans` package is invaluable for unbalanced designs:\n\n**What it does**:\n\n- Computes **estimated marginal means** (EMMs): breed means averaged across farms, weighted appropriately\n- Handles **missing cells** gracefully\n- Provides **correct SEs** accounting for unbalanced sample sizes\n- Enables **estimable contrasts** only\n\n**When to use**:\n\n- Any unbalanced multi-factor design\n- Missing cells\n- Want \"adjusted means\" (breed means accounting for farm differences)\n\n**How to use**:\n\n```r\nfit <- lm(response ~ factor1 + factor2, data = data)\nemm <- emmeans(fit, \"factor1\")         # Marginal means\npairs(emm)                              # Pairwise comparisons\ncontrast(emm, list(\"Custom\" = c(...))) # Custom contrasts\n```\n:::\n\n---\n\n### Precision Under Unbalanced Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Standard errors vary with sample size\nemm_summary <- summary(emm_breed)\n\ncat(\"Standard errors by breed:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nStandard errors by breed:\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(emm_summary[, c(\"breed\", \"emmean\", \"SE\")])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      breed   emmean          SE\n1     Angus 1.157149 0.005263675\n2 Charolais 1.307028 0.007543979\n3  Hereford 1.046161 0.005615416\n4 Simmental 1.391996 0.006354405\n```\n\n\n:::\n\n```{.r .cell-code}\n# Relative precision (1/SE²)\nemm_summary$rel_precision <- 1 / emm_summary$SE^2\n\ncat(\"\\nRelative precision (1/SE²):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nRelative precision (1/SE²):\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(emm_summary[, c(\"breed\", \"rel_precision\")])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      breed rel_precision\n1     Angus      36092.91\n2 Charolais      17571.10\n3  Hereford      31712.92\n4 Simmental      24765.67\n```\n\n\n:::\n\n```{.r .cell-code}\n# Sample sizes by breed\nn_breed <- table(beef$breed)\ncat(\"\\nSample sizes:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nSample sizes:\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(n_breed)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n    Angus Charolais  Hereford Simmental \n       57        28        49        43 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\n→ Breeds with more observations have smaller SEs (more precise).\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n→ Breeds with more observations have smaller SEs (more precise).\n```\n\n\n:::\n:::\n\n\n**Key insight**: With unbalanced data, precision differs across groups.\n\n**Formula** (approximately, for simple contrasts):\n\n$$\nSE(\\hat{\\mu}_i - \\hat{\\mu}_j) \\approx \\hat{\\sigma} \\sqrt{\\frac{1}{n_i} + \\frac{1}{n_j}}\n$$\n\n**Implications**:\n\n- Comparisons involving small groups less precise\n- Must report sample sizes with means\n- Consider weighting in meta-analysis\n\n---\n\n## Practical Guidelines\n\n### Statistical Recommendations\n\nWhen analyzing unbalanced livestock data, follow these best practices:\n\n**1. Use Type III SS for hypothesis testing**\n\n- Tests each effect adjusted for all others\n- Order-independent\n- Appropriate for unbalanced designs\n\n**2. Focus on estimable functions**\n\n- Don't interpret non-estimable parameters (NA in R output)\n- Use `emmeans` for marginal means\n- Test contrasts, not individual parameters\n\n**3. Report sample sizes clearly**\n\n- Always show $n$ by group\n- Acknowledge precision differences\n- Larger groups have narrower confidence intervals\n\n**4. Use appropriate standard errors**\n\n- `emmeans` computes correct SEs for unbalanced data\n- Don't assume equal precision across groups\n- $SE(\\hat{\\mu}_i) \\propto 1/\\sqrt{n_i}$\n\n**5. Consider model selection carefully**\n\n- Is interaction needed? Test it.\n- Are covariates confounded with treatments?\n- Document missing cells and their impact\n\n::: {.callout-warning}\n### Common Pitfalls with Unbalanced Data\n\n1. **Using Type I SS when order matters**: Type I depends on order effects entered—misleading for unbalanced data\n\n2. **Ignoring confounding**: If groups differ systematically (e.g., all high-performing animals in one group), can't separate cause from selection\n\n3. **Equal weighting when precision differs**: Averaging group means gives equal weight, but some based on $n=5$, others on $n=50$\n\n4. **Interpreting non-estimable parameters**: If R shows NA, that parameter is not estimable—don't try to interpret\n\n5. **Assuming orthogonality**: Unbalanced designs lose orthogonality—effects are correlated\n\n**Always check**:\n\n- Design matrix rank\n- Which parameters estimable\n- Standard errors vary with $n$\n- Type III SS for testing\n:::\n\n---\n\n### Experimental Design Implications\n\n**Why balanced designs are preferred**:\n\n1. **Equal precision**: All group means estimated with same accuracy\n2. **Orthogonal contrasts**: Effects independent, easier to interpret\n3. **Type I = II = III**: All SS types agree\n4. **Simpler analysis**: No estimability issues\n5. **More power**: For same total $n$, balanced design most powerful\n\n**When unbalanced is unavoidable** (commercial data, missing data, etc.):\n\n1. **Document why**: Animal loss? Selection? Practical constraints?\n2. **Analyze appropriately**: Type III SS, `emmeans`, estimable contrasts\n3. **Report limitations**: Missing cells, confounding, precision differences\n4. **Be transparent**: Show sample sizes, acknowledge bias potential\n\n**For planned experiments**:\n\n- **Aim for balance** when possible\n- If unbalanced necessary, plan analysis in advance\n- Consider blocking to reduce confounding\n\n---\n\n## Summary\n\n### Conceptual Summary\n\nReal livestock data is messy, but the linear models framework still works—we just need additional tools.\n\n**Key insights from Week 12**:\n\n1. **Cell means model is always full rank**, even with unbalanced data. It directly estimates group means, avoiding singularity issues.\n\n2. **Effects model may be rank deficient** with unbalanced data. Individual $\\mu$ and $\\alpha_i$ parameters are not uniquely estimable, but contrasts $\\alpha_i - \\alpha_j$ are.\n\n3. **Generalized inverses solve singular systems**. Any $(\\mathbf{X}'\\mathbf{X})^-$ works—different g-inverses give different $\\mathbf{b}$, but estimable functions $\\mathbf{c}'\\mathbf{b}$ are always the same.\n\n4. **Estimability is key**: A function $\\mathbf{c}'\\boldsymbol{\\beta}$ is estimable iff $\\mathbf{c}' = \\mathbf{a}'\\mathbf{X}$ for some $\\mathbf{a}$. Only estimable functions should be interpreted.\n\n5. **Constraints remove redundancy**: Set-to-zero, sum-to-zero, or weighted constraints make parameters unique, but choice is interpretational—estimable contrasts remain the same.\n\n**For animal breeding applications**:\n\n- We care about **differences** between breeds, sires, or treatments—not absolute values\n- Rank deficiency is not a problem for contrasts\n- Unbalanced data is the norm in genetic evaluation\n- Focus on estimable functions and use appropriate methods (`emmeans`, Type III SS)\n\n::: {.callout-note}\n### Looking Ahead\n\n**Week 13: Special Topics I**\n\n- More on constraint systems and different parameterizations\n- Types of generalized inverses (Moore-Penrose, reflexive, others)\n- Weighted least squares for heterogeneous variances\n- Strategic approaches to unbalanced data\n\n**Week 14: Special Topics II**\n\n- Polynomial regression (growth curves, lactation curves)\n- Regression through the origin\n- **Preview of mixed models**: Adding random effects\n- **Henderson's mixed model equations (MME)**: The foundation of BLUP\n\n$$\n\\begin{bmatrix}\n\\mathbf{X}'\\mathbf{R}^{-1}\\mathbf{X} & \\mathbf{X}'\\mathbf{R}^{-1}\\mathbf{Z} \\\\\n\\mathbf{Z}'\\mathbf{R}^{-1}\\mathbf{X} & \\mathbf{Z}'\\mathbf{R}^{-1}\\mathbf{Z} + \\mathbf{G}^{-1}\n\\end{bmatrix}\n\\begin{bmatrix}\n\\hat{\\boldsymbol{\\beta}} \\\\\n\\hat{\\mathbf{u}}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\mathbf{X}'\\mathbf{R}^{-1}\\mathbf{y} \\\\\n\\mathbf{Z}'\\mathbf{R}^{-1}\\mathbf{y}\n\\end{bmatrix}\n$$\n\nThese are augmented normal equations—same tools (generalized inverses, estimability) apply!\n\nWeek 12 provides the foundation for understanding mixed models in genetic evaluation.\n:::\n\n---\n\n### Key Equations Summary\n\n**Rank-deficient normal equations**:\n$$\\mathbf{X}'\\mathbf{X}\\mathbf{b} = \\mathbf{X}'\\mathbf{y}, \\quad r(\\mathbf{X}'\\mathbf{X}) < p$$\n\n**G-inverse solution**:\n$$\\mathbf{b} = (\\mathbf{X}'\\mathbf{X})^-\\mathbf{X}'\\mathbf{y}$$\n\n**Estimability criterion**:\n$$\\mathbf{c}'\\boldsymbol{\\beta} \\text{ estimable} \\iff \\mathbf{c}' = \\mathbf{a}'\\mathbf{X} \\text{ for some } \\mathbf{a}$$\n\n**Variance of estimable function**:\n$$\\text{Var}(\\mathbf{c}'\\mathbf{b}) = \\mathbf{c}'(\\mathbf{X}'\\mathbf{X})^-\\mathbf{c}\\sigma^2$$\n\n**t-test for contrast**:\n$$t = \\frac{\\mathbf{c}'\\mathbf{b}}{\\sqrt{\\mathbf{c}'(\\mathbf{X}'\\mathbf{X})^-\\mathbf{c}\\hat{\\sigma}^2}} \\sim t(n - r(\\mathbf{X}))$$\n\n**SE for unbalanced contrast** (approximate):\n$$SE(\\hat{\\mu}_i - \\hat{\\mu}_j) \\approx \\hat{\\sigma}\\sqrt{\\frac{1}{n_i} + \\frac{1}{n_j}}$$\n\n---\n\n### Cross-References\n\n- **Previous**: [Week 11: Model Diagnostics](../Week11_Diagnostics/Week11_Diagnostics.qmd)\n- **Next**: [Week 13: Special Topics I](../Week13_SpecialTopicsI/Week13_SpecialTopicsI.qmd)\n\n---\n\n### References\n\n::: {.callout-tip}\n### Additional Resources\n\n**Textbooks**:\n\n- Searle, S. R. (1971). *Linear Models*. Wiley. [Classic reference on rank deficiency and estimability]\n- Milliken, G. A., & Johnson, D. E. (2009). *Analysis of Messy Data, Volume 1: Designed Experiments* (2nd ed.). CRC Press.\n- Henderson, C. R. (1984). *Applications of Linear Models in Animal Breeding*. University of Guelph.\n\n**R Packages**:\n\n- `MASS::ginv()`: Moore-Penrose inverse\n- `emmeans`: Estimated marginal means and contrasts\n- `car::Anova()`: Type II and Type III SS\n\n**Vignettes**:\n\n- `emmeans` vignette on estimability: `vignette(\"basics\", package=\"emmeans\")`\n- FAQs on unbalanced ANOVA: `vignette(\"FAQs\", package=\"emmeans\")`\n\n**Papers**:\n\n- Searle, S. R., Speed, F. M., & Milliken, G. A. (1980). Population marginal means in the linear model: An alternative to least squares means. *The American Statistician*, 34(4), 216-221.\n:::\n",
    "supporting": [
      "Week12_NonFullRank_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}