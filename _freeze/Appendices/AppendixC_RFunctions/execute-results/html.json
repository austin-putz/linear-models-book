{
  "hash": "ae9e423c23bfd729dc27d79e4dff3162",
  "result": {
    "engine": "knitr",
    "markdown": "# Appendix C: R Functions Reference {#sec-appendix-c .unnumbered}\n\n## Introduction\n\nThis appendix provides a concise reference guide to all R functions used throughout the 15-week linear models course. Functions are organized by **functional category** (not alphabetically) to help you quickly locate related operations.\n\n### Purpose and Scope\n\nThis reference is designed to:\n\n- Provide quick lookup of function syntax and key parameters\n- Show which weeks each function is introduced or used heavily\n- Distinguish between base R and package functions\n- Offer troubleshooting guidance for common issues\n\n### How to Use This Appendix\n\n- **Quick lookup**: Use the table of contents to jump to a specific category\n- **Function search**: Use your browser's search function (Ctrl+F or Cmd+F) to find a specific function name\n- **Week review**: Check the \"Week(s)\" column to see where concepts are taught\n- **Troubleshooting**: Jump to @sec-rfunc-pitfalls or @sec-rfunc-troubleshoot for common issues\n\n:::{.callout-note}\n## Relationship to Other Appendices\n\n- **Appendix A**: Mathematical notation reference\n- **Appendix B**: In-depth matrix algebra tutorial with derivations\n- **Appendix C** (this): Quick reference for R functions\n:::\n\n---\n\n## Package Installation and Setup {#sec-rfunc-setup}\n\nMost functions in this appendix are from **base R** and require no additional installation. For package functions, install as needed:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Essential packages\ninstall.packages(\"MASS\")      # ginv(), boxcox()\ninstall.packages(\"car\")       # Anova(), vif()\ninstall.packages(\"emmeans\")   # emmeans(), contrast(), pairs()\ninstall.packages(\"Matrix\")    # rankMatrix(), sparse matrices\n\n# Optional packages (used in specific weeks)\ninstall.packages(\"lme4\")      # lmer() for mixed models preview (Week 14)\ninstall.packages(\"multcomp\")  # Multiple comparisons (Week 8)\ninstall.packages(\"ggplot2\")   # Enhanced graphics\n```\n:::\n\n\n### Loading Packages\n\nLoad required packages at the start of your R session:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(MASS)\nlibrary(car)\nlibrary(emmeans)\nlibrary(Matrix)\n```\n:::\n\n\n:::{.callout-note}\n## Base R vs Packages\n\n- **Base R functions** (like `lm()`, `solve()`, `matrix()`) are always available\n- **Package functions** (like `ginv()`, `Anova()`) require loading the package first with `library()`\n:::\n\n---\n\n## Basic Matrix Operations {#sec-rfunc-matrix-basic}\n\nFunctions for creating and manipulating matrices.\n\n| Function | Package | Syntax | Description | Key Parameters | Week(s) |\n|----------|---------|--------|-------------|----------------|---------|\n| `matrix()` | base R | `matrix(data, nrow, ncol)` | Create a matrix from vector | `data=`, `nrow=`, `ncol=`, `byrow=` | 1-15 |\n| `t()` | base R | `t(X)` | Transpose matrix | `x=` | 1-15 |\n| `%*%` | base R | `A %*% B` | Matrix multiplication | - | 1-15 |\n| `solve()` | base R | `solve(A)` or `solve(A, b)` | Compute matrix inverse or solve linear system | `a=`, `b=` | 2-15 |\n| `ginv()` | MASS | `ginv(X)` | Generalized (Moore-Penrose) inverse | `X=`, `tol=` | 2,12-13 |\n| `cbind()` | base R | `cbind(v1, v2, ...)` | Combine vectors/matrices by columns | `...` | 3-15 |\n| `rbind()` | base R | `rbind(v1, v2, ...)` | Combine vectors/matrices by rows | `...` | Throughout |\n| `c()` | base R | `c(x1, x2, ...)` | Combine values into vector | `...` | 1-15 |\n\n:::{.callout-note}\n## Matrix Multiplication vs Element-wise\n\n- `%*%` performs **matrix multiplication** (inner dimensions must match: (m×n) × (n×p) → (m×p))\n- `*` performs **element-wise multiplication** (dimensions must match exactly)\n:::\n\n:::{.callout-tip}\n## Efficiency Tip\n\nFor computing $\\mathbf{X}'\\mathbf{X}$, use `crossprod(X)` instead of `t(X) %*% X` - it's faster and more numerically stable.\n:::\n\n---\n\n## Matrix Properties and Decompositions {#sec-rfunc-matrix-props}\n\nFunctions for examining matrix characteristics and performing decompositions.\n\n| Function | Package | Syntax | Description | Key Parameters | Week(s) |\n|----------|---------|--------|-------------|----------------|---------|\n| `qr()` | base R | `qr(X)` | QR decomposition; use `$rank` to get rank | `x=`, `tol=` | 2,12 |\n| `det()` | base R | `det(A)` | Compute determinant | `x=` | 2 |\n| `diag()` | base R | `diag(X)` or `diag(n)` | Extract diagonal or create diagonal matrix | `x=`, `nrow=`, `ncol=` | 2-15 |\n| `eigen()` | base R | `eigen(A)` | Eigenvalue decomposition | `x=`, `symmetric=` | 2,5 |\n| `svd()` | base R | `svd(X)` | Singular value decomposition | `x=` | 2,13 |\n| `rankMatrix()` | Matrix | `rankMatrix(X)` | Compute rank (more reliable than `qr()$rank`) | `x=`, `method=` | 2,12 |\n| `crossprod()` | base R | `crossprod(X)` or `crossprod(X, Y)` | Compute $\\mathbf{X}'\\mathbf{X}$ or $\\mathbf{X}'\\mathbf{Y}$ efficiently | `x=`, `y=` | 5-15 |\n| `tcrossprod()` | base R | `tcrossprod(X)` | Compute $\\mathbf{X}\\mathbf{X}'$ efficiently | `x=`, `y=` | 5-15 |\n| `norm()` | base R | `norm(X, type)` | Compute matrix norm | `x=`, `type=` | 2 |\n\n:::{.callout-important}\n## Rank Determination\n\nFor rank deficiency detection, use `rankMatrix()` from the Matrix package - it's more robust than `qr()$rank` for near-singular matrices. See Week 12 for details on non-full rank models.\n:::\n\n---\n\n## Linear Model Fitting {#sec-rfunc-lm-fitting}\n\nFunctions for fitting linear models and building design matrices.\n\n| Function | Package | Syntax | Description | Key Parameters | Week(s) |\n|----------|---------|--------|-------------|----------------|---------|\n| `lm()` | base R | `lm(formula, data)` | Fit linear model using ordinary least squares | `formula=`, `data=`, `weights=` | 4-15 |\n| `model.matrix()` | base R | `model.matrix(formula, data)` | Build design matrix $\\mathbf{X}$ from formula | `object=`, `data=` | 3-15 |\n| `formula()` | base R | `formula(model)` | Extract formula from fitted model | `x=` | Throughout |\n| `update()` | base R | `update(model, new_formula)` | Update and refit model with new formula | `object=`, `formula=`, `data=` | 6-10 |\n| `lmer()` | lme4 | `lmer(formula, data)` | Fit mixed model (preview only) | `formula=`, `data=`, `REML=` | 14 |\n\n:::{.callout-tip}\n## Design Matrix Construction\n\nAlways verify your design matrix before fitting:\n```r\nX <- model.matrix(~ breed + sex, data=mydata)\nhead(X)  # Check structure\nqr(X)$rank  # Check rank\n```\n:::\n\n---\n\n## Model Summaries and Extraction {#sec-rfunc-lm-summary}\n\nFunctions for extracting information from fitted models.\n\n| Function | Package | Syntax | Description | Key Parameters | Week(s) |\n|----------|---------|--------|-------------|----------------|---------|\n| `summary()` | base R | `summary(model)` | Comprehensive model summary (coefficients, R², F-test) | `object=` | 4-15 |\n| `coef()` | base R | `coef(model)` | Extract coefficient estimates $\\mathbf{b}$ | `object=` | 4-15 |\n| `residuals()` | base R | `residuals(model)` or `resid(model)` | Extract residuals $\\mathbf{e} = \\mathbf{y} - \\hat{\\mathbf{y}}$ | `object=`, `type=` | 4-15 |\n| `fitted()` | base R | `fitted(model)` | Extract fitted values $\\hat{\\mathbf{y}} = \\mathbf{Xb}$ | `object=` | 4-15 |\n| `predict()` | base R | `predict(model, newdata)` | Predict for new observations | `object=`, `newdata=`, `interval=` | 4,6 |\n| `vcov()` | base R | `vcov(model)` | Variance-covariance matrix of estimates $(\\mathbf{X}'\\mathbf{X})^{-1}\\hat{\\sigma}^2$ | `object=` | 5-15 |\n| `sigma()` | base R | `sigma(model)` | Extract residual standard error $\\hat{\\sigma}$ | `object=` | 5-15 |\n| `deviance()` | base R | `deviance(model)` | Residual sum of squares (SSE) | `object=` | 5-15 |\n| `logLik()` | base R | `logLik(model)` | Log-likelihood of fitted model | `object=` | 6,14 |\n| `AIC()` | base R | `AIC(model)` | Akaike Information Criterion | `object=`, `k=` | 6,14 |\n| `confint()` | base R | `confint(model, level=0.95)` | Confidence intervals for parameters | `object=`, `parm=`, `level=` | 5-6 |\n\n:::{.callout-note}\n## Residuals vs Fitted Values\n\n- `residuals(model)`: Returns $\\mathbf{e} = \\mathbf{y} - \\hat{\\mathbf{y}}$\n- `fitted(model)`: Returns $\\hat{\\mathbf{y}} = \\mathbf{Xb}$\n- Verify: `all.equal(y, fitted(model) + residuals(model))` should be `TRUE`\n:::\n\n---\n\n## Hypothesis Testing and ANOVA {#sec-rfunc-testing}\n\nFunctions for testing hypotheses about model parameters.\n\n| Function | Package | Syntax | Description | Key Parameters | Week(s) |\n|----------|---------|--------|-------------|----------------|---------|\n| `anova()` | base R | `anova(model)` or `anova(model1, model2)` | ANOVA table with Type I (sequential) SS | `object=` | 6-10 |\n| `Anova()` | car | `Anova(model, type=3)` | Type II or Type III SS for unbalanced data | `mod=`, `type=` | 9-10,12 |\n| `emmeans()` | emmeans | `emmeans(model, specs)` | Estimated marginal means (LSMEANS) | `object=`, `specs=`, `by=` | 8-10 |\n| `contrast()` | emmeans | `contrast(emm, method)` | Test contrasts among means | `object=`, `method=`, `adjust=` | 8-10 |\n| `pairs()` | emmeans | `pairs(emm)` | Pairwise comparisons | `x=`, `adjust=` | 8-9 |\n| `drop1()` | base R | `drop1(model, test=\"F\")` | Test dropping each term | `object=`, `scope=`, `test=` | 6,9 |\n| `add1()` | base R | `add1(model, scope, test=\"F\")` | Test adding each term | `object=`, `scope=`, `test=` | 6 |\n| `vif()` | car | `vif(model)` | Variance inflation factors (detect collinearity) | `mod=` | 6 |\n\n:::{.callout-important}\n## Type I vs Type III SS\n\n- **Type I SS** (sequential): Order matters! Each term adjusted for previous terms only\n  - Use `anova(model)` - default in R\n  - Appropriate for **balanced** designs\n\n- **Type III SS** (partial): Each term adjusted for all other terms\n  - Use `car::Anova(model, type=3)`\n  - Appropriate for **unbalanced** designs and recommended for general use\n\nSee Weeks 9-10 for detailed discussion.\n:::\n\n---\n\n## Model Diagnostics {#sec-rfunc-diagnostics}\n\nFunctions for checking model assumptions and identifying influential observations.\n\n| Function | Package | Syntax | Description | Key Parameters | Week(s) |\n|----------|---------|--------|-------------|----------------|---------|\n| `plot()` | base R | `plot(lm_object)` | Create 4 diagnostic plots automatically | `x=`, `which=` | 11 |\n| `hatvalues()` | base R | `hatvalues(model)` | Extract leverage values (diagonal of hat matrix $\\mathbf{H}$) | `model=` | 11 |\n| `cooks.distance()` | base R | `cooks.distance(model)` | Compute Cook's distance for each observation | `model=` | 11 |\n| `rstandard()` | base R | `rstandard(model)` | Standardized residuals | `model=`, `type=` | 11 |\n| `rstudent()` | base R | `rstudent(model)` | Studentized deleted residuals | `model=` | 11 |\n| `influence.measures()` | base R | `influence.measures(model)` | Comprehensive influence diagnostics | `model=` | 11 |\n| `dffits()` | base R | `dffits(model)` | Change in fitted value when observation deleted | `model=` | 11 |\n| `dfbetas()` | base R | `dfbetas(model)` | Change in coefficients when observation deleted | `model=` | 11 |\n| `qqnorm()` | base R | `qqnorm(residuals)` | Normal Q-Q plot to check normality | `y=` | 11 |\n| `boxcox()` | MASS | `boxcox(model)` | Box-Cox transformation for normality/homoscedasticity | `object=`, `lambda=` | 11,14 |\n\n:::{.callout-tip}\n## Rule-of-Thumb Thresholds\n\n- **High leverage**: $h_{ii} > 2p/n$ or $3p/n$ where $p$ = number of parameters, $n$ = sample size\n- **Influential observation**: Cook's D > 1 or Cook's D > 4/n\n- **Outlier**: |studentized residual| > 3\n\nWeek 11 provides detailed guidance on interpretation and remedial measures.\n:::\n\n:::{.callout-note}\n## Quick Diagnostic Check\n\n```r\npar(mfrow=c(2,2))\nplot(model)  # Creates all 4 diagnostic plots at once\n```\n\n1. **Residuals vs Fitted**: Check linearity and homoscedasticity\n2. **Q-Q Plot**: Check normality assumption\n3. **Scale-Location**: Check homoscedasticity\n4. **Residuals vs Leverage**: Identify influential points\n:::\n\n---\n\n## Advanced Model Tools {#sec-rfunc-advanced}\n\nFunctions for working with contrasts, constraints, and model parameterizations.\n\n| Function | Package | Syntax | Description | Key Parameters | Week(s) |\n|----------|---------|--------|-------------|----------------|---------|\n| `contr.treatment()` | base R | `contr.treatment(n)` | Treatment (reference cell) contrasts | `n=`, `base=` | 3,8,13 |\n| `contr.sum()` | base R | `contr.sum(n)` | Sum-to-zero contrasts | `n=` | 8,13 |\n| `contrasts()` | base R | `contrasts(factor)` | Get or set contrasts for a factor | `x=`, `value=` | 8,13 |\n| `options()` | base R | `options(contrasts=c(...))` | Set default contrast system | `contrasts=` | 13 |\n| `relevel()` | base R | `relevel(factor, ref)` | Change reference level of factor | `x=`, `ref=` | 8-9 |\n| `interaction.plot()` | base R | `interaction.plot(f1, f2, y)` | Plot interaction between two factors | `x.factor=`, `trace.factor=`, `response=` | 9 |\n| `all.equal()` | base R | `all.equal(x, y)` | Compare objects with tolerance (for floating-point) | `target=`, `current=`, `tolerance=` | Throughout |\n| `is.estimable()` | estimability | `is.estimable(contrast, X)` | Check if linear function is estimable | `x=`, `X=` | 8,12-13 |\n\n:::{.callout-important}\n## Contrast Systems\n\n**Set-to-zero (treatment) contrasts**:\n```r\noptions(contrasts = c(\"contr.treatment\", \"contr.poly\"))\n```\n- Default in R\n- First level is reference (coefficient = 0)\n- Other coefficients are **differences from reference**\n\n**Sum-to-zero (effects) contrasts**:\n```r\noptions(contrasts = c(\"contr.sum\", \"contr.poly\"))\n```\n- Coefficients sum to zero: $\\sum \\alpha_i = 0$\n- Each coefficient is **deviation from overall mean**\n- More symmetric, preferred for balanced designs\n\nSee Week 13 for detailed comparison and implications.\n:::\n\n---\n\n## Data Manipulation {#sec-rfunc-data}\n\nFunctions for organizing and summarizing data.\n\n| Function | Package | Syntax | Description | Key Parameters | Week(s) |\n|----------|---------|--------|-------------|----------------|---------|\n| `tapply()` | base R | `tapply(X, INDEX, FUN)` | Apply function to subgroups | `X=`, `INDEX=`, `FUN=` | 7-10 |\n| `aggregate()` | base R | `aggregate(x, by, FUN)` | Compute summary statistics by groups | `x=`, `by=`, `FUN=` | 7-10 |\n| `factor()` | base R | `factor(x, levels)` | Create or modify factor variable | `x=`, `levels=`, `labels=` | 3-15 |\n| `mean()` | base R | `mean(x)` | Compute arithmetic mean | `x=`, `na.rm=` | 1-15 |\n| `sum()` | base R | `sum(x)` | Compute sum | `x=`, `na.rm=` | 1-15 |\n| `length()` | base R | `length(x)` | Number of elements in vector | `x=` | Throughout |\n| `nrow()` | base R | `nrow(X)` | Number of rows in matrix/data frame | `x=` | Throughout |\n| `ncol()` | base R | `ncol(X)` | Number of columns in matrix/data frame | `x=` | Throughout |\n| `subset()` | base R | `subset(data, condition)` | Extract subset of data | `x=`, `subset=`, `select=` | Throughout |\n| `transform()` | base R | `transform(data, ...)` | Add or modify variables | `_data=`, `...` | Throughout |\n| `with()` | base R | `with(data, expr)` | Evaluate expression in data environment | `data=`, `expr=` | Throughout |\n| `round()` | base R | `round(x, digits)` | Round to specified decimal places | `x=`, `digits=` | Throughout |\n| `sprintf()` | base R | `sprintf(fmt, ...)` | Format output with C-style formatting | `fmt=`, `...` | Throughout |\n| `cat()` | base R | `cat(...)` | Print output (useful in R Markdown) | `...`, `sep=`, `fill=` | Throughout |\n\n:::{.callout-tip}\n## Computing Group Statistics\n\nThree common approaches:\n\n**1. Using `tapply()`** - Returns vector/array:\n```r\ntapply(y, group, mean)  # Mean of y for each group\n```\n\n**2. Using `aggregate()`** - Returns data frame:\n```r\naggregate(y ~ group, data=mydata, FUN=mean)\n```\n\n**3. Using `emmeans()`** - Returns model-based estimates:\n```r\nemmeans(lm(y ~ group), specs=\"group\")\n```\n\nChoose based on your needs:\n- `tapply()`: Quick calculations\n- `aggregate()`: Multiple variables at once\n- `emmeans()`: Adjusted means from models\n:::\n\n---\n\n## Common Pitfalls {#sec-rfunc-pitfalls}\n\nCommon issues encountered when working with linear models in R, their symptoms, and solutions.\n\n| Issue | Symptom | Solution |\n|-------|---------|----------|\n| **Singular matrix** | `Error in solve.default(X): system is computationally singular` | Use `ginv()` from MASS package instead of `solve()`. Occurs when $\\mathbf{X}'\\mathbf{X}$ is not full rank (Week 12). |\n| **Object not found** | `Error: object 'variable_name' not found` | Add `data=` argument to `lm()`: `lm(y ~ x, data=mydata)`. Ensures variables are found in the data frame. |\n| **Wrong SS type** | Type I SS gives different results than expected in unbalanced data | Use `car::Anova(model, type=3)` instead of base `anova()` for unbalanced designs (Weeks 9-10). |\n| **Non-estimable contrasts** | Different g-inverses give different parameter estimates | Verify contrast is estimable: check $\\sum c_i = 0$ for treatment contrasts. Only interpret estimable functions (Week 8, 12-13). |\n| **Uncentered covariate** | Intercept not interpretable as group mean at $\\bar{x}$ | Center covariate: `lm(y ~ group + I(x - mean(x)))` (Week 10). |\n| **Rank deficiency warnings** | `Coefficients: (1 not defined because of singularities)` | Either use cell means model (`~ factor - 1`) or apply explicit constraints. Check design matrix rank: `qr(X)$rank` (Week 12). |\n| **Factor vs numeric** | `contrasts can be applied only to factors with 2 or more levels` | Convert numeric variable to factor: `factor(variable)` or include in formula as `factor(variable)`. |\n| **Dimension mismatch** | `non-conformable arrays` or `arguments imply differing number of rows` | Check dimensions with `dim(X)`, `length(y)`. Matrix multiplication requires matching inner dimensions (Week 1-2). |\n\n:::{.callout-important}\n## Debugging Strategy\n\nWhen encountering errors, follow this systematic approach:\n\n1. **Check your data**: `str(data)`, `summary(data)`, `head(data)`\n2. **Check your formula**: `formula(model)`\n3. **Check design matrix**: `X <- model.matrix(model)`, then `dim(X)`, `qr(X)$rank`\n4. **Verify dimensions**: Ensure $n \\times p$ design matrix matches $n \\times 1$ response\n5. **Check for rank deficiency**: Compare `qr(X)$rank` to `ncol(X)`\n6. **Compare with lm()**: Verify manual calculations match `lm()` output\n7. **Test estimability**: For contrasts, verify $\\mathbf{c}'\\boldsymbol{\\beta}$ is estimable\n\nSee Week 11 (Diagnostics) and Week 12 (Non-Full Rank) for detailed troubleshooting.\n:::\n\n---\n\n## Quick Troubleshooting Guide {#sec-rfunc-troubleshoot}\n\n### Common Error Messages and Solutions\n\n**\"Error in solve.default(): system is computationally singular\"**\n\n- **Cause**: Matrix $\\mathbf{X}'\\mathbf{X}$ is not full rank (determinant ≈ 0)\n- **Solution**:\n  ```r\n  library(MASS)\n  b <- ginv(t(X) %*% X) %*% t(X) %*% y  # Use generalized inverse\n  ```\n- **Related**: Week 2 (Linear Algebra), Week 12 (Non-Full Rank Models)\n\n**\"Error: object 'variable_name' not found\"**\n\n- **Cause**: Variable not in current environment or data frame not specified\n- **Solution**:\n  ```r\n  model <- lm(y ~ x, data=mydata)  # Always use data= argument\n  ```\n- **Related**: Week 4 (Simple Regression)\n\n**\"Coefficients: (1 not defined because of singularities)\"**\n\n- **Cause**: Design matrix is rank deficient (overparameterized model)\n- **Solution**:\n  ```r\n  # Option 1: Cell means model\n  model <- lm(y ~ breed - 1, data=mydata)\n\n  # Option 2: Check which parameters are aliased\n  alias(model)\n  ```\n- **Related**: Week 12 (Non-Full Rank Models)\n\n**\"contrasts can be applied only to factors with 2 or more levels\"**\n\n- **Cause**: Categorical variable coded as numeric instead of factor\n- **Solution**:\n  ```r\n  mydata$breed <- factor(mydata$breed)\n  # Or in formula:\n  model <- lm(y ~ factor(breed), data=mydata)\n  ```\n- **Related**: Week 3 (Design Matrices), Week 7 (ANOVA)\n\n**\"non-conformable arrays\"**\n\n- **Cause**: Matrix dimensions don't match for the operation\n- **Solution**:\n  ```r\n  dim(X)  # Check dimensions\n  dim(y)\n  # For matrix multiplication A %*% B, need ncol(A) == nrow(B)\n  ```\n- **Related**: Week 1-2 (Matrix Operations)\n\n---\n\n### Getting Help in R\n\n**Function documentation**:\n```r\n?lm           # Quick help\nhelp(lm)      # Same as ?\n??regression  # Search all help files\n```\n\n**Examples**:\n```r\nexample(lm)           # Run examples from help file\ndemo(\"graphics\")      # Interactive demonstrations\n```\n\n**Package information**:\n```r\nhelp(package=\"MASS\")  # Package overview and function list\n```\n\n**Vignettes** (detailed tutorials):\n```r\nvignette()                    # List all available vignettes\nvignette(\"emmeans\")           # View specific vignette\nbrowseVignettes(\"emmeans\")    # Open in browser\n```\n\n**Online resources**:\n\n- R Documentation: https://www.rdocumentation.org/\n- Stack Overflow: https://stackoverflow.com/questions/tagged/r\n- R-bloggers: https://www.r-bloggers.com/\n- Quick-R: https://www.statmethods.net/\n\n---\n\n### Verification Strategy\n\nWhen building your own least squares solvers, always verify against `lm()`:\n\n```r\n# 1. Manual calculation\nX <- model.matrix(~ breed + sex, data=mydata)\ny <- mydata$weight\nb_manual <- solve(t(X) %*% X) %*% t(X) %*% y\n\n# 2. Using lm()\nmodel <- lm(weight ~ breed + sex, data=mydata)\nb_lm <- coef(model)\n\n# 3. Compare (should be near-zero)\nmax(abs(b_manual - b_lm))\n\n# 4. Use all.equal() for floating-point comparisons\nall.equal(as.vector(b_manual), b_lm)\n# Should return TRUE (or very small tolerance message)\n\n# 5. Verify fitted values\ny_hat_manual <- X %*% b_manual\ny_hat_lm <- fitted(model)\nall.equal(as.vector(y_hat_manual), y_hat_lm)\n\n# 6. Verify residuals\ne_manual <- y - y_hat_manual\ne_lm <- residuals(model)\nall.equal(as.vector(e_manual), e_lm)\n\n# 7. Verify SSE\nSSE_manual <- sum(e_manual^2)\nSSE_lm <- deviance(model)\nall.equal(SSE_manual, SSE_lm)\n```\n\n:::{.callout-tip}\n## Floating-Point Comparison\n\nNever use `==` to compare floating-point numbers! Use `all.equal()` instead:\n\n```r\n# BAD\nb_manual == b_lm  # May fail due to rounding errors\n\n# GOOD\nall.equal(b_manual, b_lm)  # Allows small tolerance (default: 1.5e-8)\n```\n:::\n\n---\n\n## Week-by-Week Function Index {#sec-rfunc-by-week}\n\nQuick reference showing which functions are introduced or used heavily in each week.\n\n| Week | Topic | Key Functions |\n|------|-------|---------------|\n| **1** | Overview & Foundations | `matrix()`, `t()`, `%*%`, `c()`, `mean()`, `sum()`, `length()` |\n| **2** | Linear Algebra | `solve()`, `ginv()`, `qr()`, `det()`, `diag()`, `eigen()`, `svd()`, `rankMatrix()` |\n| **3** | Design Matrices | `model.matrix()`, `factor()`, `cbind()`, `rbind()`, `formula()`, `contr.treatment()`, `contr.sum()` |\n| **4** | Simple Regression | `lm()`, `coef()`, `fitted()`, `residuals()`, `predict()`, `summary()` |\n| **5** | Least Squares Theory | `crossprod()`, `tcrossprod()`, `vcov()`, `sigma()`, `deviance()`, `confint()` |\n| **6** | Multiple Regression | `anova()`, `drop1()`, `add1()`, `vif()`, `cor()`, `AIC()`, `update()` |\n| **7** | One-Way ANOVA | `anova()`, `tapply()`, `aggregate()`, `aov()`, `TukeyHSD()` |\n| **8** | Contrasts | `emmeans()`, `contrast()`, `pairs()`, `contr.sum()`, `contr.treatment()`, `contrasts()`, `relevel()` |\n| **9** | Two-Way ANOVA | `Anova()` (Type III), `interaction.plot()`, `model.tables()`, `emmeans()` with interactions |\n| **10** | ANCOVA | `emmeans()` (adjusted means), `anova()` (sequential tests), `Anova()` (partial tests), centering covariates |\n| **11** | Diagnostics | `plot()`, `hatvalues()`, `cooks.distance()`, `rstandard()`, `rstudent()`, `influence.measures()`, `dffits()`, `dfbetas()`, `qqnorm()` |\n| **12** | Non-Full Rank | `ginv()`, `rankMatrix()`, `qr()`, `all.equal()`, `alias()`, checking estimability |\n| **13** | Special Topics I | `options(contrasts)`, `relevel()`, `is.estimable()`, different constraint systems |\n| **14** | Special Topics II | `poly()`, `lm(weights=)`, `lmer()` (preview), `boxcox()`, `logLik()` |\n| **15** | Capstone | **Integration of all functions above** - comprehensive livestock data analysis |\n\n:::{.callout-note}\n## Progressive Learning\n\n- **Weeks 1-3**: Foundations (matrix operations, design matrices)\n- **Weeks 4-6**: Core regression (simple, theory, multiple)\n- **Weeks 7-10**: ANOVA family (one-way, contrasts, two-way, ANCOVA)\n- **Week 11**: Diagnostics (checking all assumptions)\n- **Weeks 12-14**: Advanced topics (rank deficiency, special cases)\n- **Week 15**: Integration (real-world application)\n\nEach week builds on previous concepts - review earlier weeks as needed.\n:::\n\n---\n\n## Additional Resources\n\n### R Cheat Sheets\n\n- **Base R**: https://iqss.github.io/dss-workshops/R/Rintro/base-r-cheat-sheet.pdf\n- **RStudio**: https://www.rstudio.com/resources/cheatsheets/\n\n### Textbooks with R Code\n\n- *Linear Models with R* by Julian Faraway\n- *The R Book* by Michael Crawley\n- *Applied Linear Statistical Models* by Kutner et al. (has R companion)\n\n### Online Courses\n\n- DataCamp: \"Introduction to Linear Modeling in R\"\n- Coursera: \"Regression Models\" (Johns Hopkins)\n- R-exercises: https://www.r-exercises.com/\n\n### Package Documentation\n\n- **MASS**: https://cran.r-project.org/web/packages/MASS/MASS.pdf\n- **car**: https://cran.r-project.org/web/packages/car/car.pdf\n- **emmeans**: https://cran.r-project.org/web/packages/emmeans/vignettes/\n\n---\n\nThis completes Appendix C. For mathematical notation, see [Appendix A](#sec-appendix-a). For in-depth matrix algebra, see [Appendix B](#sec-appendix-b).\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}